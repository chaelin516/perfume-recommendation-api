# utils/emotion_analyzer.py - Whiff ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ (Google Drive ì—°ë™ ë²„ì „)

import re
import logging
import json
import os
import asyncio
import time
import pickle
import requests
from typing import List, Dict, Tuple, Optional, Union, Any
from datetime import datetime, timedelta
from collections import Counter
import numpy as np

# Google Drive API ê´€ë ¨ ì„í¬íŠ¸
try:
    from googleapiclient.discovery import build
    from google.oauth2.service_account import Credentials
    from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload
    import io

    GOOGLE_DRIVE_AVAILABLE = True
except ImportError:
    GOOGLE_DRIVE_AVAILABLE = False
    logging.warning("Google Drive API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-api-python-client google-auth ì‹¤í–‰í•˜ì„¸ìš”.")

logger = logging.getLogger(__name__)


class GoogleDriveManager:
    """Google Drive ì—°ë™ ê´€ë¦¬ì"""

    def __init__(self, credentials_path: Optional[str] = None):
        """Google Drive ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        self.service = None
        self.credentials_path = credentials_path or os.getenv('GOOGLE_DRIVE_CREDENTIALS_PATH')
        self.is_connected = False

        if GOOGLE_DRIVE_AVAILABLE and self.credentials_path:
            self._initialize_drive_service()

    def _initialize_drive_service(self):
        """Google Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            if not os.path.exists(self.credentials_path):
                logger.error(f"Google Drive ì¸ì¦ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.credentials_path}")
                return False

            # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
            scopes = ['https://www.googleapis.com/auth/drive.readonly',
                      'https://www.googleapis.com/auth/drive.file']

            credentials = Credentials.from_service_account_file(
                self.credentials_path, scopes=scopes
            )

            self.service = build('drive', 'v3', credentials=credentials)
            self.is_connected = True

            logger.info("âœ… Google Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"âŒ Google Drive ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def download_file_content(self, file_id: str) -> Optional[str]:
        """Google Drive íŒŒì¼ ë‚´ìš© ë‹¤ìš´ë¡œë“œ"""
        if not self.is_connected:
            logger.warning("Google Driveì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        try:
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            file_metadata = self.service.files().get(fileId=file_id).execute()
            file_name = file_metadata.get('name', 'unknown')

            logger.info(f"ğŸ“ Google Drive íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {file_name}")

            # íŒŒì¼ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
            request = self.service.files().get_media(fileId=file_id)
            file_content = io.BytesIO()
            downloader = MediaIoBaseDownload(file_content, request)

            done = False
            while done is False:
                status, done = downloader.next_chunk()

            # í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”©
            file_content.seek(0)
            content = file_content.read().decode('utf-8')

            logger.info(f"âœ… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_name} ({len(content)}ì)")
            return content

        except Exception as e:
            logger.error(f"âŒ Google Drive íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    async def upload_analysis_result(self, content: str, filename: str, folder_id: Optional[str] = None) -> Optional[
        str]:
        """ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ Google Driveì— ì—…ë¡œë“œ"""
        if not self.is_connected:
            logger.warning("Google Driveì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        try:
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì„¤ì •
            file_metadata = {
                'name': filename,
                'parents': [folder_id] if folder_id else []
            }

            # íŒŒì¼ ë‚´ìš©ì„ BytesIOë¡œ ë³€í™˜
            media = MediaIoBaseUpload(
                io.BytesIO(content.encode('utf-8')),
                mimetype='text/plain'
            )

            # íŒŒì¼ ì—…ë¡œë“œ
            file = self.service.files().create(
                body=file_metadata,
                media_body=media,
                fields='id'
            ).execute()

            file_id = file.get('id')
            logger.info(f"âœ… ë¶„ì„ ê²°ê³¼ ì—…ë¡œë“œ ì™„ë£Œ: {filename} (ID: {file_id})")

            return file_id

        except Exception as e:
            logger.error(f"âŒ Google Drive ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    async def list_analysis_files(self, folder_id: Optional[str] = None) -> List[Dict[str, str]]:
        """ë¶„ì„ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        if not self.is_connected:
            return []

        try:
            query = "mimeType='text/plain'"
            if folder_id:
                query += f" and '{folder_id}' in parents"

            results = self.service.files().list(
                q=query,
                pageSize=50,
                fields="nextPageToken, files(id, name, modifiedTime, size)"
            ).execute()

            files = results.get('files', [])

            logger.info(f"ğŸ“ Google Driveì—ì„œ {len(files)}ê°œ ë¶„ì„ íŒŒì¼ ë°œê²¬")

            return files

        except Exception as e:
            logger.error(f"âŒ Google Drive íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []


class EmotionAnalyzer:
    """
    Whiff ì‹œí–¥ì¼ê¸° í…ìŠ¤íŠ¸ì˜ ê°ì • ë¶„ì„ ë° íƒœê·¸ ìƒì„± ì„œë¹„ìŠ¤ (Google Drive ì—°ë™)

    Features:
    - ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ + AI ëª¨ë¸ ì¤€ë¹„
    - Google Drive ì—°ë™ (ë¶„ì„ ê²°ê³¼ ì €ì¥/ë¡œë“œ)
    - 8ê°œ í•µì‹¬ ê°ì • ì§€ì›
    - í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™” í‚¤ì›Œë“œ
    - ì‹¤ì‹œê°„ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° Google Drive ë°±ì—…
    """

    def __init__(self, google_drive_credentials: Optional[str] = None):
        """ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” (Google Drive ì—°ë™)"""
        logger.info("ğŸ­ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘... (Google Drive ì—°ë™)")

        # Google Drive ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.gdrive_manager = GoogleDriveManager(google_drive_credentials)

        # ğŸ¯ ê°ì •ë³„ íƒœê·¸ ë§¤í•‘ (Google Driveì—ì„œ ë™ê¸°í™” ê°€ëŠ¥)
        self.emotion_to_tags = {
            "ê¸°ì¨": ["#joyful", "#bright", "#citrus", "#happy", "#cheerful"],
            "ë¶ˆì•ˆ": ["#nervous", "#sharp", "#spicy", "#anxious", "#tense"],
            "ë‹¹í™©": ["#confused", "#mild", "#powdery", "#surprised", "#bewildered"],
            "ë¶„ë…¸": ["#angry", "#hot", "#burntwood", "#intense", "#fiery"],
            "ìƒì²˜": ["#hurt", "#cool", "#woody", "#sad", "#melancholy"],
            "ìŠ¬í””": ["#sad", "#deep", "#musk", "#blue", "#tearful"],
            "ìš°ìš¸": ["#depressed", "#dark", "#leather", "#gloomy", "#heavy"],
            "í¥ë¶„": ["#excited", "#fresh", "#green", "#energetic", "#vibrant"]
        }

        # ğŸ” ë£° ê¸°ë°˜ ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ (í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™”)
        self.emotion_keywords = {
            "ê¸°ì¨": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "ì¢‹ì•„", "í–‰ë³µ", "ê¸°ë»", "ì¦ê±°ì›Œ", "ë§Œì¡±", "ì™„ë²½", "ìµœê³ ", "ì‚¬ë‘",
                # í–¥ìˆ˜ ê´€ë ¨ ê¸ì • í‘œí˜„
                "ìƒì¾Œ", "ë°ì€", "í™”ì‚¬", "ì‹±ê·¸ëŸ¬ìš´", "ìƒí¼", "ë‹¬ì½¤", "í¬ê·¼", "ë”°ëœ»",
                "ì‚¬ë‘ìŠ¤ëŸ¬ìš´", "ì˜ˆìœ", "ê³ ê¸‰ìŠ¤ëŸ¬ìš´", "ìš°ì•„í•œ", "ì„¸ë ¨ëœ", "ë§¤ë ¥ì ",
                # ê°ê°ì  í‘œí˜„
                "ë¶€ë“œëŸ¬ìš´", "ì€ì€í•œ", "ê¹”ë”í•œ", "ê¹¨ë—í•œ", "ì²­ëŸ‰í•œ", "ì‹œì›í•œ"
            ],
            "ë¶ˆì•ˆ": [
                "ë¶ˆì•ˆ", "ê±±ì •", "ê¸´ì¥", "ë–¨ë ¤", "ë‘ë ¤ìš´", "ë¬´ì„œìš´", "ì¡°ë§ˆì¡°ë§ˆ",
                "ì–´ìƒ‰", "ë¶€ë‹´", "ì••ë°•", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆí¸", "ì–´ìƒ‰í•´",
                "ì´ìƒí•´", "ì–´ìƒ‰í•œ", "ë‹µë‹µ", "ë¬´ê±°ìš´"
            ],
            "ë‹¹í™©": [
                "ë‹¹í™©", "ë†€ë€", "í˜¼ë€", "ì–´ë¦¬ë‘¥ì ˆ", "ë©í•œ", "ëª¨ë¥´ê² ë‹¤", "í—·ê°ˆë ¤",
                "ì´ìƒ", "ì˜ˆìƒê³¼ ë‹¬ë¼", "ì˜ì™¸", "ì‹ ê¸°", "íŠ¹ì´", "ë…íŠ¹",
                "ì˜ˆìƒëª»í•œ", "ëœ»ë°–ì˜", "ê°‘ì‘ìŠ¤ëŸ¬ìš´"
            ],
            "ë¶„ë…¸": [
                "í™”ê°€", "ì§œì¦", "ì—´ë°›", "ë¶„ë…¸", "ê²©ì •", "ì‹«ì–´", "ë³„ë¡œ", "ìµœì•…",
                "ìê·¹ì ", "ê°•ë ¬", "ê³¼í•´", "ë¶€ë‹´ìŠ¤ëŸ¬ì›Œ", "ë…í•´", "ì—­ê²¨ìš´",
                "ë”ì°", "ëª»ì°¸ê² ", "ê²¬ë”œìˆ˜ì—†", "ê·¹í˜"
            ],
            "ìƒì²˜": [
                "ìƒì²˜", "ì•„í”ˆ", "ì„œìš´", "ì‹¤ë§", "ì•„ì‰¬ì›Œ", "ìŠ¬í”ˆ", "í˜ë“ ",
                "ì„­ì„­", "ë§ˆìŒì•„í”ˆ", "ì“¸ì“¸", "ê·¸ë¦¬ìš´", "ê·¸ë¦½", "ì• í‹‹", "ì•ˆíƒ€ê¹Œìš´", "ì•„ë ¨í•œ"
            ],
            "ìŠ¬í””": [
                "ìŠ¬í¼", "ëˆˆë¬¼", "ì• ì ˆ", "ì²˜ëŸ‰", "ê³ ë…", "ì™¸ë¡œìš´", "ì“¸ì“¸",
                "ë¨¹ë¨¹", "ì°¡í•œ", "ìš¸ì»¥", "ì§„í•œ", "ê¹Šì€", "ì°¨ê°€ìš´", "ë¬´ê±°ìš´", "ì¹¨ìš¸í•œ", "ì•”ìš¸í•œ"
            ],
            "ìš°ìš¸": [
                "ìš°ìš¸", "ë‹µë‹µ", "ë¬´ê¸°ë ¥", "ì ˆë§", "ì–´ë‘ ", "ì¹¨ìš¸", "ë©œë‘ì½œë¦¬",
                "ë¸”ë£¨", "ê·¸ëŠ˜ì§„", "ì–´ë‘ìš´", "ë§‰ë§‰í•œ", "ì ˆë§ì ", "í¬ë§ì—†ëŠ”", "ì˜ìš•ì—†ëŠ”", "ê³µí—ˆí•œ"
            ],
            "í¥ë¶„": [
                "í¥ë¶„", "ì‹ ë‚˜", "ë‘ê·¼", "ì„¤ë ˜", "í™œê¸°", "ìƒë™ê°", "ì—ë„ˆì§€",
                "í™œë°œ", "ì—­ë™ì ", "í„ë–¡", "í†¡í†¡", "íŒ¡íŒ¡", "ìƒìƒí•œ", "í™œë ¥", "ì Šì€", "ë°œë„í•œ"
            ]
        }

        # ğŸŒ¸ í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™” ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ
        self.perfume_context_keywords = {
            "positive_intensity": {
                "mild": ["ì€ì€", "ë¶€ë“œëŸ¬ìš´", "ê°€ë²¼ìš´", "ì‚´ì§", "ì€ê·¼"],
                "medium": ["ì ë‹¹", "ê´œì°®ì€", "ë¬´ë‚œí•œ", "ê· í˜•ì¡íŒ"],
                "strong": ["ì§„í•œ", "ê°•í•œ", "ê¹Šì€", "í’ë¶€í•œ", "ë†ì¶•ëœ"]
            },
            "positive_quality": [
                "ì¢‹ì•„", "ë§ˆìŒì— ë“¤ì–´", "í–¥ì´ ì¢‹ì•„", "ì˜ˆë»", "ê³ ê¸‰ìŠ¤ëŸ¬ì›Œ", "ìš°ì•„í•´",
                "ì„¸ë ¨ëœ", "ë§¤ë ¥ì ", "í¬ê·¼í•´", "ë”°ëœ»í•´", "ì‹œì›í•´", "ì²­ëŸ‰í•´", "ìƒí¼í•´",
                "ë‹¬ì½¤í•´", "ë¶€ë“œëŸ¬ì›Œ", "ì€ì€í•´", "ê¹”ë”í•´", "ê¹¨ë—í•´", "fresh", "nice"
            ],
            "negative_quality": [
                "ì‹«ì–´", "ë³„ë¡œ", "ì•„ì‰¬ì›Œ", "ì´ìƒí•´", "ì–´ìƒ‰í•´", "ë¶€ë‹´ìŠ¤ëŸ¬ì›Œ", "ê³¼í•´",
                "ë‹¨ì¡°ë¡œì›Œ", "ë°‹ë°‹í•´", "ë…í•´", "ìê·¹ì ", "ì—­ê²¨ìš´", "ë”ì°"
            ],
            "intensity_negative": [
                "ì§„í•´", "ì•½í•´", "ì„¸", "ê°•í•´", "ë…í•´", "ìê·¹ì ", "ì••ë„ì "
            ],
            "temporal_context": [
                "ì²˜ìŒ", "ì²«", "ë‚˜ì¤‘", "ì‹œê°„ì§€ë‚˜", "ì§€ì†", "ë³€í™”", "ë°”ë€Œ"
            ]
        }

        # ğŸ¯ ëª¨ë¸ ìƒíƒœ ê´€ë¦¬
        self.model_loaded = False
        self.model = None
        self.tokenizer = None
        self.model_version = "v2_gdrive"  # Google Drive ì—°ë™ ë²„ì „
        self.analysis_count = 0

        # ğŸ“Š ì„±ëŠ¥ í†µê³„ (Google Drive ë°±ì—…)
        self.performance_stats = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "average_response_time": 0.0,
            "method_distribution": {"rule_based": 0, "ai_model": 0},
            "confidence_distribution": {"high": 0, "medium": 0, "low": 0},
            "gdrive_operations": {"uploads": 0, "downloads": 0, "sync_failures": 0}
        }

        # ğŸ”„ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ (Google Drive ë™ê¸°í™”)
        self.learning_data = []
        self.last_gdrive_sync = None
        self.sync_interval = timedelta(hours=1)  # 1ì‹œê°„ë§ˆë‹¤ ë™ê¸°í™”

        # ğŸš€ ì´ˆê¸°í™” ì™„ë£Œ
        logger.info("âœ… ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (Google Drive ì—°ë™)")
        logger.info(f"  - ì§€ì› ê°ì •: {list(self.emotion_to_tags.keys())}")
        logger.info(f"  - ëª¨ë¸ ë²„ì „: {self.model_version}")
        logger.info(f"  - Google Drive ì—°ê²°: {'âœ…' if self.gdrive_manager.is_connected else 'âŒ'}")
        logger.info(f"  - ì´ í‚¤ì›Œë“œ: {sum(len(keywords) for keywords in self.emotion_keywords.values())}ê°œ")

    async def analyze_emotion(self, text: str, use_model: bool = True, save_to_gdrive: bool = False) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ (Google Drive ì—°ë™)

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            use_model: AI ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
            save_to_gdrive: Google Driveì— ê²°ê³¼ ì €ì¥ ì—¬ë¶€

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        self.analysis_count += 1

        logger.info(f"ğŸ­ ê°ì • ë¶„ì„ ì‹œì‘ (#{self.analysis_count})")
        logger.info(f"  - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
        logger.info(f"  - ëª¨ë¸ ì‚¬ìš©: {'âœ…' if use_model else 'âŒ'}")
        logger.info(f"  - Google Drive ì €ì¥: {'âœ…' if save_to_gdrive else 'âŒ'}")

        # ì…ë ¥ ê²€ì¦
        if not text or not text.strip():
            return self._create_empty_result()

        if len(text) > 2000:
            logger.warning(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤: {len(text)}ì")
            return self._create_error_result("text_too_long", "í…ìŠ¤íŠ¸ê°€ 2000ìë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")

        try:
            # ğŸ¤– AI ëª¨ë¸ ë¶„ì„ ì‹œë„ (ê°œë°œ ì™„ë£Œ í›„)
            result = None
            if use_model and self._is_model_available():
                try:
                    logger.info(f"ğŸ¤– AI ëª¨ë¸ v{self.model_version} ë¶„ì„ ì‹œì‘...")
                    result = await self._analyze_with_model(text)

                    if result.get("success"):
                        logger.info(f"âœ… AI ëª¨ë¸ ë¶„ì„ ì™„ë£Œ")
                    else:
                        logger.warning("âš ï¸ AI ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨, ë£° ê¸°ë°˜ìœ¼ë¡œ í´ë°±")
                        result = None

                except Exception as e:
                    logger.error(f"âŒ AI ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
                    result = None

            # ğŸ“‹ ë£° ê¸°ë°˜ ë¶„ì„ (í´ë°± ë˜ëŠ” ê¸°ë³¸)
            if result is None:
                logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ ì‹œì‘...")
                result = await self._analyze_with_rules(text)

            # â±ï¸ ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            response_time = time.time() - start_time
            result["processing_time"] = round(response_time, 3)

            # ğŸ“Š ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
            self._update_performance_stats(result, response_time)

            # ğŸ“š í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
            await self._collect_learning_data(text, result)

            # ğŸ’¾ Google Drive ì €ì¥
            if save_to_gdrive and result.get("success"):
                await self._save_result_to_gdrive(text, result)

            # ğŸ”„ ì •ê¸° ë™ê¸°í™” í™•ì¸
            await self._check_and_sync_gdrive()

            logger.info(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {response_time:.3f}ì´ˆ)")
            logger.info(f"  - ê°ì •: {result.get('primary_emotion')}")
            logger.info(f"  - ì‹ ë¢°ë„: {result.get('confidence', 0):.3f}")

            return result

        except Exception as e:
            logger.error(f"âŒ ê°ì • ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return self._create_error_result("analysis_exception", str(e))

    async def sync_with_gdrive(self, force: bool = False) -> Dict[str, Any]:
        """Google Driveì™€ ìˆ˜ë™ ë™ê¸°í™”"""
        if not self.gdrive_manager.is_connected:
            return {"success": False, "message": "Google Driveì— ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

        try:
            sync_start = time.time()
            logger.info("ğŸ”„ Google Drive ë™ê¸°í™” ì‹œì‘...")

            # 1. ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ ë™ê¸°í™”
            keywords_synced = await self._sync_emotion_keywords()

            # 2. ì„±ëŠ¥ í†µê³„ ë°±ì—…
            stats_backed_up = await self._backup_performance_stats()

            # 3. í•™ìŠµ ë°ì´í„° ë™ê¸°í™”
            learning_data_synced = await self._sync_learning_data()

            sync_time = time.time() - sync_start
            self.last_gdrive_sync = datetime.now()

            result = {
                "success": True,
                "sync_time": round(sync_time, 3),
                "operations": {
                    "keywords_synced": keywords_synced,
                    "stats_backed_up": stats_backed_up,
                    "learning_data_synced": learning_data_synced
                },
                "last_sync": self.last_gdrive_sync.isoformat()
            }

            logger.info(f"âœ… Google Drive ë™ê¸°í™” ì™„ë£Œ (ì†Œìš”ì‹œê°„: {sync_time:.3f}ì´ˆ)")
            return result

        except Exception as e:
            self.performance_stats["gdrive_operations"]["sync_failures"] += 1
            logger.error(f"âŒ Google Drive ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return {"success": False, "message": str(e)}

    async def load_emotion_keywords_from_gdrive(self, file_id: str) -> bool:
        """Google Driveì—ì„œ ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ ë¡œë“œ"""
        try:
            content = await self.gdrive_manager.download_file_content(file_id)
            if content:
                keywords_data = json.loads(content)
                self.emotion_keywords.update(keywords_data)
                logger.info(f"âœ… Google Driveì—ì„œ ê°ì • í‚¤ì›Œë“œ ë¡œë“œ ì™„ë£Œ")
                return True
        except Exception as e:
            logger.error(f"âŒ Google Drive í‚¤ì›Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

    async def analyze_gdrive_document(self, file_id: str) -> Dict[str, Any]:
        """Google Drive ë¬¸ì„œ ê°ì • ë¶„ì„"""
        try:
            # ë¬¸ì„œ ë‚´ìš© ë‹¤ìš´ë¡œë“œ
            content = await self.gdrive_manager.download_file_content(file_id)
            if not content:
                return self._create_error_result("gdrive_download_failed", "Google Drive ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

            # ê°ì • ë¶„ì„ ìˆ˜í–‰
            result = await self.analyze_emotion(content, save_to_gdrive=True)

            # ë¬¸ì„œ ì •ë³´ ì¶”ê°€
            result["source"] = "google_drive"
            result["file_id"] = file_id

            logger.info(f"âœ… Google Drive ë¬¸ì„œ ë¶„ì„ ì™„ë£Œ: {file_id}")
            return result

        except Exception as e:
            logger.error(f"âŒ Google Drive ë¬¸ì„œ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return self._create_error_result("gdrive_analysis_failed", str(e))

    async def batch_analyze_gdrive_folder(self, folder_id: str, max_files: int = 10) -> List[Dict[str, Any]]:
        """Google Drive í´ë” ë‚´ ë¬¸ì„œë“¤ ì¼ê´„ ë¶„ì„"""
        if not self.gdrive_manager.is_connected:
            return []

        try:
            logger.info(f"ğŸ“ Google Drive í´ë” ì¼ê´„ ë¶„ì„ ì‹œì‘: {folder_id}")

            # í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
            files = await self.gdrive_manager.list_analysis_files(folder_id)
            files = files[:max_files]  # ìµœëŒ€ íŒŒì¼ ìˆ˜ ì œí•œ

            results = []
            for file_info in files:
                file_id = file_info['id']
                file_name = file_info['name']

                logger.info(f"ğŸ“„ ë¶„ì„ ì¤‘: {file_name}")

                # ê°œë³„ íŒŒì¼ ë¶„ì„
                analysis_result = await self.analyze_gdrive_document(file_id)
                analysis_result["file_name"] = file_name

                results.append(analysis_result)

                # ê³¼ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì ì‹œ ëŒ€ê¸°
                await asyncio.sleep(0.5)

            logger.info(f"âœ… í´ë” ì¼ê´„ ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ íŒŒì¼")
            return results

        except Exception as e:
            logger.error(f"âŒ Google Drive í´ë” ì¼ê´„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return []

    # ========================= Private Methods =========================

    def _is_model_available(self) -> bool:
        """AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return self.model_loaded and self.model is not None

    async def _analyze_with_model(self, text: str) -> Dict[str, Any]:
        """AI ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì • ë¶„ì„ (ë¯¸ë˜ êµ¬í˜„)"""
        try:
            await asyncio.sleep(0.05)  # ëª¨ë¸ ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜
            return {
                "success": False,
                "reason": "model_under_development",
                "message": f"AI ëª¨ë¸ v{self.model_version}ëŠ” í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤."
            }
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜: {e}")
            return {"success": False, "reason": "model_error", "message": str(e)}

    async def _analyze_with_rules(self, text: str) -> Dict[str, Any]:
        """ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ (í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™”)"""
        try:
            text_lower = text.lower().strip()
            text_words = text.split()

            # ğŸ” 1ë‹¨ê³„: ê¸°ë³¸ ê°ì • í‚¤ì›Œë“œ ë§¤ì¹­
            emotion_scores = {}
            keyword_matches = {}
            total_keywords_found = 0

            for emotion, keywords in self.emotion_keywords.items():
                score = 0
                matched_keywords = []

                for keyword in keywords:
                    pattern = r'\b' + re.escape(keyword) + r'\b'
                    matches = len(re.findall(pattern, text_lower))

                    if matches > 0:
                        weight = self._get_keyword_weight(keyword, emotion)
                        score += matches * weight
                        matched_keywords.extend([keyword] * matches)
                        total_keywords_found += matches

                if score > 0:
                    emotion_scores[emotion] = score
                    keyword_matches[emotion] = matched_keywords

            # ğŸŒ¸ 2ë‹¨ê³„: í–¥ìˆ˜ ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ ë³´ì •
            context_boost = self._analyze_perfume_context(text_lower, text_words)

            for emotion, boost in context_boost.items():
                if emotion in emotion_scores:
                    emotion_scores[emotion] += boost
                elif boost > 0.5:
                    emotion_scores[emotion] = boost
                    keyword_matches[emotion] = ["context_boost"]

            # ğŸ“Š 3ë‹¨ê³„: ê²°ê³¼ ê³„ì‚° ë° ì •ê·œí™”
            if emotion_scores:
                normalization_factor = max(len(text_words), 1)
                normalized_scores = {}

                for emotion, score in emotion_scores.items():
                    normalized_score = min(score / normalization_factor * 1.5, 1.0)
                    normalized_scores[emotion] = normalized_score

                primary_emotion = max(normalized_scores.keys(), key=lambda x: normalized_scores[x])
                confidence = normalized_scores[primary_emotion]

                confidence_boost = min(total_keywords_found * 0.1, 0.3)
                final_confidence = min(confidence + confidence_boost, 1.0)

                emotion_tags = self.emotion_to_tags.get(primary_emotion, ["#neutral"])

                return {
                    "success": True,
                    "method": "rule_based",
                    "primary_emotion": primary_emotion,
                    "confidence": round(final_confidence, 3),
                    "emotion_tags": emotion_tags,
                    "analysis_details": {
                        "raw_scores": emotion_scores,
                        "normalized_scores": normalized_scores,
                        "keyword_matches": keyword_matches,
                        "context_boost": context_boost,
                        "total_keywords": total_keywords_found,
                        "text_length": len(text),
                        "word_count": len(text_words)
                    },
                    "analyzed_at": datetime.now().isoformat(),
                    "analyzer_version": "rule_based_gdrive_v1.3"
                }
            else:
                return self._create_neutral_result("no_emotion_keywords")

        except Exception as e:
            logger.error(f"âŒ ë£° ê¸°ë°˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_error_result("rule_analysis_error", str(e))

    def _get_keyword_weight(self, keyword: str, emotion: str) -> float:
        """í‚¤ì›Œë“œ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        high_weight_keywords = {
            "ê¸°ì¨": ["ì¢‹ì•„", "í–‰ë³µ", "ì‚¬ë‘", "ì™„ë²½", "ìµœê³ "],
            "ë¶ˆì•ˆ": ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤ìš´", "ë¶€ë‹´"],
            "ë‹¹í™©": ["ë‹¹í™©", "ë†€ë€", "í˜¼ë€", "ì˜ì™¸"],
            "ë¶„ë…¸": ["í™”ê°€", "ì§œì¦", "ì‹«ì–´", "ìµœì•…"],
            "ìƒì²˜": ["ìƒì²˜", "ì•„í”ˆ", "ì‹¤ë§", "ê·¸ë¦¬ìš´"],
            "ìŠ¬í””": ["ìŠ¬í¼", "ëˆˆë¬¼", "ì™¸ë¡œìš´", "ì“¸ì“¸"],
            "ìš°ìš¸": ["ìš°ìš¸", "ì ˆë§", "ë¬´ê¸°ë ¥", "ì–´ë‘ "],
            "í¥ë¶„": ["í¥ë¶„", "ì‹ ë‚˜", "ì„¤ë ˜", "ì—ë„ˆì§€"]
        }

        if keyword in high_weight_keywords.get(emotion, []):
            return 1.5
        elif len(keyword) >= 3:
            return 1.2
        else:
            return 1.0

    def _analyze_perfume_context(self, text_lower: str, text_words: List[str]) -> Dict[str, float]:
        """í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        context_boost = {}

        positive_quality_count = sum(text_lower.count(kw) for kw in self.perfume_context_keywords["positive_quality"])
        negative_quality_count = sum(text_lower.count(kw) for kw in self.perfume_context_keywords["negative_quality"])
        intensity_negative_count = sum(
            text_lower.count(kw) for kw in self.perfume_context_keywords["intensity_negative"])

        if positive_quality_count > 0:
            boost_strength = min(positive_quality_count * 0.8, 2.0)
            context_boost["ê¸°ì¨"] = boost_strength
            if positive_quality_count >= 2:
                context_boost["í¥ë¶„"] = boost_strength * 0.6

        if negative_quality_count > 0:
            boost_strength = min(negative_quality_count * 0.7, 1.8)
            if negative_quality_count >= 2:
                context_boost["ë¶„ë…¸"] = boost_strength
            else:
                context_boost["ìƒì²˜"] = boost_strength * 0.8

        if intensity_negative_count > 0:
            boost_strength = min(intensity_negative_count * 0.6, 1.5)
            context_boost["ë¶ˆì•ˆ"] = boost_strength

        temporal_keywords = ["ì²˜ìŒ", "ì²«", "ë‚˜ì¤‘", "ì‹œê°„ì§€ë‚˜", "ë³€í™”"]
        temporal_count = sum(text_lower.count(kw) for kw in temporal_keywords)
        if temporal_count > 0:
            context_boost["ë‹¹í™©"] = min(temporal_count * 0.5, 1.0)

        return context_boost

    def _create_empty_result(self) -> Dict[str, Any]:
        """ë¹ˆ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê²°ê³¼"""
        return {
            "success": True,
            "method": "validation",
            "primary_emotion": "ì¤‘ë¦½",
            "confidence": 0.0,
            "emotion_tags": ["#neutral"],
            "reason": "empty_text",
            "message": "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.",
            "analyzed_at": datetime.now().isoformat()
        }

    def _create_neutral_result(self, reason: str) -> Dict[str, Any]:
        """ì¤‘ë¦½ ê°ì • ê²°ê³¼"""
        return {
            "success": True,
            "method": "rule_based",
            "primary_emotion": "ì¤‘ë¦½",
            "confidence": 0.3,
            "emotion_tags": ["#neutral", "#calm"],
            "reason": reason,
            "message": "ëª…í™•í•œ ê°ì • ì‹ í˜¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "analyzed_at": datetime.now().isoformat()
        }

    def _create_error_result(self, error_type: str, message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼"""
        return {
            "success": False,
            "error_type": error_type,
            "message": message,
            "primary_emotion": "ì˜¤ë¥˜",
            "confidence": 0.0,
            "emotion_tags": ["#error"],
            "analyzed_at": datetime.now().isoformat()
        }

    def _update_performance_stats(self, result: Dict[str, Any], response_time: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.performance_stats["total_analyses"] += 1

        if result.get("success"):
            self.performance_stats["successful_analyses"] += 1

            method = result.get("method", "unknown")
            if method in self.performance_stats["method_distribution"]:
                self.performance_stats["method_distribution"][method] += 1

            confidence = result.get("confidence", 0.0)
            if confidence >= 0.7:
                self.performance_stats["confidence_distribution"]["high"] += 1
            elif confidence >= 0.4:
                self.performance_stats["confidence_distribution"]["medium"] += 1
            else:
                self.performance_stats["confidence_distribution"]["low"] += 1

        total_time = (self.performance_stats["average_response_time"] *
                      (self.performance_stats["total_analyses"] - 1) + response_time)
        self.performance_stats["average_response_time"] = total_time / self.performance_stats["total_analyses"]

    async def _collect_learning_data(self, text: str, result: Dict[str, Any]):
        """í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘"""
        if result.get("success"):
            learning_item = {
                "timestamp": datetime.now().isoformat(),
                "text": text[:200],  # ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ ì œí•œ
                "emotion": result.get("primary_emotion"),
                "confidence": result.get("confidence"),
                "method": result.get("method"),
                "processing_time": result.get("processing_time")
            }
            self.learning_data.append(learning_item)

            # ë©”ëª¨ë¦¬ ê´€ë¦¬: ìµœëŒ€ 1000ê°œ í•­ëª© ìœ ì§€
            if len(self.learning_data) > 1000:
                self.learning_data = self.learning_data[-1000:]

    async def _save_result_to_gdrive(self, text: str, result: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ë¥¼ Google Driveì— ì €ì¥"""
        if not self.gdrive_manager.is_connected:
            return

        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"emotion_analysis_{timestamp}.json"

            save_data = {
                "analysis_result": result,
                "original_text": text[:500],  # í…ìŠ¤íŠ¸ ì¼ë¶€ë§Œ ì €ì¥
                "timestamp": datetime.now().isoformat(),
                "analyzer_version": self.model_version
            }

            content = json.dumps(save_data, ensure_ascii=False, indent=2)

            file_id = await self.gdrive_manager.upload_analysis_result(content, filename)
            if file_id:
                self.performance_stats["gdrive_operations"]["uploads"] += 1
                logger.info(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ Google Drive ì €ì¥ ì™„ë£Œ: {filename}")

        except Exception as e:
            logger.error(f"âŒ Google Drive ì €ì¥ ì‹¤íŒ¨: {e}")

    async def _check_and_sync_gdrive(self):
        """ì •ê¸° Google Drive ë™ê¸°í™” í™•ì¸"""
        if not self.gdrive_manager.is_connected:
            return

        now = datetime.now()
        if (self.last_gdrive_sync is None or
                now - self.last_gdrive_sync > self.sync_interval):
            logger.info("ğŸ”„ ì •ê¸° Google Drive ë™ê¸°í™” ì‹¤í–‰...")
            await self.sync_with_gdrive()

    async def _sync_emotion_keywords(self) -> bool:
        """ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ Google Drive ë™ê¸°í™”"""
        try:
            filename = f"emotion_keywords_{datetime.now().strftime('%Y%m%d')}.json"
            content = json.dumps(self.emotion_keywords, ensure_ascii=False, indent=2)

            file_id = await self.gdrive_manager.upload_analysis_result(content, filename)
            return file_id is not None

        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def _backup_performance_stats(self) -> bool:
        """ì„±ëŠ¥ í†µê³„ Google Drive ë°±ì—…"""
        try:
            filename = f"performance_stats_{datetime.now().strftime('%Y%m%d')}.json"
            content = json.dumps(self.performance_stats, ensure_ascii=False, indent=2)

            file_id = await self.gdrive_manager.upload_analysis_result(content, filename)
            return file_id is not None

        except Exception as e:
            logger.error(f"âŒ ì„±ëŠ¥ í†µê³„ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False

    async def _sync_learning_data(self) -> bool:
        """í•™ìŠµ ë°ì´í„° Google Drive ë™ê¸°í™”"""
        if not self.learning_data:
            return True

        try:
            filename = f"learning_data_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
            content = json.dumps(self.learning_data, ensure_ascii=False, indent=2)

            file_id = await self.gdrive_manager.upload_analysis_result(content, filename)
            if file_id:
                self.learning_data.clear()  # ë™ê¸°í™” í›„ ë©”ëª¨ë¦¬ ì •ë¦¬
                return True

        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨: {e}")

        return False

    # ========================= Public Utility Methods =========================

    def get_supported_emotions(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” ê°ì • ëª©ë¡ ë°˜í™˜"""
        return list(self.emotion_to_tags.keys())

    def get_emotion_tags(self, emotion: str) -> List[str]:
        """íŠ¹ì • ê°ì •ì˜ íƒœê·¸ ëª©ë¡ ë°˜í™˜"""
        return self.emotion_to_tags.get(emotion, ["#neutral"])

    def get_gdrive_status(self) -> Dict[str, Any]:
        """Google Drive ì—°ê²° ìƒíƒœ ë°˜í™˜"""
        return {
            "connected": self.gdrive_manager.is_connected,
            "last_sync": self.last_gdrive_sync.isoformat() if self.last_gdrive_sync else None,
            "sync_interval_hours": self.sync_interval.total_seconds() / 3600,
            "operations": self.performance_stats["gdrive_operations"],
            "learning_data_count": len(self.learning_data)
        }

    def get_analysis_stats(self) -> Dict[str, Any]:
        """ë¶„ì„ ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´ (Google Drive í¬í•¨)"""
        success_rate = 0.0
        if self.performance_stats["total_analyses"] > 0:
            success_rate = (self.performance_stats["successful_analyses"] /
                            self.performance_stats["total_analyses"] * 100)

        return {
            "model_loaded": self.model_loaded,
            "model_version": self.model_version,
            "supported_emotions": len(self.emotion_to_tags),
            "total_keywords": sum(len(keywords) for keywords in self.emotion_keywords.values()),
            "analysis_methods": ["rule_based"] + (["ai_model"] if self.model_loaded else []),

            "performance": {
                "total_analyses": self.performance_stats["total_analyses"],
                "successful_analyses": self.performance_stats["successful_analyses"],
                "success_rate": round(success_rate, 2),
                "average_response_time": round(self.performance_stats["average_response_time"], 3),
                "method_distribution": self.performance_stats["method_distribution"],
                "confidence_distribution": self.performance_stats["confidence_distribution"]
            },

            "google_drive": self.get_gdrive_status(),

            "emotion_list": list(self.emotion_to_tags.keys()),
            "emotion_tags_count": {emotion: len(tags) for emotion, tags in self.emotion_to_tags.items()},

            "system_info": {
                "max_text_length": 2000,
                "supported_languages": ["í•œêµ­ì–´"],
                "domain_specialization": "í–¥ìˆ˜_ë¦¬ë·°",
                "features": ["Google Drive ì—°ë™", "ì‹¤ì‹œê°„ í•™ìŠµ", "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"],
                "last_updated": datetime.now().isoformat()
            }
        }


# ğŸŒŸ ì „ì—­ ê°ì • ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤ (Google Drive ì—°ë™)
emotion_analyzer = EmotionAnalyzer(
    google_drive_credentials=os.getenv('GOOGLE_DRIVE_CREDENTIALS_PATH')
)


# ğŸ§ª í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_emotion_analyzer_with_gdrive():
    """Google Drive ì—°ë™ ê°ì • ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Google Drive ì—°ë™ ê°ì • ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘...\n")

    test_cases = [
        "ì´ í–¥ìˆ˜ ì •ë§ ì¢‹ì•„ìš”! ë‹¬ì½¤í•˜ê³  ìƒí¼í•´ì„œ ê¸°ë¶„ì´ ì¢‹ì•„ì ¸ìš”.",
        "í–¥ì´ ë„ˆë¬´ ì§„í•´ì„œ ë³„ë¡œì˜ˆìš”. ì¢€ ë¶€ë‹´ìŠ¤ëŸ½ë„¤ìš”.",
        "ì²˜ìŒ ë§¡ì•˜ì„ ë•Œ ë†€ëì–´ìš”. ì˜ˆìƒê³¼ ì™„ì „ ë‹¬ë¼ì„œ ë‹¹í™©ìŠ¤ëŸ¬ì› ì–´ìš”.",
    ]

    for i, text in enumerate(test_cases, 1):
        print(f"--- í…ŒìŠ¤íŠ¸ {i} ---")
        print(f"ì…ë ¥: {text}")

        result = await emotion_analyzer.analyze_emotion(text, save_to_gdrive=True)

        print(f"ê²°ê³¼: {result['primary_emotion']} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
        print(f"íƒœê·¸: {result['emotion_tags']}")
        print(f"ë°©ë²•: {result['method']}")
        print(f"ì²˜ë¦¬ì‹œê°„: {result.get('processing_time', 0):.3f}ì´ˆ")
        print()

    # Google Drive ìƒíƒœ í™•ì¸
    gdrive_status = emotion_analyzer.get_gdrive_status()
    print("ğŸ”„ Google Drive ìƒíƒœ:")
    print(f"  ì—°ê²°ë¨: {gdrive_status['connected']}")
    print(f"  ë§ˆì§€ë§‰ ë™ê¸°í™”: {gdrive_status['last_sync']}")
    print(f"  ì—…ë¡œë“œ íšŸìˆ˜: {gdrive_status['operations']['uploads']}")
    print()

    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(test_emotion_analyzer_with_gdrive())