# utils/emotion_analyzer.py - Whiff ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ

import re
import logging
import json
import os
import asyncio
import time
from typing import List, Dict, Tuple, Optional, Union, Any
from datetime import datetime
from collections import Counter
import numpy as np

logger = logging.getLogger(__name__)


class EmotionAnalyzer:
    """
    Whiff ì‹œí–¥ì¼ê¸° í…ìŠ¤íŠ¸ì˜ ê°ì • ë¶„ì„ ë° íƒœê·¸ ìƒì„± ì„œë¹„ìŠ¤

    Features:
    - ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ (í˜„ì¬ ë²„ì „)
    - AI ëª¨ë¸ v2 ì¤€ë¹„ êµ¬ì¡°
    - 8ê°œ í•µì‹¬ ê°ì • ì§€ì›
    - í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™” í‚¤ì›Œë“œ
    - í´ë°± ë©”ì»¤ë‹ˆì¦˜
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    """

    def __init__(self):
        """ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        logger.info("ğŸ­ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì‹œì‘...")

        # ğŸ¯ ê°ì •ë³„ íƒœê·¸ ë§¤í•‘ (ì´ˆê¸° ëª¨ë¸ ë²„ì „ - í™•ì¥ ê°€ëŠ¥)
        self.emotion_to_tags = {
            "ê¸°ì¨": ["#joyful", "#bright", "#citrus", "#happy", "#cheerful"],
            "ë¶ˆì•ˆ": ["#nervous", "#sharp", "#spicy", "#anxious", "#tense"],
            "ë‹¹í™©": ["#confused", "#mild", "#powdery", "#surprised", "#bewildered"],
            "ë¶„ë…¸": ["#angry", "#hot", "#burntwood", "#intense", "#fiery"],
            "ìƒì²˜": ["#hurt", "#cool", "#woody", "#sad", "#melancholy"],
            "ìŠ¬í””": ["#sad", "#deep", "#musk", "#blue", "#tearful"],
            "ìš°ìš¸": ["#depressed", "#dark", "#leather", "#gloomy", "#heavy"],
            "í¥ë¶„": ["#excited", "#fresh", "#green", "#energetic", "#vibrant"]
        }

        # ğŸ” ë£° ê¸°ë°˜ ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ (í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™”)
        self.emotion_keywords = {
            "ê¸°ì¨": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "ì¢‹ì•„", "í–‰ë³µ", "ê¸°ë»", "ì¦ê±°ì›Œ", "ë§Œì¡±", "ì™„ë²½", "ìµœê³ ", "ì‚¬ë‘",
                # í–¥ìˆ˜ ê´€ë ¨ ê¸ì • í‘œí˜„
                "ìƒì¾Œ", "ë°ì€", "í™”ì‚¬", "ì‹±ê·¸ëŸ¬ìš´", "ìƒí¼", "ë‹¬ì½¤", "í¬ê·¼", "ë”°ëœ»",
                "ì‚¬ë‘ìŠ¤ëŸ¬ìš´", "ì˜ˆìœ", "ê³ ê¸‰ìŠ¤ëŸ¬ìš´", "ìš°ì•„í•œ", "ì„¸ë ¨ëœ", "ë§¤ë ¥ì ",
                # ê°ê°ì  í‘œí˜„
                "ë¶€ë“œëŸ¬ìš´", "ì€ì€í•œ", "ê¹”ë”í•œ", "ê¹¨ë—í•œ", "ì²­ëŸ‰í•œ", "ì‹œì›í•œ"
            ],
            "ë¶ˆì•ˆ": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "ë¶ˆì•ˆ", "ê±±ì •", "ê¸´ì¥", "ë–¨ë ¤", "ë‘ë ¤ìš´", "ë¬´ì„œìš´", "ì¡°ë§ˆì¡°ë§ˆ",
                # í–¥ìˆ˜ ê´€ë ¨ ë¶€ì • í‘œí˜„
                "ì–´ìƒ‰", "ë¶€ë‹´", "ì••ë°•", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆí¸", "ì–´ìƒ‰í•´",
                "ì´ìƒí•´", "ì–´ìƒ‰í•œ", "ë‹µë‹µ", "ë¬´ê±°ìš´"
            ],
            "ë‹¹í™©": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "ë‹¹í™©", "ë†€ë€", "í˜¼ë€", "ì–´ë¦¬ë‘¥ì ˆ", "ë©í•œ", "ëª¨ë¥´ê² ë‹¤", "í—·ê°ˆë ¤",
                # ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê²½í—˜
                "ì´ìƒ", "ì˜ˆìƒê³¼ ë‹¬ë¼", "ì˜ì™¸", "ì‹ ê¸°", "íŠ¹ì´", "ë…íŠ¹",
                "ì˜ˆìƒëª»í•œ", "ëœ»ë°–ì˜", "ê°‘ì‘ìŠ¤ëŸ¬ìš´"
            ],
            "ë¶„ë…¸": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "í™”ê°€", "ì§œì¦", "ì—´ë°›", "ë¶„ë…¸", "ê²©ì •", "ì‹«ì–´", "ë³„ë¡œ", "ìµœì•…",
                # í–¥ìˆ˜ ê´€ë ¨ ê°•í•œ ë¶€ì •
                "ìê·¹ì ", "ê°•ë ¬", "ê³¼í•´", "ë¶€ë‹´ìŠ¤ëŸ¬ì›Œ", "ë…í•´", "ì—­ê²¨ìš´",
                "ë”ì°", "ëª»ì°¸ê² ", "ê²¬ë”œìˆ˜ì—†", "ê·¹í˜"
            ],
            "ìƒì²˜": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "ìƒì²˜", "ì•„í”ˆ", "ì„œìš´", "ì‹¤ë§", "ì•„ì‰¬ì›Œ", "ìŠ¬í”ˆ", "í˜ë“ ",
                "ì„­ì„­", "ë§ˆìŒì•„í”ˆ", "ì“¸ì“¸",
                # ê·¸ë¦¬ì›€ê³¼ ì—°ê´€
                "ê·¸ë¦¬ìš´", "ê·¸ë¦½", "ì• í‹‹", "ì•ˆíƒ€ê¹Œìš´", "ì•„ë ¨í•œ"
            ],
            "ìŠ¬í””": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "ìŠ¬í¼", "ëˆˆë¬¼", "ì• ì ˆ", "ì²˜ëŸ‰", "ê³ ë…", "ì™¸ë¡œìš´", "ì“¸ì“¸",
                "ë¨¹ë¨¹", "ì°¡í•œ", "ìš¸ì»¥",
                # ê¹Šì€ ê°ì •
                "ì§„í•œ", "ê¹Šì€", "ì°¨ê°€ìš´", "ë¬´ê±°ìš´", "ì¹¨ìš¸í•œ", "ì•”ìš¸í•œ"
            ],
            "ìš°ìš¸": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "ìš°ìš¸", "ë‹µë‹µ", "ë¬´ê¸°ë ¥", "ì ˆë§", "ì–´ë‘ ", "ì¹¨ìš¸", "ë©œë‘ì½œë¦¬",
                "ë¸”ë£¨", "ê·¸ëŠ˜ì§„", "ì–´ë‘ìš´", "ë§‰ë§‰í•œ",
                # ê¹Šì€ ìš°ìš¸ê°
                "ì ˆë§ì ", "í¬ë§ì—†ëŠ”", "ì˜ìš•ì—†ëŠ”", "ê³µí—ˆí•œ"
            ],
            "í¥ë¶„": [
                # ì§ì ‘ì  ê°ì • í‘œí˜„
                "í¥ë¶„", "ì‹ ë‚˜", "ë‘ê·¼", "ì„¤ë ˜", "í™œê¸°", "ìƒë™ê°", "ì—ë„ˆì§€",
                "í™œë°œ", "ì—­ë™ì ", "í„ë–¡",
                # í–¥ìˆ˜ ê´€ë ¨ í™œê¸°
                "í†¡í†¡", "íŒ¡íŒ¡", "ìƒìƒí•œ", "í™œë ¥", "ì Šì€", "ë°œë„í•œ"
            ]
        }

        # ğŸŒ¸ í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™” ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ
        self.perfume_context_keywords = {
            "positive_intensity": {
                "mild": ["ì€ì€", "ë¶€ë“œëŸ¬ìš´", "ê°€ë²¼ìš´", "ì‚´ì§", "ì€ê·¼"],
                "medium": ["ì ë‹¹", "ê´œì°®ì€", "ë¬´ë‚œí•œ", "ê· í˜•ì¡íŒ"],
                "strong": ["ì§„í•œ", "ê°•í•œ", "ê¹Šì€", "í’ë¶€í•œ", "ë†ì¶•ëœ"]
            },
            "positive_quality": [
                "ì¢‹ì•„", "ë§ˆìŒì— ë“¤ì–´", "í–¥ì´ ì¢‹ì•„", "ì˜ˆë»", "ê³ ê¸‰ìŠ¤ëŸ¬ì›Œ", "ìš°ì•„í•´",
                "ì„¸ë ¨ëœ", "ë§¤ë ¥ì ", "í¬ê·¼í•´", "ë”°ëœ»í•´", "ì‹œì›í•´", "ì²­ëŸ‰í•´", "ìƒí¼í•´",
                "ë‹¬ì½¤í•´", "ë¶€ë“œëŸ¬ì›Œ", "ì€ì€í•´", "ê¹”ë”í•´", "ê¹¨ë—í•´", "fresh", "nice"
            ],
            "negative_quality": [
                "ì‹«ì–´", "ë³„ë¡œ", "ì•„ì‰¬ì›Œ", "ì´ìƒí•´", "ì–´ìƒ‰í•´", "ë¶€ë‹´ìŠ¤ëŸ¬ì›Œ", "ê³¼í•´",
                "ë‹¨ì¡°ë¡œì›Œ", "ë°‹ë°‹í•´", "ë…í•´", "ìê·¹ì ", "ì—­ê²¨ìš´", "ë”ì°"
            ],
            "intensity_negative": [
                "ì§„í•´", "ì•½í•´", "ì„¸", "ê°•í•´", "ë…í•´", "ìê·¹ì ", "ì••ë„ì "
            ],
            "temporal_context": [
                "ì²˜ìŒ", "ì²«", "ë‚˜ì¤‘", "ì‹œê°„ì§€ë‚˜", "ì§€ì†", "ë³€í™”", "ë°”ë€Œ"
            ]
        }

        # ğŸ¯ ëª¨ë¸ ìƒíƒœ ê´€ë¦¬
        self.model_loaded = False
        self.model = None
        self.tokenizer = None
        self.model_version = "v2_dev"  # ê°œë°œ ì¤‘ ë²„ì „
        self.analysis_count = 0
        self.performance_stats = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "average_response_time": 0.0,
            "method_distribution": {"rule_based": 0, "ai_model": 0},
            "confidence_distribution": {"high": 0, "medium": 0, "low": 0}
        }

        logger.info("âœ… ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"  - ì§€ì› ê°ì •: {list(self.emotion_to_tags.keys())}")
        logger.info(f"  - ëª¨ë¸ ë²„ì „: {self.model_version} (ê°œë°œ ì¤‘)")
        logger.info(f"  - ì´ í‚¤ì›Œë“œ: {sum(len(keywords) for keywords in self.emotion_keywords.values())}ê°œ")

    async def analyze_emotion(self, text: str, use_model: bool = True) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ (ëª¨ë¸ ìš°ì„ , ì‹¤íŒ¨ ì‹œ ë£° ê¸°ë°˜ í´ë°±)

        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            use_model: AI ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ (Falseë©´ ë£° ê¸°ë°˜ë§Œ ì‚¬ìš©)

        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        self.analysis_count += 1

        logger.info(f"ğŸ­ ê°ì • ë¶„ì„ ì‹œì‘ (#{self.analysis_count})")
        logger.info(f"  - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
        logger.info(f"  - ëª¨ë¸ ì‚¬ìš©: {'âœ…' if use_model else 'âŒ'}")

        # ì…ë ¥ ê²€ì¦
        if not text or not text.strip():
            return self._create_empty_result()

        if len(text) > 2000:
            logger.warning(f"âš ï¸ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤: {len(text)}ì")
            return self._create_error_result("text_too_long", "í…ìŠ¤íŠ¸ê°€ 2000ìë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")

        try:
            # ğŸ¤– AI ëª¨ë¸ ë¶„ì„ ì‹œë„ (ê°œë°œ ì™„ë£Œ í›„)
            if use_model and self._is_model_available():
                try:
                    logger.info(f"ğŸ¤– AI ëª¨ë¸ v{self.model_version} ë¶„ì„ ì‹œì‘...")
                    model_result = await self._analyze_with_model(text)

                    if model_result.get("success"):
                        response_time = time.time() - start_time
                        self._update_performance_stats(model_result, response_time)

                        logger.info(f"âœ… AI ëª¨ë¸ ë¶„ì„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {response_time:.3f}ì´ˆ)")
                        logger.info(f"  - ê°ì •: {model_result.get('primary_emotion')}")
                        logger.info(f"  - ì‹ ë¢°ë„: {model_result.get('confidence', 0):.3f}")

                        return model_result
                    else:
                        logger.warning("âš ï¸ AI ëª¨ë¸ ë¶„ì„ ì‹¤íŒ¨, ë£° ê¸°ë°˜ìœ¼ë¡œ í´ë°±")

                except Exception as e:
                    logger.error(f"âŒ AI ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")

            # ğŸ“‹ ë£° ê¸°ë°˜ ë¶„ì„ (í´ë°± ë˜ëŠ” ê¸°ë³¸)
            logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ ì‹œì‘...")
            rule_result = await self._analyze_with_rules(text)

            response_time = time.time() - start_time
            self._update_performance_stats(rule_result, response_time)

            logger.info(f"âœ… ë£° ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {response_time:.3f}ì´ˆ)")
            logger.info(f"  - ê°ì •: {rule_result.get('primary_emotion')}")
            logger.info(f"  - ì‹ ë¢°ë„: {rule_result.get('confidence', 0):.3f}")

            return rule_result

        except Exception as e:
            logger.error(f"âŒ ê°ì • ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return self._create_error_result("analysis_exception", str(e))

    def _is_model_available(self) -> bool:
        """AI ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        # ğŸš§ í˜„ì¬ëŠ” ëª¨ë¸ ê°œë°œ ì¤‘ì´ë¯€ë¡œ False ë°˜í™˜
        # ëª¨ë¸ ì™„ì„± í›„ ì‹¤ì œ ë¡œë”© ë¡œì§ìœ¼ë¡œ êµì²´
        return self.model_loaded and self.model is not None

    async def _analyze_with_model(self, text: str) -> Dict[str, Any]:
        """AI ëª¨ë¸ì„ ì‚¬ìš©í•œ ê°ì • ë¶„ì„ (ë¯¸ë˜ êµ¬í˜„)"""
        # ğŸš§ ëª¨ë¸ ê°œë°œ ì™„ë£Œ í›„ êµ¬í˜„ ì˜ˆì •
        try:
            # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡  ë¡œì§
            # 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            # processed_text = self._preprocess_text(text)

            # 2. í† í¬ë‚˜ì´ì§•
            # tokenized = self.tokenizer.transform([processed_text])

            # 3. ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
            # prediction = self.model.predict(tokenized)
            # probabilities = self.model.predict_proba(tokenized)[0]

            # 4. ê²°ê³¼ í›„ì²˜ë¦¬
            # emotion_idx = np.argmax(prediction)
            # confidence = float(max(probabilities))

            # ì„ì‹œë¡œ ê°œë°œ ì¤‘ ìƒíƒœ ë°˜í™˜
            await asyncio.sleep(0.05)  # ëª¨ë¸ ì¶”ë¡  ì‹œë®¬ë ˆì´ì…˜

            return {
                "success": False,
                "reason": "model_under_development",
                "message": f"AI ëª¨ë¸ v{self.model_version}ëŠ” í˜„ì¬ ê°œë°œ ì¤‘ì…ë‹ˆë‹¤."
            }

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜: {e}")
            return {"success": False, "reason": "model_error", "message": str(e)}

    async def _analyze_with_rules(self, text: str) -> Dict[str, Any]:
        """ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ (í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™”)"""
        try:
            text_lower = text.lower().strip()
            text_words = text.split()

            # ğŸ” 1ë‹¨ê³„: ê¸°ë³¸ ê°ì • í‚¤ì›Œë“œ ë§¤ì¹­
            emotion_scores = {}
            keyword_matches = {}
            total_keywords_found = 0

            for emotion, keywords in self.emotion_keywords.items():
                score = 0
                matched_keywords = []

                for keyword in keywords:
                    # ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ì´ ì•„ë‹Œ)
                    pattern = r'\b' + re.escape(keyword) + r'\b'
                    matches = len(re.findall(pattern, text_lower))

                    if matches > 0:
                        # í‚¤ì›Œë“œ ì¤‘ìš”ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì ìš©
                        weight = self._get_keyword_weight(keyword, emotion)
                        score += matches * weight
                        matched_keywords.extend([keyword] * matches)
                        total_keywords_found += matches

                if score > 0:
                    emotion_scores[emotion] = score
                    keyword_matches[emotion] = matched_keywords

            # ğŸŒ¸ 2ë‹¨ê³„: í–¥ìˆ˜ ë„ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ ë³´ì •
            context_boost = self._analyze_perfume_context(text_lower, text_words)

            # ì»¨í…ìŠ¤íŠ¸ ë³´ì • ì ìš©
            for emotion, boost in context_boost.items():
                if emotion in emotion_scores:
                    emotion_scores[emotion] += boost
                elif boost > 0.5:  # ì¶©ë¶„íˆ ê°•í•œ ì»¨í…ìŠ¤íŠ¸ ì‹ í˜¸
                    emotion_scores[emotion] = boost
                    keyword_matches[emotion] = ["context_boost"]

            # ğŸ“Š 3ë‹¨ê³„: ê²°ê³¼ ê³„ì‚° ë° ì •ê·œí™”
            if emotion_scores:
                # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ì •ê·œí™”
                normalization_factor = max(len(text_words), 1)
                normalized_scores = {}

                for emotion, score in emotion_scores.items():
                    # ì •ê·œí™” ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)
                    normalized_score = min(score / normalization_factor * 1.5, 1.0)
                    normalized_scores[emotion] = normalized_score

                # ìµœê³  ì ìˆ˜ ê°ì • ì„ íƒ
                primary_emotion = max(normalized_scores.keys(),
                                      key=lambda x: normalized_scores[x])
                confidence = normalized_scores[primary_emotion]

                # ì‹ ë¢°ë„ ë³´ì • (í‚¤ì›Œë“œ ë§¤ì¹­ì´ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€)
                confidence_boost = min(total_keywords_found * 0.1, 0.3)
                final_confidence = min(confidence + confidence_boost, 1.0)

                # ê°ì • íƒœê·¸ ìƒì„±
                emotion_tags = self.emotion_to_tags.get(primary_emotion, ["#neutral"])

                return {
                    "success": True,
                    "method": "rule_based",
                    "primary_emotion": primary_emotion,
                    "confidence": round(final_confidence, 3),
                    "emotion_tags": emotion_tags,
                    "analysis_details": {
                        "raw_scores": emotion_scores,
                        "normalized_scores": normalized_scores,
                        "keyword_matches": keyword_matches,
                        "context_boost": context_boost,
                        "total_keywords": total_keywords_found,
                        "text_length": len(text),
                        "word_count": len(text_words)
                    },
                    "analyzed_at": datetime.now().isoformat(),
                    "analyzer_version": "rule_based_v1.2"
                }
            else:
                # í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì—†ëŠ” ê²½ìš°
                return self._create_neutral_result("no_emotion_keywords")

        except Exception as e:
            logger.error(f"âŒ ë£° ê¸°ë°˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_error_result("rule_analysis_error", str(e))

    def _get_keyword_weight(self, keyword: str, emotion: str) -> float:
        """í‚¤ì›Œë“œ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        # ê°ì •ë³„ í•µì‹¬ í‚¤ì›Œë“œì— ë†’ì€ ê°€ì¤‘ì¹˜
        high_weight_keywords = {
            "ê¸°ì¨": ["ì¢‹ì•„", "í–‰ë³µ", "ì‚¬ë‘", "ì™„ë²½", "ìµœê³ "],
            "ë¶ˆì•ˆ": ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤ìš´", "ë¶€ë‹´"],
            "ë‹¹í™©": ["ë‹¹í™©", "ë†€ë€", "í˜¼ë€", "ì˜ì™¸"],
            "ë¶„ë…¸": ["í™”ê°€", "ì§œì¦", "ì‹«ì–´", "ìµœì•…"],
            "ìƒì²˜": ["ìƒì²˜", "ì•„í”ˆ", "ì‹¤ë§", "ê·¸ë¦¬ìš´"],
            "ìŠ¬í””": ["ìŠ¬í¼", "ëˆˆë¬¼", "ì™¸ë¡œìš´", "ì“¸ì“¸"],
            "ìš°ìš¸": ["ìš°ìš¸", "ì ˆë§", "ë¬´ê¸°ë ¥", "ì–´ë‘ "],
            "í¥ë¶„": ["í¥ë¶„", "ì‹ ë‚˜", "ì„¤ë ˜", "ì—ë„ˆì§€"]
        }

        if keyword in high_weight_keywords.get(emotion, []):
            return 1.5  # í•µì‹¬ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
        elif len(keyword) >= 3:
            return 1.2  # ê¸´ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
        else:
            return 1.0  # ê¸°ë³¸ ê°€ì¤‘ì¹˜

    def _analyze_perfume_context(self, text_lower: str, text_words: List[str]) -> Dict[str, float]:
        """í–¥ìˆ˜ ë„ë©”ì¸ íŠ¹í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        context_boost = {}

        # ê¸ì •ì  í’ˆì§ˆ í‘œí˜„ ê°ì§€
        positive_quality_count = 0
        for keyword in self.perfume_context_keywords["positive_quality"]:
            positive_quality_count += text_lower.count(keyword)

        # ë¶€ì •ì  í’ˆì§ˆ í‘œí˜„ ê°ì§€
        negative_quality_count = 0
        for keyword in self.perfume_context_keywords["negative_quality"]:
            negative_quality_count += text_lower.count(keyword)

        # ê°•ë„ ê´€ë ¨ ë¶€ì • í‘œí˜„
        intensity_negative_count = 0
        for keyword in self.perfume_context_keywords["intensity_negative"]:
            intensity_negative_count += text_lower.count(keyword)

        # ğŸŒ¸ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë³´ì •
        if positive_quality_count > 0:
            boost_strength = min(positive_quality_count * 0.8, 2.0)
            context_boost["ê¸°ì¨"] = boost_strength

            # ê¸ì •ì  í‘œí˜„ì´ ë§¤ìš° ê°•í•œ ê²½ìš° í¥ë¶„ë„ ì¶”ê°€
            if positive_quality_count >= 2:
                context_boost["í¥ë¶„"] = boost_strength * 0.6

        if negative_quality_count > 0:
            boost_strength = min(negative_quality_count * 0.7, 1.8)
            # ë¶€ì •ì  í‘œí˜„ì˜ ê°•ë„ì— ë”°ë¼ ë‹¤ë¥¸ ê°ì • ë°°ì •
            if negative_quality_count >= 2:
                context_boost["ë¶„ë…¸"] = boost_strength
            else:
                context_boost["ìƒì²˜"] = boost_strength * 0.8

        if intensity_negative_count > 0:
            boost_strength = min(intensity_negative_count * 0.6, 1.5)
            context_boost["ë¶ˆì•ˆ"] = boost_strength

        # ì‹œê°„ì  ë§¥ë½ ë¶„ì„ (ë³€í™” í‘œí˜„)
        temporal_keywords = ["ì²˜ìŒ", "ì²«", "ë‚˜ì¤‘", "ì‹œê°„ì§€ë‚˜", "ë³€í™”"]
        temporal_count = sum(text_lower.count(kw) for kw in temporal_keywords)
        if temporal_count > 0:
            context_boost["ë‹¹í™©"] = min(temporal_count * 0.5, 1.0)

        return context_boost

    def _create_empty_result(self) -> Dict[str, Any]:
        """ë¹ˆ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ê²°ê³¼"""
        return {
            "success": True,
            "method": "validation",
            "primary_emotion": "ì¤‘ë¦½",
            "confidence": 0.0,
            "emotion_tags": ["#neutral"],
            "reason": "empty_text",
            "message": "ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.",
            "analyzed_at": datetime.now().isoformat()
        }

    def _create_neutral_result(self, reason: str) -> Dict[str, Any]:
        """ì¤‘ë¦½ ê°ì • ê²°ê³¼"""
        return {
            "success": True,
            "method": "rule_based",
            "primary_emotion": "ì¤‘ë¦½",
            "confidence": 0.3,
            "emotion_tags": ["#neutral", "#calm"],
            "reason": reason,
            "message": "ëª…í™•í•œ ê°ì • ì‹ í˜¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "analyzed_at": datetime.now().isoformat()
        }

    def _create_error_result(self, error_type: str, message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼"""
        return {
            "success": False,
            "error_type": error_type,
            "message": message,
            "primary_emotion": "ì˜¤ë¥˜",
            "confidence": 0.0,
            "emotion_tags": ["#error"],
            "analyzed_at": datetime.now().isoformat()
        }

    def _update_performance_stats(self, result: Dict[str, Any], response_time: float):
        """ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.performance_stats["total_analyses"] += 1

        if result.get("success"):
            self.performance_stats["successful_analyses"] += 1

            # ë°©ë²•ë³„ ë¶„í¬ ì—…ë°ì´íŠ¸
            method = result.get("method", "unknown")
            if method in self.performance_stats["method_distribution"]:
                self.performance_stats["method_distribution"][method] += 1

            # ì‹ ë¢°ë„ ë¶„í¬ ì—…ë°ì´íŠ¸
            confidence = result.get("confidence", 0.0)
            if confidence >= 0.7:
                self.performance_stats["confidence_distribution"]["high"] += 1
            elif confidence >= 0.4:
                self.performance_stats["confidence_distribution"]["medium"] += 1
            else:
                self.performance_stats["confidence_distribution"]["low"] += 1

        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        total_time = (self.performance_stats["average_response_time"] *
                      (self.performance_stats["total_analyses"] - 1) + response_time)
        self.performance_stats["average_response_time"] = total_time / self.performance_stats["total_analyses"]

    def get_supported_emotions(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” ê°ì • ëª©ë¡ ë°˜í™˜"""
        return list(self.emotion_to_tags.keys())

    def get_emotion_tags(self, emotion: str) -> List[str]:
        """íŠ¹ì • ê°ì •ì˜ íƒœê·¸ ëª©ë¡ ë°˜í™˜"""
        return self.emotion_to_tags.get(emotion, ["#neutral"])

    def get_analysis_stats(self) -> Dict[str, Any]:
        """ë¶„ì„ ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´"""
        success_rate = 0.0
        if self.performance_stats["total_analyses"] > 0:
            success_rate = (self.performance_stats["successful_analyses"] /
                            self.performance_stats["total_analyses"] * 100)

        return {
            # ê¸°ë³¸ ì •ë³´
            "model_loaded": self.model_loaded,
            "model_version": self.model_version,
            "supported_emotions": len(self.emotion_to_tags),
            "total_keywords": sum(len(keywords) for keywords in self.emotion_keywords.values()),
            "analysis_methods": ["rule_based"] + (["ai_model"] if self.model_loaded else []),

            # ì„±ëŠ¥ í†µê³„
            "performance": {
                "total_analyses": self.performance_stats["total_analyses"],
                "successful_analyses": self.performance_stats["successful_analyses"],
                "success_rate": round(success_rate, 2),
                "average_response_time": round(self.performance_stats["average_response_time"], 3),
                "method_distribution": self.performance_stats["method_distribution"],
                "confidence_distribution": self.performance_stats["confidence_distribution"]
            },

            # ê°ì • ëª©ë¡
            "emotion_list": list(self.emotion_to_tags.keys()),
            "emotion_tags_count": {emotion: len(tags) for emotion, tags in self.emotion_to_tags.items()},

            # ì‹œìŠ¤í…œ ì •ë³´
            "system_info": {
                "max_text_length": 2000,
                "supported_languages": ["í•œêµ­ì–´"],
                "domain_specialization": "í–¥ìˆ˜_ë¦¬ë·°",
                "last_updated": datetime.now().isoformat()
            }
        }


# ğŸŒŸ ì „ì—­ ê°ì • ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
emotion_analyzer = EmotionAnalyzer()


# ğŸ§ª í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹… í•¨ìˆ˜ë“¤
async def test_emotion_analyzer():
    """ê°ì • ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª ê°ì • ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘...\n")

    test_cases = [
        "ì´ í–¥ìˆ˜ ì •ë§ ì¢‹ì•„ìš”! ë‹¬ì½¤í•˜ê³  ìƒí¼í•´ì„œ ê¸°ë¶„ì´ ì¢‹ì•„ì ¸ìš”.",
        "í–¥ì´ ë„ˆë¬´ ì§„í•´ì„œ ë³„ë¡œì˜ˆìš”. ì¢€ ë¶€ë‹´ìŠ¤ëŸ½ë„¤ìš”.",
        "ì²˜ìŒ ë§¡ì•˜ì„ ë•Œ ë†€ëì–´ìš”. ì˜ˆìƒê³¼ ì™„ì „ ë‹¬ë¼ì„œ ë‹¹í™©ìŠ¤ëŸ¬ì› ì–´ìš”.",
        "ì´ í–¥ìˆ˜ë¥¼ ë§¡ìœ¼ë©´ ì˜›ë‚  ìƒê°ì´ ë‚˜ì„œ ìŠ¬í¼ì ¸ìš”.",
        "í–¥ìˆ˜ê°€ ë„ˆë¬´ ìê·¹ì ì´ì–´ì„œ í™”ê°€ ë‚˜ìš”. ìµœì•…ì´ì—ìš”.",
        "ìƒˆë¡œìš´ í–¥ìˆ˜ë¥¼ ë°œê²¬í•´ì„œ ë„ˆë¬´ ì‹ ë‚˜ìš”! ì—ë„ˆì§€ê°€ ë„˜ì³ìš”.",
        "í–¥ì´ ì€ì€í•˜ê³  ê¹”ë”í•´ì„œ ë§ˆìŒì— ë“¤ì–´ìš”.",
        ""  # ë¹ˆ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
    ]

    for i, text in enumerate(test_cases, 1):
        print(f"--- í…ŒìŠ¤íŠ¸ {i} ---")
        print(f"ì…ë ¥: {text if text else '(ë¹ˆ í…ìŠ¤íŠ¸)'}")

        result = await emotion_analyzer.analyze_emotion(text)

        print(f"ê²°ê³¼: {result['primary_emotion']} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
        print(f"íƒœê·¸: {result['emotion_tags']}")
        print(f"ë°©ë²•: {result['method']}")
        print()

    # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
    stats = emotion_analyzer.get_analysis_stats()
    print("ğŸ“Š ì„±ëŠ¥ í†µê³„:")
    print(f"  ì´ ë¶„ì„: {stats['performance']['total_analyses']}íšŒ")
    print(f"  ì„±ê³µë¥ : {stats['performance']['success_rate']}%")
    print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {stats['performance']['average_response_time']:.3f}ì´ˆ")
    print()

    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
    asyncio.run(test_emotion_analyzer())