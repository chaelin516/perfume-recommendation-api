# utils/model_downloader.py
# ğŸ¤– Google Driveì—ì„œ AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œìŠ¤í…œ

import os
import requests
import logging
import time
import hashlib
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
from datetime import datetime
import pickle
import json

logger = logging.getLogger("model_downloader")


class ModelDownloader:
    """AI ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ í´ë˜ìŠ¤"""

    def __init__(self):
        # ğŸ”— Google Drive íŒŒì¼ ì„¤ì •ë“¤
        self.file_configs = {
            "emotion_model": {
                "file_id": "1JYUJvKVb44p63ctWe3c1G_qmdcDr-Xix",  # âœ… ì‹¤ì œ ê°ì • ëª¨ë¸ íŒŒì¼ ID
                "local_path": "emotion_models/scent_emotion_model_v6.keras",
                "expected_size_mb": 1200,  # 1.2GB
                "description": "ê°ì • íƒœê¹… AI ëª¨ë¸",
                "required": True,
                "backup_urls": []  # ë°±ì—… ë‹¤ìš´ë¡œë“œ URL (í•„ìš”ì‹œ)
            },
            "vectorizer": {
                "file_id": "CREATE_DUMMY_VECTORIZER",  # ğŸ”§ ë”ë¯¸ ë²¡í„°ë¼ì´ì € ìƒì„±
                "local_path": "emotion_models/vectorizer.pkl",
                "expected_size_mb": 1,
                "description": "í…ìŠ¤íŠ¸ ë²¡í„°ë¼ì´ì €",
                "required": False,  # ì—†ì–´ë„ ë”ë¯¸ë¡œ ìƒì„± ê°€ëŠ¥
                "backup_urls": []
            }
        }

        # ë‹¤ìš´ë¡œë“œ ì„¤ì •
        self.chunk_size = 8192 * 8  # 64KB chunks
        self.timeout = 30  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
        self.max_retries = 3
        self.retry_delay = 5  # 5ì´ˆ ëŒ€ê¸°

    def check_file_integrity(self, file_path: str, expected_size_mb: float) -> bool:
        """íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬"""
        try:
            if not os.path.exists(file_path):
                return False

            file_size = os.path.getsize(file_path)
            expected_size_bytes = expected_size_mb * 1024 * 1024

            # í¬ê¸° ê²€ì¦ (Â±10% í—ˆìš©)
            size_tolerance = 0.1
            min_size = expected_size_bytes * (1 - size_tolerance)
            max_size = expected_size_bytes * (1 + size_tolerance)

            if min_size <= file_size <= max_size:
                logger.info(f"âœ… íŒŒì¼ í¬ê¸° ê²€ì¦ í†µê³¼: {file_size:,} bytes (ì˜ˆìƒ: {expected_size_bytes:,})")
                return True
            else:
                logger.warning(f"âš ï¸ íŒŒì¼ í¬ê¸° ë¶ˆì¼ì¹˜: {file_size:,} bytes, ì˜ˆìƒ: {expected_size_bytes:,}")
                return False

        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def get_google_drive_download_url(self, file_id: str) -> str:
        """Google Drive ì§ì ‘ ë‹¤ìš´ë¡œë“œ URL ìƒì„±"""
        return f"https://drive.google.com/uc?export=download&id={file_id}"

    def handle_google_drive_virus_warning(self, response_text: str, file_id: str) -> Optional[str]:
        """Google Drive ë°”ì´ëŸ¬ìŠ¤ ê²½ê³  ì²˜ë¦¬"""
        try:
            # confirm í† í° ì°¾ê¸°
            if "download_warning" in response_text or "virus scan warning" in response_text:
                # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ confirm í† í° ì¶”ì¶œ ì‹œë„
                confirm_patterns = [
                    'name="confirm" value="',
                    'confirm=',
                    'confirm&amp;'
                ]

                for pattern in confirm_patterns:
                    if pattern in response_text:
                        start = response_text.find(pattern) + len(pattern)
                        end = response_text.find('"', start) if '"' in response_text[start:start + 50] else start + 10
                        confirm_token = response_text[start:end].split('&')[0]

                        if confirm_token and len(confirm_token) < 50:  # ìœ íš¨í•œ í† í°ì¸ì§€ ê°„ë‹¨ ê²€ì¦
                            logger.info(f"ğŸ”“ Google Drive í™•ì¸ í† í° ë°œê²¬: {confirm_token[:10]}...")
                            return f"https://drive.google.com/uc?export=download&id={file_id}&confirm={confirm_token}"

                # ê¸°ë³¸ í™•ì¸ í† í° ì‹œë„
                logger.info("ğŸ”“ ê¸°ë³¸ í™•ì¸ í† í° ì‚¬ìš©")
                return f"https://drive.google.com/uc?export=download&id={file_id}&confirm=t"

        except Exception as e:
            logger.warning(f"âš ï¸ ë°”ì´ëŸ¬ìŠ¤ ê²½ê³  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

        return None

    def download_with_progress(self, url: str, destination: str, description: str) -> bool:
        """ì§„í–‰ë¥  í‘œì‹œì™€ í•¨ê»˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            session = requests.Session()

            # User-Agent ì„¤ì • (ì¼ë¶€ ì œí•œ ìš°íšŒ)
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            session.headers.update(headers)

            logger.info(f"ğŸ“¡ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {description}")

            response = session.get(url, stream=True, timeout=self.timeout)
            response.raise_for_status()

            # Content-Length í—¤ë”ì—ì„œ íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            total_size = int(response.headers.get('content-length', 0))

            if total_size == 0:
                logger.warning("âš ï¸ íŒŒì¼ í¬ê¸° ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")

            downloaded_size = 0
            last_progress_time = time.time()
            last_downloaded_size = 0

            with open(destination, 'wb') as f:
                for chunk in response.iter_content(chunk_size=self.chunk_size):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)

                        # ì§„í–‰ë¥  í‘œì‹œ (5ì´ˆë§ˆë‹¤ ë˜ëŠ” 10MBë§ˆë‹¤)
                        current_time = time.time()
                        if (current_time - last_progress_time >= 5) or (
                                downloaded_size - last_downloaded_size >= 10 * 1024 * 1024):
                            if total_size > 0:
                                progress = (downloaded_size / total_size) * 100
                                speed_mbps = (downloaded_size - last_downloaded_size) / (
                                            current_time - last_progress_time) / 1024 / 1024
                                eta_seconds = (total_size - downloaded_size) / (
                                            speed_mbps * 1024 * 1024) if speed_mbps > 0 else 0

                                logger.info(f"ğŸ“¥ {description}: {progress:.1f}% "
                                            f"({downloaded_size:,}/{total_size:,} bytes) "
                                            f"ì†ë„: {speed_mbps:.1f}MB/s, "
                                            f"ë‚¨ì€ì‹œê°„: {int(eta_seconds // 60)}ë¶„ {int(eta_seconds % 60)}ì´ˆ")
                            else:
                                logger.info(f"ğŸ“¥ {description}: {downloaded_size:,} bytes ë‹¤ìš´ë¡œë“œë¨")

                            last_progress_time = current_time
                            last_downloaded_size = downloaded_size

            logger.info(f"âœ… {description} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {downloaded_size:,} bytes")
            return True

        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False

    def download_from_google_drive(self, file_id: str, destination: str, description: str,
                                   expected_size_mb: float) -> bool:
        """Google Driveì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""

        # ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•˜ê³  ìœ íš¨í•œì§€ í™•ì¸
        if self.check_file_integrity(destination, expected_size_mb):
            logger.info(f"âœ… {description} íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ê³  ìœ íš¨í•¨: {destination}")
            return True

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(destination), exist_ok=True)

        # ê¸°ì¡´ ë¶ˆì™„ì „í•œ íŒŒì¼ ì œê±°
        if os.path.exists(destination):
            os.remove(destination)
            logger.info(f"ğŸ—‘ï¸ ê¸°ì¡´ ë¶ˆì™„ì „í•œ íŒŒì¼ ì œê±°: {destination}")

        for attempt in range(self.max_retries):
            try:
                logger.info(f"ğŸ”„ {description} ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1}/{self.max_retries}")

                # ì²« ë²ˆì§¸ ìš”ì²­ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ URL í™•ì¸
                session = requests.Session()
                initial_url = self.get_google_drive_download_url(file_id)

                response = session.get(initial_url, stream=True, timeout=self.timeout)

                # Google Drive ë°”ì´ëŸ¬ìŠ¤ ê²½ê³  ì²˜ë¦¬
                if response.status_code == 200 and len(response.content) < 1024 * 1024:  # 1MB ë¯¸ë§Œì´ë©´ ê²½ê³  í˜ì´ì§€ì¼ ìˆ˜ ìˆìŒ
                    response_text = response.text
                    if "download_warning" in response_text or "virus scan warning" in response_text:
                        logger.info("ğŸ¦  Google Drive ë°”ì´ëŸ¬ìŠ¤ ìŠ¤ìº” ê²½ê³  ê°ì§€, í™•ì¸ í† í° ì²˜ë¦¬...")
                        confirmed_url = self.handle_google_drive_virus_warning(response_text, file_id)

                        if confirmed_url:
                            # í™•ì¸ í† í°ì´ í¬í•¨ëœ URLë¡œ ë‹¤ì‹œ ì‹œë„
                            if self.download_with_progress(confirmed_url, destination, description):
                                if self.check_file_integrity(destination, expected_size_mb):
                                    return True
                                else:
                                    logger.warning(f"âš ï¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {destination}")
                        else:
                            logger.error("âŒ í™•ì¸ í† í°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                else:
                    # ì¼ë°˜ì ì¸ ë‹¤ìš´ë¡œë“œ
                    response.close()  # ê¸°ì¡´ ì—°ê²° ë‹«ê¸°
                    if self.download_with_progress(initial_url, destination, description):
                        if self.check_file_integrity(destination, expected_size_mb):
                            return True
                        else:
                            logger.warning(f"âš ï¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {destination}")

            except Exception as e:
                logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")

            # ì¬ì‹œë„ ì „ ëŒ€ê¸°
            if attempt < self.max_retries - 1:
                logger.info(f"â³ {self.retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(self.retry_delay)

        logger.error(f"âŒ {description} ë‹¤ìš´ë¡œë“œ ìµœì¢… ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì†Œì§„)")
        return False

    def create_dummy_vectorizer(self) -> bool:
        """ë”ë¯¸ ë²¡í„°ë¼ì´ì € ìƒì„± (vectorizer.pklì´ ì—†ì„ ë•Œ)"""
        try:
            from sklearn.feature_extraction.text import TfidfVectorizer

            logger.info("ğŸ”§ ë”ë¯¸ ë²¡í„°ë¼ì´ì € ìƒì„± ì¤‘...")

            # ê°„ë‹¨í•œ TF-IDF ë²¡í„°ë¼ì´ì € ìƒì„±
            vectorizer = TfidfVectorizer(
                max_features=10000,
                ngram_range=(1, 2),
                stop_words=None,
                lowercase=True,
                token_pattern=r'\b\w+\b'
            )

            # ë”ë¯¸ ë°ì´í„°ë¡œ fit
            dummy_texts = [
                "ì¢‹ì•„ìš” í–¥ìˆ˜ ê¸°ë¶„ ì¢‹ì•„ í–‰ë³µí•´ ì‚¬ë‘í•´",
                "ë‚˜ë¹ ìš” ì‹«ì–´ í™”ë‚˜ ì§œì¦ë‚˜ ë³„ë¡œì•¼",
                "ìŠ¬í¼ìš” ìš°ìš¸í•´ ëˆˆë¬¼ ì™¸ë¡œì›Œ ì“¸ì“¸í•´",
                "ì‹ ë‚˜ìš” í¥ë¯¸ë¡œì›Œ ì—ë„ˆì§€ í™œê¸°ì°¨ ì¦ê±°ì›Œ",
                "ë¶ˆì•ˆí•´ ê±±ì •ë¼ ë‘ë ¤ì›Œ ê¸´ì¥ë¼ ìŠ¤íŠ¸ë ˆìŠ¤",
                "ë‹¹í™©ìŠ¤ëŸ¬ì›Œ ë†€ë¼ì›Œ í˜¼ë€ìŠ¤ëŸ¬ì›Œ ì˜ì™¸ì•¼",
                "ìƒì²˜ë°›ì•„ ì•„íŒŒ ì‹¤ë§ìŠ¤ëŸ¬ì›Œ ì„œìš´í•´",
                "ì™„ë²½í•´ ìµœê³ ì•¼ í›Œë¥­í•´ ë©‹ì ¸ í™˜ìƒì "
            ]

            vectorizer.fit(dummy_texts)

            # ì €ì¥
            vectorizer_path = "emotion_models/vectorizer.pkl"
            os.makedirs(os.path.dirname(vectorizer_path), exist_ok=True)

            with open(vectorizer_path, 'wb') as f:
                pickle.dump(vectorizer, f)

            logger.info(f"âœ… ë”ë¯¸ ë²¡í„°ë¼ì´ì € ìƒì„± ì™„ë£Œ: {vectorizer_path}")
            return True

        except Exception as e:
            logger.error(f"âŒ ë”ë¯¸ ë²¡í„°ë¼ì´ì € ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def ensure_models_available(self) -> Dict[str, bool]:
        """ëª¨ë“  í•„ìš”í•œ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  ë‹¤ìš´ë¡œë“œ"""
        results = {}

        logger.info("ğŸ¤– AI ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì‹œì‘...")

        for model_name, config in self.file_configs.items():
            file_id = config["file_id"]
            local_path = config["local_path"]
            expected_size_mb = config["expected_size_mb"]
            description = config["description"]
            required = config.get("required", True)

            logger.info(f"ğŸ” {description} í™•ì¸ ì¤‘...")

            # íŒŒì¼ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°
            if file_id.startswith("YOUR_"):
                logger.warning(f"âš ï¸ {description} íŒŒì¼ IDê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ: {file_id}")

                if model_name == "vectorizer":
                    # ë²¡í„°ë¼ì´ì €ëŠ” ë”ë¯¸ë¡œ ìƒì„± ê°€ëŠ¥
                    results[model_name] = self.create_dummy_vectorizer()
                else:
                    results[model_name] = False
                continue

            # ë‹¤ìš´ë¡œë“œ ì‹œë„
            success = self.download_from_google_drive(file_id, local_path, description, expected_size_mb)
            results[model_name] = success

            if success:
                logger.info(f"âœ… {description} ì¤€ë¹„ ì™„ë£Œ")
            else:
                if required:
                    logger.error(f"âŒ í•„ìˆ˜ ëª¨ë¸ {description} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
                else:
                    logger.warning(f"âš ï¸ ì„ íƒì  ëª¨ë¸ {description} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

                    # ë²¡í„°ë¼ì´ì €ê°€ ì‹¤íŒ¨í•œ ê²½ìš° ë”ë¯¸ ìƒì„± ì‹œë„
                    if model_name == "vectorizer":
                        logger.info("ğŸ”§ ë²¡í„°ë¼ì´ì € ë”ë¯¸ ìƒì„± ì‹œë„...")
                        results[model_name] = self.create_dummy_vectorizer()

        # ê²°ê³¼ ìš”ì•½
        successful_models = sum(1 for success in results.values() if success)
        total_models = len(results)

        logger.info(f"ğŸ“Š ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ: {successful_models}/{total_models}")

        # í•„ìˆ˜ ëª¨ë¸ í™•ì¸
        emotion_model_ready = results.get("emotion_model", False)

        if emotion_model_ready:
            logger.info("ğŸ‰ ê°ì • íƒœê¹… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
        else:
            logger.error("âŒ ê°ì • íƒœê¹… ì‹œìŠ¤í…œ ì¤€ë¹„ ì‹¤íŒ¨ - í•µì‹¬ ëª¨ë¸ ì—†ìŒ")

        return results

    def get_download_status(self) -> Dict[str, Any]:
        """ë‹¤ìš´ë¡œë“œ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        status = {
            "models": {},
            "system_info": {
                "timestamp": datetime.now().isoformat(),
                "python_version": os.sys.version,
                "working_directory": os.getcwd()
            }
        }

        for model_name, config in self.file_configs.items():
            local_path = config["local_path"]
            expected_size_mb = config["expected_size_mb"]

            model_status = {
                "local_path": local_path,
                "exists": os.path.exists(local_path),
                "file_size_mb": 0,
                "is_valid": False,
                "description": config["description"]
            }

            if os.path.exists(local_path):
                file_size = os.path.getsize(local_path)
                model_status["file_size_mb"] = round(file_size / 1024 / 1024, 2)
                model_status["is_valid"] = self.check_file_integrity(local_path, expected_size_mb)

            status["models"][model_name] = model_status

        return status

    def update_file_id(self, model_name: str, new_file_id: str) -> bool:
        """íŒŒì¼ ID ì—…ë°ì´íŠ¸ (ëŸ°íƒ€ì„ì—ì„œ)"""
        if model_name in self.file_configs:
            old_id = self.file_configs[model_name]["file_id"]
            self.file_configs[model_name]["file_id"] = new_file_id
            logger.info(f"ğŸ”„ {model_name} íŒŒì¼ ID ì—…ë°ì´íŠ¸: {old_id[:10]}... â†’ {new_file_id[:10]}...")
            return True
        else:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸: {model_name}")
            return False


# â”€â”€â”€ ì „ì—­ ë‹¤ìš´ë¡œë” ì¸ìŠ¤í„´ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_downloader = ModelDownloader()


# â”€â”€â”€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def ensure_emotion_model_available() -> bool:
    """ê°ì • ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸ (ë¹„ë™ê¸° ë˜í¼)"""
    try:
        results = model_downloader.ensure_models_available()
        return results.get("emotion_model", False)
    except Exception as e:
        logger.error(f"âŒ ê°ì • ëª¨ë¸ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def check_emotion_model_status() -> Dict[str, Any]:
    """ê°ì • ëª¨ë¸ ìƒíƒœ í™•ì¸"""
    return model_downloader.get_download_status()


def download_emotion_model_sync() -> bool:
    """ê°ì • ëª¨ë¸ ë™ê¸° ë‹¤ìš´ë¡œë“œ"""
    try:
        config = model_downloader.file_configs["emotion_model"]
        return model_downloader.download_from_google_drive(
            file_id=config["file_id"],
            destination=config["local_path"],
            description=config["description"],
            expected_size_mb=config["expected_size_mb"]
        )
    except Exception as e:
        logger.error(f"âŒ ê°ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


# â”€â”€â”€ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def test_downloader():
    """ë‹¤ìš´ë¡œë” í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª ëª¨ë¸ ë‹¤ìš´ë¡œë” í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    # í˜„ì¬ ìƒíƒœ í™•ì¸
    status = model_downloader.get_download_status()
    print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ: {status}")

    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„
    results = model_downloader.ensure_models_available()
    print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ê²°ê³¼: {results}")

    # ìµœì¢… ìƒíƒœ í™•ì¸
    final_status = model_downloader.get_download_status()
    print(f"ğŸ“Š ìµœì¢… ìƒíƒœ: {final_status}")

    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
    test_downloader()