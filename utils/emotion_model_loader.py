# utils/emotion_model_loader.py
# ğŸ­ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë” - Google Drive ì—°ë™ ë²„ì „

import os
import pickle
import requests
import logging
from pathlib import Path
import gdown
from typing import Optional, Tuple, Any
import hashlib

logger = logging.getLogger(__name__)

# ğŸ”— Google Drive íŒŒì¼ ID ì„¤ì •
EMOTION_MODEL_FILE_ID = "1JYUJvKVb44p63ctWe3c1G_qmdcDr-Xix"  # ê°ì • ëª¨ë¸ íŒŒì¼ ID
VECTORIZER_FILE_ID = None  # ë²¡í„°ë¼ì´ì €ëŠ” ë¡œì»¬ íŒŒì¼ ì‚¬ìš© (Gitì— í¬í•¨)

# ë¡œì»¬ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
BASE_DIR = Path(__file__).parent.parent
MODELS_DIR = BASE_DIR / "emotion_models"
EMOTION_MODEL_PATH = MODELS_DIR / "scent_emotion_model_v6.keras"
VECTORIZER_PATH = MODELS_DIR / "vectorizer.pkl"

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ê³¼ ë²¡í„°ë¼ì´ì € ì €ì¥
_emotion_model = None
_vectorizer = None
_model_loaded = False


def create_models_directory():
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±"""
    MODELS_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"ğŸ“ ëª¨ë¸ ë””ë ‰í† ë¦¬ í™•ì¸: {MODELS_DIR}")


def download_from_google_drive_gdown(file_id: str, output_path: str) -> bool:
    """gdown ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ Google Drive ë‹¤ìš´ë¡œë“œ"""
    try:
        logger.info(f"ğŸ“¥ Google Driveì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (gdown): {file_id}")

        # gdownì„ ì‚¬ìš©í•œ ë‹¤ìš´ë¡œë“œ
        url = f"https://drive.google.com/uc?id={file_id}"

        # ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
        output = gdown.download(url, output_path, quiet=False)

        if output and os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            logger.info(f"âœ… gdown ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path} ({file_size:,} bytes)")
            return True
        else:
            logger.error("âŒ gdown ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            return False

    except Exception as e:
        logger.error(f"âŒ gdown ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False


def download_from_google_drive_requests(file_id: str, destination: str) -> bool:
    """requestsë¥¼ ì‚¬ìš©í•œ Google Drive ë‹¤ìš´ë¡œë“œ (í´ë°±)"""
    try:
        logger.info(f"ğŸ“¥ Google Driveì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (requests): {file_id}")

        # Google Drive ë‹¤ìš´ë¡œë“œ URL
        url = f"https://drive.google.com/uc?export=download&id={file_id}"

        # ì„¸ì…˜ ìƒì„±
        session = requests.Session()
        response = session.get(url, stream=True)

        # í° íŒŒì¼ì˜ ê²½ìš° í™•ì¸ í† í° ì²˜ë¦¬
        if response.status_code == 200:
            # ë°”ì´ëŸ¬ìŠ¤ ìŠ¤ìº” ê²½ê³ ê°€ ìˆëŠ”ì§€ í™•ì¸
            if "virus scan warning" in response.text.lower() or "download_warning" in response.text:
                logger.info("ğŸ” ëŒ€ìš©ëŸ‰ íŒŒì¼ í™•ì¸ í† í° ì²˜ë¦¬ ì¤‘...")

                # í™•ì¸ í˜ì´ì§€ì—ì„œ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                confirm_url = f"https://drive.google.com/uc?export=download&confirm=t&id={file_id}"
                response = session.get(confirm_url, stream=True)

        # íŒŒì¼ ì €ì¥
        if response.status_code == 200:
            os.makedirs(os.path.dirname(destination), exist_ok=True)

            total_size = 0
            with open(destination, 'wb') as f:
                for chunk in response.iter_content(chunk_size=32768):
                    if chunk:
                        f.write(chunk)
                        total_size += len(chunk)

                        # ì§„í–‰ ìƒí™© ë¡œê·¸ (10MBë§ˆë‹¤)
                        if total_size % (10 * 1024 * 1024) == 0:
                            logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì§„í–‰: {total_size / 1024 / 1024:.1f}MB")

            file_size = os.path.getsize(destination)
            logger.info(f"âœ… requests ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {destination} ({file_size:,} bytes)")
            return True
        else:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status_code}")
            return False

    except Exception as e:
        logger.error(f"âŒ requests ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False


def download_model_file(file_id: str, output_path: str) -> bool:
    """ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)"""
    if not file_id:
        logger.warning("âš ï¸ íŒŒì¼ IDê°€ ì œê³µë˜ì§€ ì•ŠìŒ")
        return False

    create_models_directory()

    # íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if os.path.exists(output_path):
        file_size = os.path.getsize(output_path)
        if file_size > 1024:  # 1KB ì´ìƒì´ë©´ ìœ íš¨í•œ íŒŒì¼ë¡œ ê°„ì£¼
            logger.info(f"âœ… íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬: {output_path} ({file_size:,} bytes)")
            return True

    # ë°©ë²• 1: gdown ì‹œë„
    try:
        import gdown
        if download_from_google_drive_gdown(file_id, output_path):
            return True
    except ImportError:
        logger.warning("âš ï¸ gdown ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŒ. requestsë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
    except Exception as e:
        logger.warning(f"âš ï¸ gdown ë°©ë²• ì‹¤íŒ¨: {e}")

    # ë°©ë²• 2: requests ì‹œë„
    if download_from_google_drive_requests(file_id, output_path):
        return True

    logger.error("âŒ ëª¨ë“  ë‹¤ìš´ë¡œë“œ ë°©ë²• ì‹¤íŒ¨")
    return False


def verify_model_file(file_path: str) -> bool:
    """ëª¨ë¸ íŒŒì¼ ìœ íš¨ì„± ê²€ì¦"""
    try:
        if not os.path.exists(file_path):
            return False

        file_size = os.path.getsize(file_path)
        if file_size < 1024:  # 1KB ë¯¸ë§Œì´ë©´ ë¬´íš¨
            logger.warning(f"âš ï¸ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {file_size} bytes")
            return False

        # Keras ëª¨ë¸ íŒŒì¼ì¸ì§€ í™•ì¸
        if file_path.endswith('.keras'):
            try:
                import tensorflow as tf
                # ëª¨ë¸ í—¤ë”ë§Œ í™•ì¸ (ì „ì²´ ë¡œë”©í•˜ì§€ ì•ŠìŒ)
                with open(file_path, 'rb') as f:
                    header = f.read(100)
                    if b'keras' in header.lower() or b'tensorflow' in header.lower():
                        logger.info(f"âœ… Keras ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì™„ë£Œ: {file_size:,} bytes")
                        return True
            except Exception as e:
                logger.warning(f"âš ï¸ Keras ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")

        # Pickle íŒŒì¼ì¸ì§€ í™•ì¸
        elif file_path.endswith('.pkl'):
            try:
                with open(file_path, 'rb') as f:
                    # pickle í—¤ë” í™•ì¸
                    header = f.read(10)
                    if header.startswith(b'\x80'):  # pickle protocol
                        logger.info(f"âœ… Pickle íŒŒì¼ ê²€ì¦ ì™„ë£Œ: {file_size:,} bytes")
                        return True
            except Exception as e:
                logger.warning(f"âš ï¸ Pickle íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")

        # ê¸°ë³¸ì ìœ¼ë¡œ í¬ê¸°ê°€ ì¶©ë¶„í•˜ë©´ ìœ íš¨í•˜ë‹¤ê³  íŒë‹¨
        logger.info(f"âœ… íŒŒì¼ ê¸°ë³¸ ê²€ì¦ ì™„ë£Œ: {file_size:,} bytes")
        return True

    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        return False


def load_emotion_model():
    """ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë”©"""
    global _emotion_model

    if _emotion_model is not None:
        return _emotion_model

    try:
        # ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (í•„ìš”í•œ ê²½ìš°)
        if not verify_model_file(str(EMOTION_MODEL_PATH)):
            logger.info("ğŸ“¥ ê°ì • ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            if not download_model_file(EMOTION_MODEL_FILE_ID, str(EMOTION_MODEL_PATH)):
                raise Exception("ê°ì • ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

        # ëª¨ë¸ ë¡œë”©
        logger.info(f"ğŸ¤– ê°ì • ëª¨ë¸ ë¡œë”© ì‹œì‘: {EMOTION_MODEL_PATH}")

        import tensorflow as tf

        # Keras ëª¨ë¸ ë¡œë”©
        _emotion_model = tf.keras.models.load_model(str(EMOTION_MODEL_PATH), compile=False)

        logger.info(f"âœ… ê°ì • ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        logger.info(f"  - ì…ë ¥ shape: {_emotion_model.input_shape}")
        logger.info(f"  - ì¶œë ¥ shape: {_emotion_model.output_shape}")

        return _emotion_model

    except Exception as e:
        logger.error(f"âŒ ê°ì • ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        _emotion_model = None
        return None


def load_vectorizer():
    """ë²¡í„°ë¼ì´ì € ë¡œë”© (ë¡œì»¬ íŒŒì¼ ì‚¬ìš©)"""
    global _vectorizer

    if _vectorizer is not None:
        return _vectorizer

    try:
        if os.path.exists(VECTORIZER_PATH):
            logger.info(f"ğŸ“Š ë²¡í„°ë¼ì´ì € ë¡œë”© ì‹œì‘ (ë¡œì»¬ íŒŒì¼): {VECTORIZER_PATH}")

            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size = os.path.getsize(VECTORIZER_PATH)
            logger.info(f"ğŸ“Š ë²¡í„°ë¼ì´ì € íŒŒì¼ í¬ê¸°: {file_size:,} bytes")

            with open(VECTORIZER_PATH, 'rb') as f:
                _vectorizer = pickle.load(f)

            logger.info("âœ… ë²¡í„°ë¼ì´ì € ë¡œë”© ì™„ë£Œ (ë¡œì»¬ íŒŒì¼)")
            return _vectorizer
        else:
            logger.warning("âš ï¸ ë²¡í„°ë¼ì´ì € íŒŒì¼ì´ ì—†ìŒ - ëª¨ë¸ ë‚´ì¥ ì „ì²˜ë¦¬ ì‚¬ìš©")
            logger.warning(f"  ì˜ˆìƒ ê²½ë¡œ: {VECTORIZER_PATH}")
            return None

    except Exception as e:
        logger.error(f"âŒ ë²¡í„°ë¼ì´ì € ë¡œë”© ì‹¤íŒ¨: {e}")
        _vectorizer = None
        return None


def get_emotion_model():
    """ê°ì • ëª¨ë¸ getter"""
    return load_emotion_model()


def get_vectorizer():
    """ë²¡í„°ë¼ì´ì € getter"""
    return load_vectorizer()


def initialize_emotion_models() -> Tuple[bool, str]:
    """ê°ì • ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™”"""
    global _model_loaded

    try:
        logger.info("ğŸ­ ê°ì • ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘...")

        # ëª¨ë¸ íŒŒì¼ í™•ì¸ (ê°ì • ëª¨ë¸ì€ ë‹¤ìš´ë¡œë“œ, ë²¡í„°ë¼ì´ì €ëŠ” ë¡œì»¬)
        model_available = verify_model_file(str(EMOTION_MODEL_PATH))
        vectorizer_available = os.path.exists(VECTORIZER_PATH)  # ë¡œì»¬ íŒŒì¼ë§Œ í™•ì¸

        logger.info(f"ğŸ“‹ ëª¨ë¸ íŒŒì¼ ìƒíƒœ:")
        logger.info(f"  - ê°ì • ëª¨ë¸: {'âœ… ì¡´ì¬' if model_available else 'âŒ ë‹¤ìš´ë¡œë“œ í•„ìš”'}")
        logger.info(f"  - ë²¡í„°ë¼ì´ì €: {'âœ… ì¡´ì¬ (ë¡œì»¬)' if vectorizer_available else 'âŒ ì—†ìŒ (ë¡œì»¬)'}")

        # ê°ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (í•„ìš”í•œ ê²½ìš°)
        if not model_available:
            logger.info("ğŸ“¥ ê°ì • ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
            if EMOTION_MODEL_FILE_ID:
                if download_model_file(EMOTION_MODEL_FILE_ID, str(EMOTION_MODEL_PATH)):
                    model_available = True
                    logger.info("âœ… ê°ì • ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                else:
                    return False, "ê°ì • ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨"
            else:
                return False, "ê°ì • ëª¨ë¸ íŒŒì¼ IDê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ"

        # ë²¡í„°ë¼ì´ì € í™•ì¸ (ë¡œì»¬ íŒŒì¼)
        if not vectorizer_available:
            logger.warning(f"âš ï¸ ë²¡í„°ë¼ì´ì € íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {VECTORIZER_PATH}")
            logger.warning("  ëª¨ë¸ ë‚´ì¥ ì „ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ë£° ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤")

        # ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
        if model_available:
            model = load_emotion_model()
            vectorizer = load_vectorizer()  # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

            if model is not None:
                logger.info("âœ… ê°ì • ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
                logger.info(f"  - ê°ì • ëª¨ë¸: âœ… ë¡œë“œë¨")
                logger.info(f"  - ë²¡í„°ë¼ì´ì €: {'âœ… ë¡œë“œë¨' if vectorizer is not None else 'âŒ ì—†ìŒ (ëª¨ë¸ ë‚´ì¥ ì‚¬ìš©)'}")
                _model_loaded = True
                return True, "ê°ì • ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ"
            else:
                return False, "ê°ì • ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨"
        else:
            return False, "ê°ì • ëª¨ë¸ íŒŒì¼ ì¤€ë¹„ ì‹¤íŒ¨"

    except Exception as e:
        logger.error(f"âŒ ê°ì • ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False, f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}"


def is_model_available() -> bool:
    """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
    return _model_loaded and _emotion_model is not None


def get_model_status() -> dict:
    """ëª¨ë¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
    return {
        "model_loaded": _model_loaded,
        "emotion_model_available": _emotion_model is not None,
        "vectorizer_available": _vectorizer is not None,
        "emotion_model_path": str(EMOTION_MODEL_PATH),
        "vectorizer_path": str(VECTORIZER_PATH),
        "emotion_model_exists": os.path.exists(EMOTION_MODEL_PATH),
        "vectorizer_exists": os.path.exists(VECTORIZER_PATH),
        "emotion_model_file_id": EMOTION_MODEL_FILE_ID,
        "vectorizer_source": "ë¡œì»¬ íŒŒì¼ (Git í¬í•¨)",  # ğŸ†• ë²¡í„°ë¼ì´ì € ì†ŒìŠ¤ ëª…ì‹œ
        "emotion_model_source": "Google Drive ë‹¤ìš´ë¡œë“œ",  # ğŸ†• ê°ì • ëª¨ë¸ ì†ŒìŠ¤ ëª…ì‹œ
        "vectorizer_file_id": "N/A (ë¡œì»¬ íŒŒì¼)"  # ğŸ†• File ID ì—†ìŒ í‘œì‹œ
    }


# ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œ ìë™ ì´ˆê¸°í™” ì‹œë„ (ì„ íƒì‚¬í•­)
def auto_initialize():
    """ìë™ ì´ˆê¸°í™” (í•„ìš”ì‹œ)"""
    if not _model_loaded:
        success, message = initialize_emotion_models()
        if success:
            logger.info("ğŸ¯ ê°ì • ëª¨ë¸ ìë™ ì´ˆê¸°í™” ì„±ê³µ")
        else:
            logger.warning(f"âš ï¸ ê°ì • ëª¨ë¸ ìë™ ì´ˆê¸°í™” ì‹¤íŒ¨: {message}")

# í•„ìš”í•œ ê²½ìš° ì£¼ì„ í•´ì œ
# auto_initialize()