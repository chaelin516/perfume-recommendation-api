# routers/recommend_2nd_router.py
# ğŸ†• 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API - í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° ë§¤í•‘ ìˆ˜ì • ë²„ì „

import os
import pickle
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field, validator
from collections import Counter
import re

# âœ… ê³µí†µ í•¨ìˆ˜ë“¤ì„ recommend_routerì—ì„œ ì„í¬íŠ¸
from routers.recommend_router import (
    check_model_availability,
    get_model,
    get_saved_encoder,
    get_fallback_encoder,
    safe_transform_input,
    predict_cluster_recommendation,
    EMOTION_CLUSTER_MAP,
    _model_available
)

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recommend_2nd_router")

# â”€â”€â”€ 1. ë°ì´í„° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/perfume_final_dataset.csv")
try:
    df = pd.read_csv(DATA_PATH)
    df.fillna("", inplace=True)
    logger.info(f"âœ… Perfume dataset loaded: {df.shape[0]} rows")

    # emotion_cluster ì»¬ëŸ¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
    if 'emotion_cluster' in df.columns:
        df['emotion_cluster'] = pd.to_numeric(df['emotion_cluster'], errors='coerce').fillna(0).astype(int)
        logger.info(f"ğŸ“Š Emotion clusters: {sorted(df['emotion_cluster'].unique())}")

    logger.info(f"ğŸ“‹ Available columns: {list(df.columns)}")

except Exception as e:
    logger.error(f"âŒ perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    raise RuntimeError(f"perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")


# â”€â”€â”€ 2. ğŸ†• í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° ë§¤í•‘ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_frontend_data(user_preferences: dict) -> dict:
    """
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì˜¤ëŠ” ë°ì´í„°ë¥¼ ë°±ì—”ë“œ AI ëª¨ë¸ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
    """
    logger.info(f"ğŸ”„ í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° ì •ê·œí™” ì‹œì‘: {user_preferences}")

    # 1. ì†Œë¬¸ì ë³€í™˜ ë§¤í•‘
    normalized = {}

    # gender ë§¤í•‘
    gender = str(user_preferences.get('gender', '')).lower()
    if gender in ['unisex', 'men', 'women']:
        normalized['gender'] = gender
    else:
        # ê¸°ë³¸ê°’ ë˜ëŠ” ì¶”ë¡ 
        normalized['gender'] = 'unisex'
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” gender '{gender}', ê¸°ë³¸ê°’ 'unisex' ì‚¬ìš©")

    # season_tags ë§¤í•‘
    season = str(user_preferences.get('season_tags', '')).lower()
    if season in ['spring', 'summer', 'fall', 'winter']:
        normalized['season_tags'] = season
    else:
        normalized['season_tags'] = 'summer'
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” season '{season}', ê¸°ë³¸ê°’ 'summer' ì‚¬ìš©")

    # time_tags ë§¤í•‘
    time = str(user_preferences.get('time_tags', '')).lower()
    if time in ['day', 'night']:
        normalized['time_tags'] = time
    else:
        normalized['time_tags'] = 'day'
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” time '{time}', ê¸°ë³¸ê°’ 'day' ì‚¬ìš©")

    # activity ë§¤í•‘
    activity = str(user_preferences.get('activity', '')).lower()
    if activity in ['casual', 'date', 'work']:
        normalized['activity'] = activity
    else:
        normalized['activity'] = 'casual'
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” activity '{activity}', ê¸°ë³¸ê°’ 'casual' ì‚¬ìš©")

    # weather ë§¤í•‘
    weather = str(user_preferences.get('weather', '')).lower()
    if weather in ['any', 'cold', 'hot', 'rainy']:
        normalized['weather'] = weather
    else:
        normalized['weather'] = 'any'
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” weather '{weather}', ê¸°ë³¸ê°’ 'any' ì‚¬ìš©")

    # 2. ğŸš¨ desired_impression íŠ¹ë³„ ì²˜ë¦¬ (ê°€ì¥ ì¤‘ìš”!)
    impression = str(user_preferences.get('desired_impression', '')).lower()

    # ì§€ì›ë˜ëŠ” ì¡°í•©ê°’ë“¤
    supported_impressions = [
        'confident, fresh',
        'confident, mysterious',
        'elegant, friendly',
        'pure, friendly'
    ]

    # ë‹¨ì¼ ê°’ì„ ì¡°í•© ê°’ìœ¼ë¡œ ë§¤í•‘
    impression_mapping = {
        'pure': 'pure, friendly',
        'confident': 'confident, fresh',
        'fresh': 'confident, fresh',
        'mysterious': 'confident, mysterious',
        'elegant': 'elegant, friendly',
        'friendly': 'elegant, friendly'
    }

    if impression in supported_impressions:
        # ì´ë¯¸ ì˜¬ë°”ë¥¸ ì¡°í•© í˜•íƒœ
        normalized['desired_impression'] = impression
    elif impression in impression_mapping:
        # ë‹¨ì¼ ê°’ì„ ì¡°í•© ê°’ìœ¼ë¡œ ë³€í™˜
        normalized['desired_impression'] = impression_mapping[impression]
        logger.info(f"ğŸ”„ desired_impression ë§¤í•‘: '{impression}' â†’ '{normalized['desired_impression']}'")
    else:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        normalized['desired_impression'] = 'confident, fresh'
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” desired_impression '{impression}', ê¸°ë³¸ê°’ 'confident, fresh' ì‚¬ìš©")

    logger.info(f"âœ… ì •ê·œí™” ì™„ë£Œ: {normalized}")

    return normalized


def validate_ai_model_input(user_preferences: dict) -> bool:
    """AI ëª¨ë¸ ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
    required_fields = ['gender', 'season_tags', 'time_tags', 'desired_impression', 'activity', 'weather']

    for field in required_fields:
        if field not in user_preferences:
            logger.error(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
            return False

    # ê° í•„ë“œì˜ ê°’ ê²€ì¦
    valid_values = {
        'gender': ['men', 'unisex', 'women'],
        'season_tags': ['fall', 'spring', 'summer', 'winter'],
        'time_tags': ['day', 'night'],
        'desired_impression': ['confident, fresh', 'confident, mysterious', 'elegant, friendly', 'pure, friendly'],
        'activity': ['casual', 'date', 'work'],
        'weather': ['any', 'cold', 'hot', 'rainy']
    }

    for field, valid_list in valid_values.items():
        value = user_preferences.get(field)
        if value not in valid_list:
            logger.error(f"âŒ ì˜ëª»ëœ ê°’: {field}='{value}', ìœ íš¨í•œ ê°’: {valid_list}")
            return False

    logger.info("âœ… AI ëª¨ë¸ ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼")
    return True


# â”€â”€â”€ 3. ìŠ¤í‚¤ë§ˆ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class UserPreferences(BaseModel):
    """1ì°¨ ì¶”ì²œì„ ìœ„í•œ ì‚¬ìš©ì ì„ í˜¸ë„ (AI ëª¨ë¸ ì…ë ¥) - ëŒ€ì†Œë¬¸ì ê´€ê³„ì—†ì´ í—ˆìš©"""

    gender: str = Field(..., description="ì„±ë³„")
    season_tags: str = Field(..., description="ê³„ì ˆ")
    time_tags: str = Field(..., description="ì‹œê°„")
    desired_impression: str = Field(..., description="ì›í•˜ëŠ” ì¸ìƒ")
    activity: str = Field(..., description="í™œë™")
    weather: str = Field(..., description="ë‚ ì”¨")


class SecondRecommendRequest(BaseModel):
    """2ì°¨ ì¶”ì²œ ìš”ì²­ ìŠ¤í‚¤ë§ˆ - AI ëª¨ë¸ í˜¸ì¶œ í¬í•¨"""

    user_preferences: UserPreferences = Field(
        ...,
        description="1ì°¨ ì¶”ì²œì„ ìœ„í•œ ì‚¬ìš©ì ì„ í˜¸ë„ (AI ëª¨ë¸ ì…ë ¥)"
    )

    user_note_scores: Dict[str, int] = Field(
        ...,
        description="ì‚¬ìš©ìì˜ ë…¸íŠ¸ë³„ ì„ í˜¸ë„ ì ìˆ˜ (0-5)",
        example={
            "jasmine": 5,
            "rose": 4,
            "amber": 3,
            "musk": 0,
            "citrus": 2,
            "vanilla": 1
        }
    )

    # Optional fields (ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ì„± ìœ ì§€)
    emotion_proba: Optional[List[float]] = Field(
        None,
        description="6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„°ë³„ í™•ë¥  ë°°ì—´ (ì œê³µë˜ì§€ ì•Šìœ¼ë©´ AI ëª¨ë¸ë¡œ ê³„ì‚°)",
        min_items=6,
        max_items=6,
        example=[0.01, 0.03, 0.85, 0.02, 0.05, 0.04]
    )

    selected_idx: Optional[List[int]] = Field(
        None,
        description="1ì°¨ ì¶”ì²œì—ì„œ ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤ ëª©ë¡ (ì œê³µë˜ì§€ ì•Šìœ¼ë©´ AI ëª¨ë¸ë¡œ ê³„ì‚°)",
        min_items=1,
        max_items=20,
        example=[23, 45, 102, 200, 233, 305, 399, 410, 487, 512]
    )

    @validator('user_note_scores')
    def validate_note_scores(cls, v):
        for note, score in v.items():
            if not isinstance(score, int) or score < 0 or score > 5:
                raise ValueError(f"ë…¸íŠ¸ '{note}'ì˜ ì ìˆ˜ëŠ” 0-5 ì‚¬ì´ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return v


class SecondRecommendItem(BaseModel):
    """2ì°¨ ì¶”ì²œ ê²°ê³¼ ì•„ì´í…œ"""

    name: str = Field(..., description="í–¥ìˆ˜ ì´ë¦„")
    brand: str = Field(..., description="ë¸Œëœë“œëª…")
    image_url: str = Field("", description="ì´ë¯¸ì§€ URL")
    notes: str = Field("", description="í–¥ìˆ˜ ë…¸íŠ¸")
    final_score: float = Field(..., description="ìµœì¢… ì¶”ì²œ ì ìˆ˜ (0.0-1.0)", ge=0.0, le=1.0)
    emotion_cluster: int = Field(..., description="ê°ì • í´ëŸ¬ìŠ¤í„° ID (0-5)", ge=0, le=5)
    reason: str = Field("", description="ì¶”ì²œ ì´ìœ ")


# â”€â”€â”€ 4. ë…¸íŠ¸ ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_notes_from_string(notes_str: str) -> List[str]:
    """ë…¸íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ê°œë³„ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not notes_str or pd.isna(notes_str):
        return []

    # ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜
    notes = [note.strip().lower() for note in str(notes_str).split(',')]
    notes = [note for note in notes if note and note != '']
    return notes


def normalize_note_name(note: str) -> str:
    """ë…¸íŠ¸ëª…ì„ ì •ê·œí™” (ìœ ì‚¬í•œ ë…¸íŠ¸ë“¤ì„ ë§¤ì¹­í•˜ê¸° ìœ„í•´)"""
    note = note.lower().strip()

    # ì¼ë°˜ì ì¸ ë…¸íŠ¸ëª… ì •ê·œí™” ê·œì¹™
    note_mappings = {
        # ì‹œíŠ¸ëŸ¬ìŠ¤ ê³„ì—´
        'bergamot': ['bergamot', 'bergamotte'],
        'lemon': ['lemon', 'citron'],
        'orange': ['orange', 'sweet orange'],
        'grapefruit': ['grapefruit', 'pink grapefruit'],
        'lime': ['lime', 'persian lime'],

        # í”Œë¡œëŸ´ ê³„ì—´
        'rose': ['rose', 'bulgarian rose', 'damascus rose', 'tea rose'],
        'jasmine': ['jasmine', 'sambac jasmine', 'star jasmine'],
        'lavender': ['lavender', 'french lavender'],
        'ylang-ylang': ['ylang-ylang', 'ylang ylang'],
        'iris': ['iris', 'orris'],

        # ìš°ë”” ê³„ì—´
        'cedar': ['cedar', 'cedarwood', 'atlas cedar'],
        'sandalwood': ['sandalwood', 'mysore sandalwood'],
        'oakmoss': ['oakmoss', 'oak moss'],
        'vetiver': ['vetiver', 'haitian vetiver'],

        # ì•°ë²„/ì˜¤ë¦¬ì—”íƒˆ ê³„ì—´
        'amber': ['amber', 'grey amber'],
        'musk': ['musk', 'white musk', 'red musk'],
        'vanilla': ['vanilla', 'madagascar vanilla'],
        'benzoin': ['benzoin', 'siam benzoin'],

        # ìŠ¤íŒŒì´ì‹œ ê³„ì—´
        'pepper': ['pepper', 'black pepper', 'pink pepper'],
        'cinnamon': ['cinnamon', 'ceylon cinnamon'],
        'cardamom': ['cardamom', 'green cardamom'],
        'ginger': ['ginger', 'fresh ginger']
    }

    # ë§¤í•‘ í…Œì´ë¸”ì—ì„œ ì •ê·œí™”ëœ ì´ë¦„ ì°¾ê¸°
    for normalized, variants in note_mappings.items():
        if note in variants:
            return normalized

    return note


def calculate_note_match_score(perfume_notes: List[str], user_note_scores: Dict[str, int]) -> float:
    """í–¥ìˆ˜ì˜ ë…¸íŠ¸ì™€ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ë¹„êµí•˜ì—¬ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
    if not perfume_notes or not user_note_scores:
        return 0.0

    # í–¥ìˆ˜ ë…¸íŠ¸ë¥¼ ì •ê·œí™”
    normalized_perfume_notes = [normalize_note_name(note) for note in perfume_notes]

    total_score = 0.0
    matched_notes_count = 0
    total_preference_weight = sum(user_note_scores.values())

    if total_preference_weight == 0:
        return 0.0

    for user_note, preference_score in user_note_scores.items():
        normalized_user_note = normalize_note_name(user_note)

        # ì •í™•í•œ ë§¤ì¹­
        if normalized_user_note in normalized_perfume_notes:
            normalized_preference = preference_score / 5.0
            weight = preference_score / total_preference_weight
            contribution = normalized_preference * weight
            total_score += contribution
            matched_notes_count += 1

        # ë¶€ë¶„ ë§¤ì¹­ (ë…¸íŠ¸ëª…ì´ í¬í•¨ë˜ëŠ” ê²½ìš°)
        else:
            partial_matches = []
            for perfume_note in normalized_perfume_notes:
                if normalized_user_note in perfume_note or perfume_note in normalized_user_note:
                    partial_matches.append(perfume_note)

            if partial_matches:
                # ë¶€ë¶„ ë§¤ì¹­ì€ 50% ê°€ì¤‘ì¹˜
                normalized_preference = (preference_score / 5.0) * 0.5
                weight = preference_score / total_preference_weight
                contribution = normalized_preference * weight
                total_score += contribution
                matched_notes_count += 0.5

    if matched_notes_count == 0:
        return 0.0

    # ë§¤ì¹­ ë¹„ìœ¨ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
    match_ratio = matched_notes_count / len(user_note_scores)
    match_bonus = match_ratio * 0.1

    final_score = min(1.0, total_score + match_bonus)
    return final_score


def calculate_emotion_cluster_weight(perfume_cluster: int, emotion_proba: List[float]) -> float:
    """í–¥ìˆ˜ì˜ ê°ì • í´ëŸ¬ìŠ¤í„°ì™€ ì‚¬ìš©ìì˜ ê°ì • í™•ë¥  ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    if perfume_cluster < 0 or perfume_cluster >= len(emotion_proba):
        return 0.1

    cluster_weight = emotion_proba[perfume_cluster]
    cluster_weight = max(0.05, cluster_weight)
    return cluster_weight


def calculate_final_score(
        note_match_score: float,
        emotion_cluster_weight: float,
        diversity_bonus: float = 0.0
) -> float:
    """ìµœì¢… ì¶”ì²œ ì ìˆ˜ ê³„ì‚°"""
    # ë…¸íŠ¸ ë§¤ì¹­ ì ìˆ˜ 70%, ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜ 25%, ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ 5%
    final_score = (
            note_match_score * 0.70 +
            emotion_cluster_weight * 0.25 +
            diversity_bonus * 0.05
    )

    final_score = max(0.0, min(1.0, final_score))
    return final_score


def get_recommendation_reason(final_score: float, note_match_score: float, emotion_cluster: int) -> str:
    """ì¶”ì²œ ì´ìœ  ìƒì„±"""
    cluster_desc = EMOTION_CLUSTER_MAP.get(emotion_cluster, f"í´ëŸ¬ìŠ¤í„° {emotion_cluster}")

    if final_score >= 0.8:
        return f"ğŸ¯ ë‹¹ì‹ ì˜ ì„ í˜¸ ë…¸íŠ¸ì™€ {note_match_score:.1%} ì¼ì¹˜í•˜ë©°, {cluster_desc} ê°ì •ì— ì™„ë²½í•˜ê²Œ ì–´ìš¸ë¦½ë‹ˆë‹¤!"
    elif final_score >= 0.6:
        return f"âœ¨ ë‹¹ì‹ ì˜ ì·¨í–¥ê³¼ {note_match_score:.1%} ì¼ì¹˜í•˜ëŠ” {cluster_desc} ìŠ¤íƒ€ì¼ì˜ í–¥ìˆ˜ì…ë‹ˆë‹¤."
    elif final_score >= 0.4:
        return f"ğŸŒŸ {cluster_desc} ë¶„ìœ„ê¸°ì˜ í–¥ìˆ˜ë¡œ, ìƒˆë¡œìš´ ì‹œë„í•´ë³¼ ë§Œí•œ ì„ íƒì…ë‹ˆë‹¤."
    else:
        return f"ğŸ” {cluster_desc} ê³„ì—´ì˜ ìƒ‰ë‹¤ë¥¸ ë§¤ë ¥ì„ ê°€ì§„ í–¥ìˆ˜ì…ë‹ˆë‹¤."


# â”€â”€â”€ 5. AI ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_ai_model_for_first_recommendation(user_preferences: dict) -> Dict:
    """AI ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ 1ì°¨ ì¶”ì²œ ìˆ˜í–‰"""
    try:
        logger.info("ğŸ¤– AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ í˜¸ì¶œ ì‹œì‘")

        # ğŸš¨ ë°ì´í„° ì •ê·œí™” ì ìš©
        normalized_preferences = normalize_frontend_data(user_preferences)

        # ğŸš¨ ìœ íš¨ì„± ê²€ì‚¬
        if not validate_ai_model_input(normalized_preferences):
            raise ValueError("AI ëª¨ë¸ ì…ë ¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨")

        logger.info(f"ğŸ”„ ì •ê·œí™”ëœ ì„ í˜¸ë„ë¡œ AI ëª¨ë¸ í˜¸ì¶œ: {normalized_preferences}")

        # predict_cluster_recommendation í•¨ìˆ˜ í˜¸ì¶œ
        result = predict_cluster_recommendation(normalized_preferences)

        # ê²°ê³¼ í˜•íƒœ ë³€í™˜
        return {
            "cluster": result["cluster"],
            "confidence": max(result["proba"]),
            "emotion_proba": result["proba"],
            "selected_idx": result["selected_idx"]
        }

    except Exception as e:
        logger.error(f"âŒ AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 6. ë©”ì¸ ì¶”ì²œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_second_recommendation_with_ai(
        user_preferences: dict,
        user_note_scores: Dict[str, int],
        emotion_proba: Optional[List[float]] = None,
        selected_idx: Optional[List[int]] = None
) -> List[Dict]:
    """AI ëª¨ë¸ì„ í¬í•¨í•œ ì™„ì „í•œ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ í•¨ìˆ˜"""
    start_time = datetime.now()

    logger.info(f"ğŸ¯ AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")

    # 1. emotion_proba ë˜ëŠ” selected_idxê°€ ì—†ìœ¼ë©´ AI ëª¨ë¸ í˜¸ì¶œ
    if emotion_proba is None or selected_idx is None:
        logger.info("ğŸ¤– AI ëª¨ë¸ë¡œ 1ì°¨ ì¶”ì²œ ìˆ˜í–‰ (emotion_proba ë˜ëŠ” selected_idx ì—†ìŒ)")

        try:
            ai_result = call_ai_model_for_first_recommendation(user_preferences)

            if emotion_proba is None:
                emotion_proba = ai_result["emotion_proba"]
                logger.info(f"âœ… AI ëª¨ë¸ì—ì„œ ê°ì • í™•ë¥  íšë“: í´ëŸ¬ìŠ¤í„° {ai_result['cluster']} (ì‹ ë¢°ë„: {ai_result['confidence']:.3f})")

            if selected_idx is None:
                selected_idx = ai_result["selected_idx"]
                logger.info(f"âœ… AI ëª¨ë¸ì—ì„œ ì„ íƒ ì¸ë±ìŠ¤ íšë“: {len(selected_idx)}ê°œ")

        except Exception as e:
            logger.error(f"âŒ AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ“‹ ë£° ê¸°ë°˜ í´ë°±ìœ¼ë¡œ ì „í™˜")

            # ë£° ê¸°ë°˜ í´ë°±
            emotion_proba = [0.1, 0.15, 0.4, 0.15, 0.1, 0.1]

            # ğŸš¨ ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ê¸°ë³¸ í•„í„°ë§
            try:
                normalized_preferences = normalize_frontend_data(user_preferences)
                candidates = df.copy()
                if 'gender' in df.columns and normalized_preferences.get("gender"):
                    gender_filtered = candidates[candidates['gender'] == normalized_preferences["gender"]]
                    if not gender_filtered.empty:
                        candidates = gender_filtered

                selected_idx = candidates.head(10).index.tolist()
                logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ í´ë°±ìœ¼ë¡œ {len(selected_idx)}ê°œ ì¸ë±ìŠ¤ ìƒì„±")
            except Exception as fallback_e:
                logger.error(f"âŒ ë£° ê¸°ë°˜ í´ë°±ë„ ì‹¤íŒ¨: {fallback_e}")
                # ìµœì¢… ì•ˆì „ì¥ì¹˜
                selected_idx = list(range(10))

    # 2. ê¸°ì¡´ 2ì°¨ ì¶”ì²œ ë¡œì§ ìˆ˜í–‰
    return process_second_recommendation(user_note_scores, emotion_proba, selected_idx)


def process_second_recommendation(
        user_note_scores: Dict[str, int],
        emotion_proba: List[float],
        selected_idx: List[int]
) -> List[Dict]:
    """2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
    start_time = datetime.now()

    logger.info(f"ğŸ¯ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")
    logger.info(f"  ğŸ“ ì‚¬ìš©ì ë…¸íŠ¸ ì„ í˜¸ë„: {user_note_scores}")
    logger.info(f"  ğŸ§  ê°ì • í™•ë¥  ë¶„í¬: {[f'{p:.3f}' for p in emotion_proba]}")
    logger.info(f"  ğŸ“‹ ì„ íƒëœ ì¸ë±ìŠ¤: {selected_idx[:5]}... (ì´ {len(selected_idx)}ê°œ)")

    # ì„ íƒëœ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ë“¤ í•„í„°ë§
    valid_indices = [idx for idx in selected_idx if idx < len(df)]

    if not valid_indices:
        raise ValueError("ìœ íš¨í•œ í–¥ìˆ˜ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    selected_perfumes = df.iloc[valid_indices].copy()
    logger.info(f"âœ… {len(selected_perfumes)}ê°œ í–¥ìˆ˜ ì„ íƒë¨")

    # ê° í–¥ìˆ˜ì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚°
    results = []
    brand_count = {}

    for idx, (_, row) in enumerate(selected_perfumes.iterrows()):
        try:
            # í–¥ìˆ˜ ê¸°ë³¸ ì •ë³´
            perfume_name = str(row['name'])
            perfume_brand = str(row['brand'])
            perfume_cluster = int(row.get('emotion_cluster', 0))
            perfume_notes_str = str(row.get('notes', ''))
            perfume_image_url = str(row.get('image_url', ''))

            # ë…¸íŠ¸ íŒŒì‹±
            perfume_notes = parse_notes_from_string(perfume_notes_str)

            # 1. ë…¸íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            note_match_score = calculate_note_match_score(perfume_notes, user_note_scores)

            # 2. ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜ ê³„ì‚°
            emotion_weight = calculate_emotion_cluster_weight(perfume_cluster, emotion_proba)

            # 3. ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ ê³„ì‚°
            brand_count[perfume_brand] = brand_count.get(perfume_brand, 0) + 1
            diversity_bonus = max(0.0, 0.1 - (brand_count[perfume_brand] - 1) * 0.02)

            # 4. ìµœì¢… ì ìˆ˜ ê³„ì‚°
            final_score = calculate_final_score(note_match_score, emotion_weight, diversity_bonus)

            # 5. ì¶”ì²œ ì´ìœ  ìƒì„±
            reason = get_recommendation_reason(final_score, note_match_score, perfume_cluster)

            # ê²°ê³¼ ì €ì¥
            result_item = {
                'name': perfume_name,
                'brand': perfume_brand,
                'image_url': perfume_image_url,
                'notes': perfume_notes_str,
                'final_score': round(final_score, 3),
                'emotion_cluster': perfume_cluster,
                'reason': reason,
                'note_match_score': round(note_match_score, 3),
                'emotion_weight': round(emotion_weight, 3),
                'diversity_bonus': round(diversity_bonus, 3),
                'original_index': valid_indices[idx]
            }

            results.append(result_item)

            # ìƒì„¸ ë¡œê¹… (ìƒìœ„ 3ê°œë§Œ)
            if idx < 3:
                logger.info(f"ğŸ“Š #{idx + 1} {perfume_name}: ë…¸íŠ¸ë§¤ì¹­={note_match_score:.3f}, "
                            f"ê°ì •ê°€ì¤‘ì¹˜={emotion_weight:.3f}, ìµœì¢…ì ìˆ˜={final_score:.3f}")

        except Exception as e:
            logger.error(f"âŒ í–¥ìˆ˜ '{row.get('name', 'Unknown')}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    # ìµœì¢… ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    results.sort(key=lambda x: x['final_score'], reverse=True)

    processing_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"âœ… 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ í–¥ìˆ˜ (ì†Œìš”ì‹œê°„: {processing_time:.3f}ì´ˆ)")

    if results:
        top_scores = [r['final_score'] for r in results[:3]]
        logger.info(f"ğŸ“Š ìƒìœ„ 3ê°œ ì ìˆ˜: {top_scores}")

    return results


# â”€â”€â”€ 7. ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/perfumes", tags=["Second Recommendation"])

# ì‹œì‘ ì‹œ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
logger.info("ğŸš€ 2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ (AI ëª¨ë¸ í¬í•¨) ì´ˆê¸°í™” ì‹œì‘...")
try:
    global _model_available
    check_model_availability()
    if _model_available:
        logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
    else:
        logger.info("ğŸ“‹ ë£° ê¸°ë°˜ í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ë™ì‘")
except Exception as e:
    logger.warning(f"âš ï¸ ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ (í´ë°±ìœ¼ë¡œ ë™ì‘): {e}")
    _model_available = False

logger.info("âœ… 2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")


@router.post(
    "/recommend-2nd",
    response_model=List[SecondRecommendItem],
    summary="2ì°¨ í–¥ìˆ˜ ì¶”ì²œ - AI ëª¨ë¸ + ë…¸íŠ¸ ì„ í˜¸ë„ ê¸°ë°˜ (ìˆ˜ì •ë¨)",
    description=(
            "ğŸ¯ **ì™„ì „í•œ End-to-End 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API (ë°ì´í„° ë§¤í•‘ ìˆ˜ì •)**\n\n"
            "í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì˜¤ëŠ” ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë°±ì—”ë“œ AI ëª¨ë¸ í˜•ì‹ì— ë§ê²Œ ë³€í™˜í•˜ì—¬\n"
            "ì •í™•í•œ 1ì°¨ ì¶”ì²œì„ ìˆ˜í–‰í•œ í›„, ë…¸íŠ¸ ì„ í˜¸ë„ì™€ ê²°í•©í•˜ì—¬ ì •ë°€í•œ 2ì°¨ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.\n\n"
            "**ğŸ”„ ìë™ ë°ì´í„° ë³€í™˜:**\n"
            "- 'Pure' â†’ 'pure, friendly'\n"
            "- 'Unisex' â†’ 'unisex'\n"
            "- 'Summer' â†’ 'summer'\n"
            "- ê¸°íƒ€ ëŒ€ì†Œë¬¸ì ë° í˜•ì‹ ì •ê·œí™”\n\n"
            "**ğŸ“¥ ì…ë ¥ ì •ë³´:**\n"
            "- `user_preferences`: ì‚¬ìš©ì ê¸°ë³¸ ì„ í˜¸ë„ (ëŒ€ì†Œë¬¸ì ë¬´ê´€)\n"
            "- `user_note_scores`: ì‚¬ìš©ìì˜ ë…¸íŠ¸ë³„ ì„ í˜¸ë„ ì ìˆ˜ (0-5)\n"
            "- `emotion_proba` (ì„ íƒ): ê°ì • í™•ë¥  ë°°ì—´\n"
            "- `selected_idx` (ì„ íƒ): ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤\n\n"
            "**ğŸ¤– ì²˜ë¦¬ ê³¼ì •:**\n"
            "1. ë°ì´í„° ì •ê·œí™” â†’ í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„°ë¥¼ AI ëª¨ë¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n"
            "2. AI ëª¨ë¸ í˜¸ì¶œ â†’ ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ + í–¥ìˆ˜ ì„ íƒ\n"
            "3. ë…¸íŠ¸ ë§¤ì¹­ â†’ ì‚¬ìš©ì ì„ í˜¸ë„ì™€ í–¥ìˆ˜ ë…¸íŠ¸ ë¹„êµ\n"
            "4. ì ìˆ˜ ê³„ì‚° â†’ ë…¸íŠ¸ ë§¤ì¹­(70%) + ê°ì • ê°€ì¤‘ì¹˜(25%) + ë‹¤ì–‘ì„±(5%)\n"
            "5. ìµœì¢… ì •ë ¬ â†’ ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ\n\n"
            "**âœ¨ íŠ¹ì§•:**\n"
            "- ğŸ”„ ìë™ ë°ì´í„° ì •ê·œí™”\n"
            "- ğŸ¤– AI ëª¨ë¸ ìë™ í˜¸ì¶œ\n"
            "- ğŸ¯ ì •í™•í•œ ë…¸íŠ¸ ë§¤ì¹­\n"
            "- ğŸ“Š ê°ì • í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ê°€ì¤‘ì¹˜\n"
            "- ğŸ”„ ë‹¤ë‹¨ê³„ í´ë°± ì‹œìŠ¤í…œ\n"
            "- ğŸŒŸ ë¸Œëœë“œ ë‹¤ì–‘ì„± ë³´ì¥"
    )
)
def recommend_second_perfumes(request: SecondRecommendRequest):
    """AI ëª¨ë¸ í¬í•¨ ì™„ì „í•œ 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API (ë°ì´í„° ë§¤í•‘ ìˆ˜ì •)"""

    request_start_time = datetime.now()

    logger.info(f"ğŸ†• AI ëª¨ë¸ í¬í•¨ 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­ ì ‘ìˆ˜")
    logger.info(f"  ğŸ‘¤ ì›ë³¸ ì‚¬ìš©ì ì„ í˜¸ë„: {request.user_preferences.dict()}")
    logger.info(f"  ğŸ“Š ë…¸íŠ¸ ì„ í˜¸ë„ ê°œìˆ˜: {len(request.user_note_scores)}ê°œ")

    try:
        # ë©”ì¸ ì¶”ì²œ ì²˜ë¦¬ (AI ëª¨ë¸ í¬í•¨, ë°ì´í„° ì •ê·œí™” ì ìš©)
        results = process_second_recommendation_with_ai(
            user_preferences=request.user_preferences.dict(),
            user_note_scores=request.user_note_scores,
            emotion_proba=request.emotion_proba,
            selected_idx=request.selected_idx
        )

        if not results:
            raise HTTPException(
                status_code=404,
                detail="ì¶”ì²œí•  ìˆ˜ ìˆëŠ” í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        # ì‘ë‹µ í˜•íƒœë¡œ ë³€í™˜
        response_items = []
        for result in results:
            response_items.append(
                SecondRecommendItem(
                    name=result['name'],
                    brand=result['brand'],
                    image_url=result['image_url'],
                    notes=result['notes'],
                    final_score=result['final_score'],
                    emotion_cluster=result['emotion_cluster'],
                    reason=result['reason']
                )
            )

        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_processing_time = (datetime.now() - request_start_time).total_seconds()

        logger.info(f"âœ… AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì™„ë£Œ: {len(response_items)}ê°œ í–¥ìˆ˜")
        logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.3f}ì´ˆ")
        logger.info(f"ğŸ“Š ìµœê³  ì ìˆ˜: {response_items[0].final_score:.3f} ({response_items[0].name})")
        logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {response_items[-1].final_score:.3f} ~ {response_items[0].final_score:.3f}")

        # í´ëŸ¬ìŠ¤í„°ë³„ ë¶„í¬ ë¡œê¹…
        cluster_distribution = {}
        for item in response_items:
            cluster_distribution[item.emotion_cluster] = cluster_distribution.get(item.emotion_cluster, 0) + 1
        logger.info(f"ğŸ“Š í´ëŸ¬ìŠ¤í„°ë³„ ë¶„í¬: {cluster_distribution}")

        return response_items

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# â”€â”€â”€ 8. ì‹œìŠ¤í…œ ìƒíƒœ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.get(
    "/system-status",
    summary="2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ ìƒíƒœ",
    description="2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ìƒíƒœì™€ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
)
def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ API"""

    try:
        # ë°ì´í„°ì…‹ í†µê³„
        total_perfumes = len(df)
        unique_brands = df['brand'].nunique() if 'brand' in df.columns else 0

        # ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„í¬
        cluster_distribution = {}
        if 'emotion_cluster' in df.columns:
            cluster_counts = df['emotion_cluster'].value_counts().to_dict()
            cluster_distribution = {int(k): int(v) for k, v in cluster_counts.items()}

        # ë…¸íŠ¸ í†µê³„ (ìƒ˜í”Œë§)
        all_notes = []
        for _, row in df.head(100).iterrows():
            notes = parse_notes_from_string(str(row.get('notes', '')))
            all_notes.extend(notes)

        note_frequency = Counter(all_notes)
        top_notes = dict(note_frequency.most_common(20))

        # AI ëª¨ë¸ ìƒíƒœ í™•ì¸
        try:
            global _model_available
            model_status = "available" if _model_available else "fallback"
        except:
            model_status = "unknown"

        return {
            "system_status": "operational",
            "timestamp": datetime.now().isoformat(),  # âœ… timestamp ì¶”ê°€
            "ai_model_status": model_status,
            "dataset_info": {
                "total_perfumes": total_perfumes,
                "unique_brands": unique_brands,
                "columns": list(df.columns),
                "sample_size_for_notes": 100
            },
            "emotion_clusters": {
                "available_clusters": list(EMOTION_CLUSTER_MAP.keys()),
                "cluster_descriptions": EMOTION_CLUSTER_MAP,
                "distribution": cluster_distribution
            },
            "note_analysis": {
                "top_20_notes": top_notes,
                "unique_notes_in_sample": len(note_frequency),
                "total_note_occurrences": len(all_notes)
            },
            "supported_features": [
                "í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° ìë™ ì •ê·œí™”",  # ğŸ†• ì¶”ê°€
                "ë…¸íŠ¸ ì„ í˜¸ë„ ê¸°ë°˜ ë§¤ì¹­",
                "ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜",
                "ë¸Œëœë“œ ë‹¤ì–‘ì„± ë³´ì¥",
                "ë…¸íŠ¸ëª… ì •ê·œí™”",
                "ë¶€ë¶„ ë§¤ì¹­ ì§€ì›",
                "AI ëª¨ë¸ ìë™ í˜¸ì¶œ",
                "ë‹¤ë‹¨ê³„ í´ë°± ì‹œìŠ¤í…œ"  # ğŸ†• ì¶”ê°€
            ],
            "data_mapping": {  # ğŸ†• ì¶”ê°€
                "frontend_to_backend": {
                    "Pure â†’ pure, friendly": "ë‹¨ì¼ ê°ì •ì„ ì¡°í•© ê°ì •ìœ¼ë¡œ ë§¤í•‘",
                    "Unisex â†’ unisex": "ëŒ€ì†Œë¬¸ì ì •ê·œí™”",
                    "Summer â†’ summer": "ëŒ€ì†Œë¬¸ì ì •ê·œí™”",
                    "Day â†’ day": "ëŒ€ì†Œë¬¸ì ì •ê·œí™”",
                    "Work â†’ work": "ëŒ€ì†Œë¬¸ì ì •ê·œí™”",
                    "Any â†’ any": "ëŒ€ì†Œë¬¸ì ì •ê·œí™”"
                }
            }
        }

    except Exception as e:
        logger.error(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "system_status": "error",
            "timestamp": datetime.now().isoformat(),
            "error_message": str(e)
        }


# â”€â”€â”€ 9. ë””ë²„ê¹… APIë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post(
    "/debug/test-data-mapping",
    summary="ë°ì´í„° ë§¤í•‘ í…ŒìŠ¤íŠ¸",
    description="í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„°ê°€ ë°±ì—”ë“œ í˜•ì‹ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ ë³€í™˜ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
)
def test_data_mapping(frontend_data: Dict):
    """ë°ì´í„° ë§¤í•‘ í…ŒìŠ¤íŠ¸ API"""
    try:
        logger.info(f"ğŸ§ª ë°ì´í„° ë§¤í•‘ í…ŒìŠ¤íŠ¸ ì‹œì‘: {frontend_data}")

        # ì •ê·œí™” ìˆ˜í–‰
        normalized = normalize_frontend_data(frontend_data)

        # ìœ íš¨ì„± ê²€ì‚¬
        is_valid = validate_ai_model_input(normalized)

        return {
            "original_data": frontend_data,
            "normalized_data": normalized,
            "is_valid_for_ai_model": is_valid,
            "mapping_applied": {
                field: {
                    "original": frontend_data.get(field, "N/A"),
                    "normalized": normalized.get(field, "N/A"),
                    "changed": frontend_data.get(field, "").lower() != normalized.get(field, "")
                }
                for field in ['gender', 'season_tags', 'time_tags', 'desired_impression', 'activity', 'weather']
            }
        }

    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë§¤í•‘ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "error": str(e),
            "original_data": frontend_data
        }


@router.get(
    "/note-analysis/{perfume_index}",
    summary="í–¥ìˆ˜ ë…¸íŠ¸ ë¶„ì„",
    description="íŠ¹ì • í–¥ìˆ˜ì˜ ë…¸íŠ¸ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."
)
def analyze_perfume_notes(perfume_index: int):
    """í–¥ìˆ˜ ë…¸íŠ¸ ë¶„ì„ API"""

    try:
        if perfume_index < 0 or perfume_index >= len(df):
            raise HTTPException(
                status_code=404,
                detail=f"ì˜ëª»ëœ í–¥ìˆ˜ ì¸ë±ìŠ¤: {perfume_index} (ë²”ìœ„: 0-{len(df) - 1})"
            )

        perfume = df.iloc[perfume_index]
        notes_str = str(perfume.get('notes', ''))
        parsed_notes = parse_notes_from_string(notes_str)
        normalized_notes = [normalize_note_name(note) for note in parsed_notes]

        return {
            "perfume_index": perfume_index,
            "name": str(perfume['name']),
            "brand": str(perfume['brand']),
            "raw_notes": notes_str,
            "parsed_notes": parsed_notes,
            "normalized_notes": normalized_notes,
            "note_count": len(parsed_notes),
            "emotion_cluster": int(perfume.get('emotion_cluster', 0))
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ë…¸íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë…¸íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.post(
    "/test-note-matching",
    summary="ë…¸íŠ¸ ë§¤ì¹­ í…ŒìŠ¤íŠ¸",
    description="ì‚¬ìš©ì ì„ í˜¸ë„ì™€ í–¥ìˆ˜ ë…¸íŠ¸ ê°„ì˜ ë§¤ì¹­ ì ìˆ˜ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
)
def test_note_matching(
        user_notes: Dict[str, int],
        perfume_notes: List[str]
):
    """ë…¸íŠ¸ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ API"""

    try:
        # ë…¸íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        match_score = calculate_note_match_score(perfume_notes, user_notes)

        # ì •ê·œí™”ëœ ë…¸íŠ¸ë“¤
        normalized_perfume_notes = [normalize_note_name(note) for note in perfume_notes]
        normalized_user_notes = {normalize_note_name(k): v for k, v in user_notes.items()}

        # ë§¤ì¹­ ìƒì„¸ ì •ë³´
        matches = []
        for user_note, preference in user_notes.items():
            normalized_user_note = normalize_note_name(user_note)
            if normalized_user_note in normalized_perfume_notes:
                matches.append({
                    "user_note": user_note,
                    "normalized": normalized_user_note,
                    "preference": preference,
                    "match_type": "exact"
                })

        return {
            "user_notes": user_notes,
            "perfume_notes": perfume_notes,
            "normalized_perfume_notes": normalized_perfume_notes,
            "match_score": round(match_score, 3),
            "matches": matches,
            "match_count": len(matches),
            "total_user_notes": len(user_notes)
        }

    except Exception as e:
        logger.error(f"âŒ ë…¸íŠ¸ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë…¸íŠ¸ ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )