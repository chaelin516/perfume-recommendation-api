# routers/recommend_2nd_router.py
# ğŸ†• 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API - ì‚¬ìš©ì ë…¸íŠ¸ ì„ í˜¸ë„ ê¸°ë°˜ ì •ë°€ ì¶”ì²œ

import os
import pickle
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field, validator
from collections import Counter
import re

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recommend_2nd_router")

# â”€â”€â”€ 1. ë°ì´í„° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/perfume_final_dataset.csv")
try:
    df = pd.read_csv(DATA_PATH)
    df.fillna("", inplace=True)
    logger.info(f"âœ… Perfume dataset loaded: {df.shape[0]} rows")

    # emotion_cluster ì»¬ëŸ¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
    if 'emotion_cluster' in df.columns:
        df['emotion_cluster'] = pd.to_numeric(df['emotion_cluster'], errors='coerce').fillna(0).astype(int)
        logger.info(f"ğŸ“Š Emotion clusters: {sorted(df['emotion_cluster'].unique())}")

    logger.info(f"ğŸ“‹ Available columns: {list(df.columns)}")

except Exception as e:
    logger.error(f"âŒ perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    raise RuntimeError(f"perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")


# â”€â”€â”€ 2. ëª¨ë¸ ê´€ë ¨ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "../models/final_model.keras")
ENCODER_PATH = os.path.join(BASE_DIR, "../models/encoder.pkl")

# ì „ì—­ ë³€ìˆ˜
_model = None
_encoder = None
_model_available = False
_fallback_encoder = None


# â”€â”€â”€ 3. ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_model_availability():
    """ëª¨ë¸ íŒŒì¼ë“¤ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    global _model_available

    logger.info("ğŸ” ëª¨ë¸ íŒŒì¼ ê°€ìš©ì„± í™•ì¸ ì¤‘...")

    try:
        # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
        model_exists = os.path.exists(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH)

        model_valid = False
        encoder_valid = False

        if model_exists:
            model_size = os.path.getsize(MODEL_PATH)
            model_valid = model_size > 10000  # 10KB ì´ìƒ
            logger.info(f"ğŸ“„ ëª¨ë¸ íŒŒì¼: {model_size:,}B ({model_size / 1024:.1f}KB) {'âœ…' if model_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")

        if encoder_exists:
            encoder_size = os.path.getsize(ENCODER_PATH)
            encoder_valid = encoder_size > 500  # 500B ì´ìƒ
            logger.info(f"ğŸ“„ ì¸ì½”ë” íŒŒì¼: {encoder_size:,}B ({encoder_size}B) {'âœ…' if encoder_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")

        _model_available = model_valid and encoder_valid

        logger.info(f"ğŸ¤– ëª¨ë¸ ê°€ìš©ì„±: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if _model_available else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")

        if _model_available:
            logger.info(f"âœ¨ ëª¨ë¸ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ - í¬ê¸°: {model_size / 1024:.1f}KB")
        else:
            if not model_valid:
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ í¬ê¸° ë¶€ì¡±: {model_size}B (ìµœì†Œ 10KB í•„ìš”)")
            if not encoder_valid:
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ í¬ê¸° ë¶€ì¡±: {encoder_size}B (ìµœì†Œ 500B í•„ìš”)")

        return _model_available

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        _model_available = False
        return False


# â”€â”€â”€ 4. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_model():
    """Keras ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model

    if _model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
                return None

            model_size = os.path.getsize(MODEL_PATH)
            if model_size < 10000:  # 10KB ë¯¸ë§Œ
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {model_size} bytes ({model_size / 1024:.1f}KB)")
                return None

            logger.info(f"ğŸ“¦ ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸ ì™„ë£Œ: {model_size:,}B ({model_size / 1024:.1f}KB)")

            # TensorFlow ë™ì  ì„í¬íŠ¸
            try:
                import tensorflow as tf
                from tensorflow import keras
                load_model = keras.models.load_model
                logger.info(f"ğŸ“¦ TensorFlow {tf.__version__} + Keras ë¡œë”©")
            except:
                from tensorflow.keras.models import load_model
                logger.info(f"ğŸ“¦ TensorFlow ê¸°ì¡´ ìŠ¤íƒ€ì¼ ë¡œë”©")

            logger.info(f"ğŸ“¦ Keras ëª¨ë¸ ë¡œë”© ì‹œë„")

            # compile=Falseë¡œ ë¹ ë¥¸ ë¡œë”©
            _model = load_model(MODEL_PATH, compile=False)

            logger.info(f"âœ… Keras ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            logger.info(f"ğŸ“Š ëª¨ë¸ ì…ë ¥ shape: {_model.input_shape}")
            logger.info(f"ğŸ“Š ëª¨ë¸ ì¶œë ¥ shape: {_model.output_shape}")

            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¶”ë¡ 
            try:
                test_input = np.random.random((1, 6)).astype(np.float32)
                test_output = _model.predict(test_input, verbose=0)
                logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì„±ê³µ: ì…ë ¥{test_input.shape} â†’ ì¶œë ¥{test_output.shape}")
            except Exception as test_e:
                logger.warning(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹¤íŒ¨: {test_e}")

        except Exception as e:
            logger.error(f"âŒ Keras ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    return _model


def get_saved_encoder():
    """ì €ì¥ëœ encoder.pklì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _encoder

    if _encoder is None:
        try:
            if not os.path.exists(ENCODER_PATH):
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")
                return None

            encoder_size = os.path.getsize(ENCODER_PATH)
            logger.info(f"ğŸ“¦ ì¸ì½”ë” ë¡œë”© ì‹œë„: {ENCODER_PATH} ({encoder_size}B)")

            with open(ENCODER_PATH, "rb") as f:
                _encoder = pickle.load(f)
            logger.info("âœ… encoder.pkl ë¡œë“œ ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ encoder.pkl ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    return _encoder


def get_fallback_encoder():
    """encoder.pklê³¼ í˜¸í™˜ë˜ëŠ” Fallback OrdinalEncoderë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global _fallback_encoder

    if _fallback_encoder is None:
        try:
            logger.info("ğŸ”§ Fallback OrdinalEncoder ìƒì„± ì¤‘...")

            from sklearn.preprocessing import OrdinalEncoder

            CATEGORIES = [
                ["men", "unisex", "women"],  # gender
                ["fall", "spring", "summer", "winter"],  # season_tags
                ["day", "night"],  # time_tags
                ["confident, fresh", "confident, mysterious", "elegant, friendly", "pure, friendly"],
                # desired_impression
                ["casual", "date", "work"],  # activity
                ["any", "cold", "hot", "rainy"]  # weather
            ]

            _fallback_encoder = OrdinalEncoder(
                categories=CATEGORIES,
                handle_unknown="error"
            )

            # ë”ë¯¸ ë°ì´í„°ë¡œ fit
            dummy_data = [
                ["men", "fall", "day", "confident, fresh", "casual", "any"],
                ["unisex", "spring", "night", "confident, mysterious", "date", "cold"],
                ["women", "summer", "day", "elegant, friendly", "work", "hot"],
                ["men", "winter", "night", "pure, friendly", "casual", "rainy"]
            ]

            _fallback_encoder.fit(dummy_data)
            logger.info("âœ… Fallback OrdinalEncoder ìƒì„± ë° í›ˆë ¨ ì™„ë£Œ")

            # ì¸ì½”ë” ê²€ì¦ í…ŒìŠ¤íŠ¸
            test_input = ["women", "spring", "day", "confident, fresh", "casual", "hot"]
            test_encoded = _fallback_encoder.transform([test_input])
            logger.info(f"ğŸ§ª Fallback ì¸ì½”ë” í…ŒìŠ¤íŠ¸ ì„±ê³µ: ì…ë ¥ 6ê°œ â†’ ì¶œë ¥ {test_encoded.shape[1]}ê°œ")

        except Exception as e:
            logger.error(f"âŒ Fallback encoder ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    return _fallback_encoder


def safe_transform_input(raw_features: list) -> np.ndarray:
    """ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ í•¨ìˆ˜"""
    try:
        # 1. ì €ì¥ëœ ì¸ì½”ë” ì‹œë„
        encoder = get_saved_encoder()
        if encoder:
            try:
                logger.info(f"ğŸ” ì €ì¥ëœ ì¸ì½”ë”ë¡œ ë³€í™˜ ì‹œë„: {raw_features}")
                transformed = encoder.transform([raw_features])
                logger.info(f"âœ… ì €ì¥ëœ ì¸ì½”ë” ë³€í™˜ ì„±ê³µ: {transformed.shape}")
                return transformed
            except Exception as e:
                logger.warning(f"âš ï¸ ì €ì¥ëœ ì¸ì½”ë” ì‹¤íŒ¨: {e}")

        # 2. Fallback ì¸ì½”ë” ì‹œë„
        fallback_encoder = get_fallback_encoder()
        if fallback_encoder:
            logger.info(f"ğŸ”„ Fallback ì¸ì½”ë”ë¡œ ë³€í™˜: {raw_features}")
            transformed = fallback_encoder.transform([raw_features])
            logger.info(f"âœ… Fallback ì¸ì½”ë” ë³€í™˜ ì„±ê³µ: {transformed.shape}")
            return transformed
        else:
            raise Exception("Fallback ì¸ì½”ë” ìƒì„± ì‹¤íŒ¨")

    except Exception as e:
        logger.error(f"âŒ ì…ë ¥ ë³€í™˜ ì™„ì „ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 5. AI ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_ai_model_for_first_recommendation(user_preferences: dict) -> Dict:
    """AI ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ 1ì°¨ ì¶”ì²œ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤."""
    try:
        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # API ì…ë ¥ì„ ëª¨ë¸ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        raw_features = [
            user_preferences["gender"],
            user_preferences["season_tags"],
            user_preferences["time_tags"],
            user_preferences["desired_impression"],
            user_preferences["activity"],
            user_preferences["weather"]
        ]

        logger.info(f"ğŸ”® AI ëª¨ë¸ ì…ë ¥ ë°ì´í„°: {raw_features}")

        # ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ ì‚¬ìš©
        x_input = safe_transform_input(raw_features)
        logger.info(f"ğŸ”® ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì‹œì‘ (ì…ë ¥ shape: {x_input.shape})")

        # ëª¨ë¸ ì˜ˆì¸¡
        preds = model.predict(x_input, verbose=0)
        cluster_probabilities = preds[0]
        predicted_cluster = int(np.argmax(cluster_probabilities))
        confidence = float(cluster_probabilities[predicted_cluster])

        logger.info(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°: {predicted_cluster} - ì‹ ë¢°ë„: {confidence:.3f}")

        # ê°ì • í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
            logger.info(f"ğŸ“‹ í´ëŸ¬ìŠ¤í„° {predicted_cluster} í–¥ìˆ˜ ê°œìˆ˜: {len(cluster_perfumes)}ê°œ")
        else:
            cluster_perfumes = df.copy()

        # ì¶”ê°€ í•„í„°ë§ (ì„±ë³„, ê³„ì ˆ ë“±)
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == user_preferences["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered

        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    user_preferences["season_tags"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered

        # ìƒìœ„ 10ê°œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        selected_indices = cluster_perfumes.head(10).index.tolist()

        return {
            "cluster": predicted_cluster,
            "confidence": confidence,
            "emotion_proba": [round(float(prob), 4) for prob in cluster_probabilities],
            "selected_idx": selected_indices
        }

    except Exception as e:
        logger.error(f"âŒ AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 6. ìŠ¤í‚¤ë§ˆ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class UserPreferences(BaseModel):
    """1ì°¨ ì¶”ì²œì„ ìœ„í•œ ì‚¬ìš©ì ì„ í˜¸ë„ (AI ëª¨ë¸ ì…ë ¥)"""

    gender: str = Field(..., description="ì„±ë³„", example="women")
    season_tags: str = Field(..., description="ê³„ì ˆ", example="spring")
    time_tags: str = Field(..., description="ì‹œê°„", example="day")
    desired_impression: str = Field(..., description="ì›í•˜ëŠ” ì¸ìƒ", example="confident, fresh")
    activity: str = Field(..., description="í™œë™", example="casual")
    weather: str = Field(..., description="ë‚ ì”¨", example="hot")


class SecondRecommendRequest(BaseModel):
    """2ì°¨ ì¶”ì²œ ìš”ì²­ ìŠ¤í‚¤ë§ˆ - AI ëª¨ë¸ í˜¸ì¶œ í¬í•¨"""

    user_preferences: UserPreferences = Field(
        ...,
        description="1ì°¨ ì¶”ì²œì„ ìœ„í•œ ì‚¬ìš©ì ì„ í˜¸ë„ (AI ëª¨ë¸ ì…ë ¥)"
    )

    user_note_scores: Dict[str, int] = Field(
        ...,
        description="ì‚¬ìš©ìì˜ ë…¸íŠ¸ë³„ ì„ í˜¸ë„ ì ìˆ˜ (0-5)",
        example={
            "jasmine": 5,
            "rose": 4,
            "amber": 3,
            "musk": 0,
            "citrus": 2,
            "vanilla": 1
        }
    )

    # Optional fields (ê¸°ì¡´ ë°©ì‹ í˜¸í™˜ì„± ìœ ì§€)
    emotion_proba: Optional[List[float]] = Field(
        None,
        description="6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„°ë³„ í™•ë¥  ë°°ì—´ (ì œê³µë˜ì§€ ì•Šìœ¼ë©´ AI ëª¨ë¸ë¡œ ê³„ì‚°)",
        min_items=6,
        max_items=6,
        example=[0.01, 0.03, 0.85, 0.02, 0.05, 0.04]
    )

    selected_idx: Optional[List[int]] = Field(
        None,
        description="1ì°¨ ì¶”ì²œì—ì„œ ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤ ëª©ë¡ (ì œê³µë˜ì§€ ì•Šìœ¼ë©´ AI ëª¨ë¸ë¡œ ê³„ì‚°)",
        min_items=1,
        max_items=20,
        example=[23, 45, 102, 200, 233, 305, 399, 410, 487, 512]
    )

    @validator('user_note_scores')
    def validate_note_scores(cls, v):
        for note, score in v.items():
            if not isinstance(score, int) or score < 0 or score > 5:
                raise ValueError(f"ë…¸íŠ¸ '{note}'ì˜ ì ìˆ˜ëŠ” 0-5 ì‚¬ì´ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    @validator('emotion_proba')
    def validate_emotion_proba(cls, v):
        if v is None:
            return v

        if len(v) != 6:
            raise ValueError("emotion_probaëŠ” ì •í™•íˆ 6ê°œì˜ í™•ë¥ ê°’ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.")

        total = sum(v)
        if not (0.95 <= total <= 1.05):
            raise ValueError(f"emotion_probaì˜ í•©ì€ 1.0ì— ê°€ê¹Œì›Œì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {total}")

        for prob in v:
            if not (0.0 <= prob <= 1.0):
                raise ValueError("ê° í™•ë¥ ê°’ì€ 0.0-1.0 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

        return v

    @validator('selected_idx')
    def validate_selected_idx(cls, v):
        if v is None:
            return v

        if len(set(v)) != len(v):
            raise ValueError("selected_idxì— ì¤‘ë³µëœ ì¸ë±ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤.")

        for idx in v:
            if idx < 0:
                raise ValueError("ì¸ë±ìŠ¤ëŠ” 0 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

        return v

    class Config:
        schema_extra = {
            "example": {
                "user_preferences": {
                    "gender": "women",
                    "season_tags": "spring",
                    "time_tags": "day",
                    "desired_impression": "confident, fresh",
                    "activity": "casual",
                    "weather": "hot"
                },
                "user_note_scores": {
                    "jasmine": 5,
                    "rose": 4,
                    "amber": 3,
                    "musk": 0,
                    "citrus": 2,
                    "vanilla": 1
                }
            }
        }


class SecondRecommendItem(BaseModel):
    """2ì°¨ ì¶”ì²œ ê²°ê³¼ ì•„ì´í…œ"""

    name: str = Field(..., description="í–¥ìˆ˜ ì´ë¦„")
    brand: str = Field(..., description="ë¸Œëœë“œëª…")
    final_score: float = Field(..., description="ìµœì¢… ì¶”ì²œ ì ìˆ˜ (0.0-1.0)", ge=0.0, le=1.0)
    emotion_cluster: int = Field(..., description="ê°ì • í´ëŸ¬ìŠ¤í„° ID (0-5)", ge=0, le=5)


# â”€â”€â”€ 7. ê°ì • í´ëŸ¬ìŠ¤í„° ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_CLUSTER_MAP = {
    0: "ì°¨ë¶„í•œ, í¸ì•ˆí•œ",
    1: "ìì‹ ê°, ì‹ ì„ í•¨",
    2: "ìš°ì•„í•¨, ì¹œê·¼í•¨",
    3: "ìˆœìˆ˜í•¨, ì¹œê·¼í•¨",
    4: "ì‹ ë¹„ë¡œìš´, ë§¤ë ¥ì ",
    5: "í™œê¸°ì°¬, ì—ë„ˆì§€"
}


# â”€â”€â”€ 8. ë…¸íŠ¸ ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_notes_from_string(notes_str: str) -> List[str]:
    """ë…¸íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ê°œë³„ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not notes_str or pd.isna(notes_str):
        return []

    # ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜
    notes = [note.strip().lower() for note in str(notes_str).split(',')]

    # ë¹ˆ ë¬¸ìì—´ ì œê±°
    notes = [note for note in notes if note and note != '']

    return notes


def normalize_note_name(note: str) -> str:
    """ë…¸íŠ¸ëª…ì„ ì •ê·œí™” (ìœ ì‚¬í•œ ë…¸íŠ¸ë“¤ì„ ë§¤ì¹­í•˜ê¸° ìœ„í•´)"""
    note = note.lower().strip()

    # ì¼ë°˜ì ì¸ ë…¸íŠ¸ëª… ì •ê·œí™” ê·œì¹™
    note_mappings = {
        # ì‹œíŠ¸ëŸ¬ìŠ¤ ê³„ì—´
        'bergamot': ['bergamot', 'bergamotte'],
        'lemon': ['lemon', 'citron'],
        'orange': ['orange', 'sweet orange'],
        'grapefruit': ['grapefruit', 'pink grapefruit'],
        'lime': ['lime', 'persian lime'],

        # í”Œë¡œëŸ´ ê³„ì—´
        'rose': ['rose', 'bulgarian rose', 'damascus rose', 'tea rose'],
        'jasmine': ['jasmine', 'sambac jasmine', 'star jasmine'],
        'lavender': ['lavender', 'french lavender'],
        'ylang-ylang': ['ylang-ylang', 'ylang ylang'],
        'iris': ['iris', 'orris'],

        # ìš°ë”” ê³„ì—´
        'cedar': ['cedar', 'cedarwood', 'atlas cedar'],
        'sandalwood': ['sandalwood', 'mysore sandalwood'],
        'oakmoss': ['oakmoss', 'oak moss'],
        'vetiver': ['vetiver', 'haitian vetiver'],

        # ì•°ë²„/ì˜¤ë¦¬ì—”íƒˆ ê³„ì—´
        'amber': ['amber', 'grey amber'],
        'musk': ['musk', 'white musk', 'red musk'],
        'vanilla': ['vanilla', 'madagascar vanilla'],
        'benzoin': ['benzoin', 'siam benzoin'],

        # ìŠ¤íŒŒì´ì‹œ ê³„ì—´
        'pepper': ['pepper', 'black pepper', 'pink pepper'],
        'cinnamon': ['cinnamon', 'ceylon cinnamon'],
        'cardamom': ['cardamom', 'green cardamom'],
        'ginger': ['ginger', 'fresh ginger']
    }

    # ë§¤í•‘ í…Œì´ë¸”ì—ì„œ ì •ê·œí™”ëœ ì´ë¦„ ì°¾ê¸°
    for normalized, variants in note_mappings.items():
        if note in variants:
            return normalized

    return note


def calculate_note_match_score(perfume_notes: List[str], user_note_scores: Dict[str, int]) -> float:
    """í–¥ìˆ˜ì˜ ë…¸íŠ¸ì™€ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ë¹„êµí•˜ì—¬ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
    if not perfume_notes or not user_note_scores:
        return 0.0

    # í–¥ìˆ˜ ë…¸íŠ¸ë¥¼ ì •ê·œí™”
    normalized_perfume_notes = [normalize_note_name(note) for note in perfume_notes]

    total_score = 0.0
    matched_notes_count = 0
    total_preference_weight = sum(user_note_scores.values())

    if total_preference_weight == 0:
        return 0.0

    for user_note, preference_score in user_note_scores.items():
        normalized_user_note = normalize_note_name(user_note)

        # ì •í™•í•œ ë§¤ì¹­
        if normalized_user_note in normalized_perfume_notes:
            # ì„ í˜¸ë„ ì ìˆ˜ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™” (5ì  ë§Œì )
            normalized_preference = preference_score / 5.0

            # ê°€ì¤‘ì¹˜ ì ìš©
            weight = preference_score / total_preference_weight

            contribution = normalized_preference * weight
            total_score += contribution
            matched_notes_count += 1

        # ë¶€ë¶„ ë§¤ì¹­
        else:
            partial_matches = []
            for perfume_note in normalized_perfume_notes:
                if normalized_user_note in perfume_note or perfume_note in normalized_user_note:
                    partial_matches.append(perfume_note)

            if partial_matches:
                # ë¶€ë¶„ ë§¤ì¹­ì€ 50% ê°€ì¤‘ì¹˜
                normalized_preference = (preference_score / 5.0) * 0.5
                weight = preference_score / total_preference_weight
                contribution = normalized_preference * weight
                total_score += contribution
                matched_notes_count += 0.5

    # ë§¤ì¹­ëœ ë…¸íŠ¸ê°€ ì—†ìœ¼ë©´ 0ì 
    if matched_notes_count == 0:
        return 0.0

    # ë§¤ì¹­ ë¹„ìœ¨ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
    match_ratio = matched_notes_count / len(user_note_scores)
    match_bonus = match_ratio * 0.1  # ìµœëŒ€ 10% ë³´ë„ˆìŠ¤

    final_score = min(1.0, total_score + match_bonus)

    return final_score


def calculate_emotion_cluster_weight(perfume_cluster: int, emotion_proba: List[float]) -> float:
    """í–¥ìˆ˜ì˜ ê°ì • í´ëŸ¬ìŠ¤í„°ì™€ ì‚¬ìš©ìì˜ ê°ì • í™•ë¥  ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    if perfume_cluster < 0 or perfume_cluster >= len(emotion_proba):
        logger.warning(f"âš ï¸ ì˜ëª»ëœ í´ëŸ¬ìŠ¤í„° ID: {perfume_cluster}")
        return 0.1  # ìµœì†Œ ê°€ì¤‘ì¹˜

    # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ í™•ë¥ ì„ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
    cluster_weight = emotion_proba[perfume_cluster]

    # ë„ˆë¬´ ë‚®ì€ ê°€ì¤‘ì¹˜ëŠ” ìµœì†Œê°’ìœ¼ë¡œ ë³´ì •
    cluster_weight = max(0.05, cluster_weight)

    return cluster_weight


def calculate_final_score(
        note_match_score: float,
        emotion_cluster_weight: float,
        diversity_bonus: float = 0.0
) -> float:
    """ìµœì¢… ì¶”ì²œ ì ìˆ˜ ê³„ì‚°"""
    # ë…¸íŠ¸ ë§¤ì¹­ ì ìˆ˜ 70%, ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜ 25%, ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ 5%
    final_score = (
            note_match_score * 0.70 +
            emotion_cluster_weight * 0.25 +
            diversity_bonus * 0.05
    )

    # 0.0 ~ 1.0 ë²”ìœ„ë¡œ ì •ê·œí™”
    final_score = max(0.0, min(1.0, final_score))

    return final_score


# â”€â”€â”€ 9. ë©”ì¸ ì¶”ì²œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_second_recommendation_with_ai(
        user_preferences: dict,
        user_note_scores: Dict[str, int],
        emotion_proba: Optional[List[float]] = None,
        selected_idx: Optional[List[int]] = None
) -> List[Dict]:
    """AI ëª¨ë¸ì„ í¬í•¨í•œ ì™„ì „í•œ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ í•¨ìˆ˜"""
    start_time = datetime.now()

    logger.info(f"ğŸ¯ AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")
    logger.info(f"  ğŸ“ ì‚¬ìš©ì ì„ í˜¸ë„: {user_preferences}")
    logger.info(f"  ğŸ¨ ë…¸íŠ¸ ì„ í˜¸ë„: {user_note_scores}")

    # emotion_proba ë˜ëŠ” selected_idxê°€ ì—†ìœ¼ë©´ AI ëª¨ë¸ í˜¸ì¶œ
    if emotion_proba is None or selected_idx is None:
        logger.info("ğŸ¤– AI ëª¨ë¸ë¡œ 1ì°¨ ì¶”ì²œ ìˆ˜í–‰ (emotion_proba ë˜ëŠ” selected_idx ì—†ìŒ)")

        try:
            ai_result = call_ai_model_for_first_recommendation(user_preferences)

            if emotion_proba is None:
                emotion_proba = ai_result["emotion_proba"]
                logger.info(f"âœ… AI ëª¨ë¸ì—ì„œ ê°ì • í™•ë¥  íšë“: í´ëŸ¬ìŠ¤í„° {ai_result['cluster']} ({ai_result['confidence']:.3f})")

            if selected_idx is None:
                selected_idx = ai_result["selected_idx"]
                logger.info(f"âœ… AI ëª¨ë¸ì—ì„œ ì„ íƒ ì¸ë±ìŠ¤ íšë“: {len(selected_idx)}ê°œ")

        except Exception as e:
            logger.error(f"âŒ AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ“‹ ë£° ê¸°ë°˜ í´ë°±ìœ¼ë¡œ ì „í™˜")

            # ë£° ê¸°ë°˜ í´ë°±
            emotion_proba = [0.1, 0.15, 0.4, 0.15, 0.1, 0.1]  # ê¸°ë³¸ í™•ë¥  ë¶„í¬

            # ê¸°ë³¸ í•„í„°ë§ìœ¼ë¡œ selected_idx ìƒì„±
            candidates = df.copy()
            if 'gender' in df.columns and user_preferences.get("gender"):
                gender_filtered = candidates[candidates['gender'] == user_preferences["gender"]]
                if not gender_filtered.empty:
                    candidates = gender_filtered

            selected_idx = candidates.head(10).index.tolist()
            logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ í´ë°±ìœ¼ë¡œ {len(selected_idx)}ê°œ ì¸ë±ìŠ¤ ìƒì„±")

    # ê¸°ì¡´ 2ì°¨ ì¶”ì²œ ë¡œì§ ìˆ˜í–‰
    return process_second_recommendation(user_note_scores, emotion_proba, selected_idx)


def process_second_recommendation(
        user_note_scores: Dict[str, int],
        emotion_proba: List[float],
        selected_idx: List[int]
) -> List[Dict]:
    """2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
    start_time = datetime.now()

    logger.info(f"ğŸ¯ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")
    logger.info(f"  ğŸ“ ì‚¬ìš©ì ë…¸íŠ¸ ì„ í˜¸ë„: {user_note_scores}")
    logger.info(f"  ğŸ§  ê°ì • í™•ë¥  ë¶„í¬: {[f'{p:.3f}' for p in emotion_proba]}")
    logger.info(f"  ğŸ“‹ ì„ íƒëœ ì¸ë±ìŠ¤: {selected_idx} (ì´ {len(selected_idx)}ê°œ)")

    # ì„ íƒëœ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ë“¤ í•„í„°ë§
    valid_indices = [idx for idx in selected_idx if idx < len(df)]
    invalid_indices = [idx for idx in selected_idx if idx >= len(df)]

    if invalid_indices:
        logger.warning(f"âš ï¸ ì˜ëª»ëœ ì¸ë±ìŠ¤ë“¤: {invalid_indices} (ë°ì´í„°ì…‹ í¬ê¸°: {len(df)})")

    if not valid_indices:
        raise ValueError("ìœ íš¨í•œ í–¥ìˆ˜ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    selected_perfumes = df.iloc[valid_indices].copy()
    logger.info(f"âœ… {len(selected_perfumes)}ê°œ í–¥ìˆ˜ ì„ íƒë¨")

    # ê° í–¥ìˆ˜ì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚°
    results = []
    brand_count = {}  # ë¸Œëœë“œë³„ ê°œìˆ˜ (ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ìš©)

    for idx, (_, row) in enumerate(selected_perfumes.iterrows()):
        try:
            # í–¥ìˆ˜ ê¸°ë³¸ ì •ë³´
            perfume_name = str(row['name'])
            perfume_brand = str(row['brand'])
            perfume_cluster = int(row.get('emotion_cluster', 0))
            perfume_notes_str = str(row.get('notes', ''))

            # ë…¸íŠ¸ íŒŒì‹±
            perfume_notes = parse_notes_from_string(perfume_notes_str)

            # 1. ë…¸íŠ¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            note_match_score = calculate_note_match_score(perfume_notes, user_note_scores)

            # 2. ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜ ê³„ì‚°
            emotion_weight = calculate_emotion_cluster_weight(perfume_cluster, emotion_proba)

            # 3. ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤ ê³„ì‚°
            brand_count[perfume_brand] = brand_count.get(perfume_brand, 0) + 1
            diversity_bonus = max(0.0, 0.1 - (brand_count[perfume_brand] - 1) * 0.02)

            # 4. ìµœì¢… ì ìˆ˜ ê³„ì‚°
            final_score = calculate_final_score(note_match_score, emotion_weight, diversity_bonus)

            # ê²°ê³¼ ì €ì¥
            result_item = {
                'name': perfume_name,
                'brand': perfume_brand,
                'final_score': round(final_score, 3),
                'emotion_cluster': perfume_cluster,
                'note_match_score': round(note_match_score, 3),
                'emotion_weight': round(emotion_weight, 3),
                'diversity_bonus': round(diversity_bonus, 3),
                'perfume_notes': perfume_notes,
                'original_index': valid_indices[idx]
            }

            results.append(result_item)

        except Exception as e:
            logger.error(f"âŒ í–¥ìˆ˜ '{row.get('name', 'Unknown')}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    # ìµœì¢… ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    results.sort(key=lambda x: x['final_score'], reverse=True)

    processing_time = (datetime.now() - start_time).total_seconds()

    logger.info(f"âœ… 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ í–¥ìˆ˜ (ì†Œìš”ì‹œê°„: {processing_time:.3f}ì´ˆ)")

    if results:
        top_scores = [r['final_score'] for r in results[:5]]
        logger.info(f"ğŸ“Š ìƒìœ„ 5ê°œ ì ìˆ˜: {top_scores}")

    return results


# â”€â”€â”€ 10. ë¼ìš°í„° ì„¤ì • ë° ëª¨ë¸ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/perfumes", tags=["Second Recommendation"])

# ì‹œì‘ ì‹œ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
logger.info("ğŸš€ 2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ (AI ëª¨ë¸ í¬í•¨) ì´ˆê¸°í™” ì‹œì‘...")
check_model_availability()
if _model_available:
    logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
else:
    logger.info("ğŸ“‹ ë£° ê¸°ë°˜ í´ë°± ì‹œìŠ¤í…œìœ¼ë¡œ ë™ì‘")
logger.info("âœ… 2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")


# â”€â”€â”€ 11. API ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post(
    "/recommend-2nd",
    response_model=List[SecondRecommendItem],
    summary="2ì°¨ í–¥ìˆ˜ ì¶”ì²œ - AI ëª¨ë¸ + ë…¸íŠ¸ ì„ í˜¸ë„ ê¸°ë°˜",
    description=(
            "ğŸ¯ **ì™„ì „í•œ End-to-End 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API**\n\n"
            "ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ 1ì°¨ ì¶”ì²œì„ ìˆ˜í–‰í•œ í›„,\n"
            "ë…¸íŠ¸ ì„ í˜¸ë„ì™€ ê²°í•©í•˜ì—¬ ì •ë°€í•œ 2ì°¨ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.\n\n"
            "**ğŸ“¥ ì…ë ¥ ì •ë³´:**\n"
            "- `user_preferences`: ì‚¬ìš©ì ê¸°ë³¸ ì„ í˜¸ë„ (AI ëª¨ë¸ ì…ë ¥ìš©)\n"
            "- `user_note_scores`: ì‚¬ìš©ìì˜ ë…¸íŠ¸ë³„ ì„ í˜¸ë„ ì ìˆ˜ (0-5)\n"
            "- `emotion_proba` (ì„ íƒ): ê°ì • í™•ë¥  ë°°ì—´\n"
            "- `selected_idx` (ì„ íƒ): ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤\n\n"
            "**ğŸ¤– ì²˜ë¦¬ ê³¼ì •:**\n"
            "1. **AI ëª¨ë¸ í˜¸ì¶œ**: user_preferences â†’ ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡\n"
            "2. **ë…¸íŠ¸ ë§¤ì¹­**: user_note_scoresì™€ í–¥ìˆ˜ ë…¸íŠ¸ ë¹„êµ\n"
            "3. **ì ìˆ˜ ê³„ì‚°**: ë…¸íŠ¸ ë§¤ì¹­(70%) + ê°ì • ê°€ì¤‘ì¹˜(25%) + ë‹¤ì–‘ì„±(5%)\n"
            "4. **ìµœì¢… ì •ë ¬**: ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n\n"
            "**âœ¨ íŠ¹ì§•:**\n"
            "- ğŸ¤– AI ëª¨ë¸ ìë™ í˜¸ì¶œë¡œ ì™„ì „í•œ ì¶”ì²œ íŒŒì´í”„ë¼ì¸\n"
            "- ğŸ¯ ì •í™•í•œ ë…¸íŠ¸ ë§¤ì¹­ + ë¶€ë¶„ ë§¤ì¹­ ì§€ì›\n"
            "- ğŸ”„ AI ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ë£° ê¸°ë°˜ í´ë°±\n"
            "- ğŸŒŸ ë¸Œëœë“œ ë‹¤ì–‘ì„± ë³´ì¥"
    )
)
def recommend_second_perfumes(request: SecondRecommendRequest):
    """AI ëª¨ë¸ í¬í•¨ ì™„ì „í•œ 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API"""

    request_start_time = datetime.now()

    logger.info(f"ğŸ†• AI ëª¨ë¸ í¬í•¨ 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­ ì ‘ìˆ˜")
    logger.info(f"  ğŸ‘¤ ì‚¬ìš©ì ì„ í˜¸ë„: {request.user_preferences.dict()}")
    logger.info(f"  ğŸ“Š ë…¸íŠ¸ ì„ í˜¸ë„ ê°œìˆ˜: {len(request.user_note_scores)}ê°œ")

    # emotion_probaë‚˜ selected_idx ì œê³µ ì—¬ë¶€ í™•ì¸
    has_emotion_proba = request.emotion_proba is not None
    has_selected_idx = request.selected_idx is not None

    if has_emotion_proba and has_selected_idx:
        logger.info(f"  ğŸ§  ê°ì • í™•ë¥  ì œê³µë¨: ìµœê³  {max(request.emotion_proba):.3f}")
        logger.info(f"  ğŸ“‹ ì„ íƒ ì¸ë±ìŠ¤ ì œê³µë¨: {len(request.selected_idx)}ê°œ")
        logger.info("  âš¡ 2ì°¨ ì¶”ì²œ ë°”ë¡œ ì‹¤í–‰ (AI ëª¨ë¸ í˜¸ì¶œ ê±´ë„ˆëœ€)")
    else:
        logger.info("  ğŸ¤– emotion_proba ë˜ëŠ” selected_idx ì—†ìŒ â†’ AI ëª¨ë¸ í˜¸ì¶œ ì˜ˆì •")

    try:
        # ë©”ì¸ ì¶”ì²œ ì²˜ë¦¬ (AI ëª¨ë¸ í¬í•¨)
        results = process_second_recommendation_with_ai(
            user_preferences=request.user_preferences.dict(),
            user_note_scores=request.user_note_scores,
            emotion_proba=request.emotion_proba,
            selected_idx=request.selected_idx
        )

        if not results:
            raise HTTPException(
                status_code=404,
                detail="ì¶”ì²œí•  ìˆ˜ ìˆëŠ” í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        # ì‘ë‹µ í˜•íƒœë¡œ ë³€í™˜
        response_items = []
        for result in results:
            response_items.append(
                SecondRecommendItem(
                    name=result['name'],
                    brand=result['brand'],
                    final_score=result['final_score'],
                    emotion_cluster=result['emotion_cluster']
                )
            )

        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        total_processing_time = (datetime.now() - request_start_time).total_seconds()

        logger.info(f"âœ… AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì™„ë£Œ: {len(response_items)}ê°œ í–¥ìˆ˜")
        logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.3f}ì´ˆ")
        logger.info(f"ğŸ“Š ìµœê³  ì ìˆ˜: {response_items[0].final_score:.3f} ({response_items[0].name})")
        logger.info(f"ğŸ“Š ìµœì € ì ìˆ˜: {response_items[-1].final_score:.3f} ({response_items[-1].name})")

        # AI ëª¨ë¸ í˜¸ì¶œ ì—¬ë¶€ ë¡œê¹…
        if not has_emotion_proba or not has_selected_idx:
            logger.info("ğŸ¤– AI ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í˜¸ì¶œë˜ì–´ 1ì°¨ ì¶”ì²œ ìˆ˜í–‰ë¨")
        else:
            logger.info("âš¡ ì œê³µëœ ë°ì´í„°ë¡œ 2ì°¨ ì¶”ì²œë§Œ ìˆ˜í–‰ë¨ (AI ëª¨ë¸ í˜¸ì¶œ ì—†ìŒ)")

        return response_items

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get(
    "/system-status",
    summary="2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ ìƒíƒœ",
    description="2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ìƒíƒœì™€ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
)
def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ API"""

    try:
        # ë°ì´í„°ì…‹ í†µê³„
        total_perfumes = len(df)
        unique_brands = df['brand'].nunique() if 'brand' in df.columns else 0

        # ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„í¬
        cluster_distribution = {}
        if 'emotion_cluster' in df.columns:
            cluster_counts = df['emotion_cluster'].value_counts().to_dict()
            cluster_distribution = {int(k): int(v) for k, v in cluster_counts.items()}

        # ë…¸íŠ¸ í†µê³„ (ìƒ˜í”Œë§)
        all_notes = []
        for _, row in df.head(100).iterrows():  # ì²˜ìŒ 100ê°œë§Œ ìƒ˜í”Œë§
            notes = parse_notes_from_string(str(row.get('notes', '')))
            all_notes.extend(notes)

        note_frequency = Counter(all_notes)
        top_notes = dict(note_frequency.most_common(20))

        return {
            "system_status": "operational",
            "model_available": _model_available,
            "dataset_info": {
                "total_perfumes": total_perfumes,
                "unique_brands": unique_brands,
                "columns": list(df.columns),
                "sample_size_for_notes": 100
            },
            "emotion_clusters": {
                "available_clusters": list(EMOTION_CLUSTER_MAP.keys()),
                "cluster_descriptions": EMOTION_CLUSTER_MAP,
                "distribution": cluster_distribution
            },
            "note_analysis": {
                "top_20_notes": top_notes,
                "unique_notes_in_sample": len(note_frequency),
                "total_note_occurrences": len(all_notes)
            },
            "supported_features": [
                "ë…¸íŠ¸ ì„ í˜¸ë„ ê¸°ë°˜ ë§¤ì¹­",
                "ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜",
                "ë¸Œëœë“œ ë‹¤ì–‘ì„± ë³´ì¥",
                "ë…¸íŠ¸ëª… ì •ê·œí™”",
                "ë¶€ë¶„ ë§¤ì¹­ ì§€ì›"
            ]
        }

    except Exception as e:
        logger.error(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )