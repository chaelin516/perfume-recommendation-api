# routers/recommend_2nd_router.py - AI ëª¨ë¸ í•¨ìˆ˜ ì¶”ê°€ ë° ì™„ì „ ìˆ˜ì •

import os
import pickle
import logging
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field, validator
from collections import Counter
import re

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recommend_2nd_router")

# â”€â”€â”€ 1. ë°ì´í„° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/perfume_final_dataset.csv")
try:
    df = pd.read_csv(DATA_PATH)
    df.fillna("", inplace=True)
    logger.info(f"âœ… Perfume dataset loaded: {df.shape[0]} rows")

    # emotion_cluster ì»¬ëŸ¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
    if 'emotion_cluster' in df.columns:
        df['emotion_cluster'] = pd.to_numeric(df['emotion_cluster'], errors='coerce').fillna(0).astype(int)
        logger.info(f"ğŸ“Š Emotion clusters: {sorted(df['emotion_cluster'].unique())}")

    logger.info(f"ğŸ“‹ Available columns: {list(df.columns)}")

except Exception as e:
    logger.error(f"âŒ perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    raise RuntimeError(f"perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# â”€â”€â”€ 2. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "../models/final_model.keras")
ENCODER_PATH = os.path.join(BASE_DIR, "../models/encoder.pkl")

# â”€â”€â”€ 3. ì „ì—­ ë³€ìˆ˜ ë° ìƒíƒœ ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_model = None
_encoder = None
_model_available = False
_fallback_encoder = None


# â”€â”€â”€ 4. ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_model_availability():
    """ëª¨ë¸ íŒŒì¼ë“¤ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    global _model_available

    logger.info("ğŸ” ëª¨ë¸ íŒŒì¼ ê°€ìš©ì„± í™•ì¸ ì¤‘...")

    try:
        model_exists = os.path.exists(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH)

        model_valid = False
        encoder_valid = False

        if model_exists:
            model_size = os.path.getsize(MODEL_PATH)
            model_valid = model_size > 10000  # 10KB ì´ìƒ
            logger.info(f"ğŸ“„ ëª¨ë¸ íŒŒì¼: {model_size:,}B ({model_size / 1024:.1f}KB) {'âœ…' if model_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")

        if encoder_exists:
            encoder_size = os.path.getsize(ENCODER_PATH)
            encoder_valid = encoder_size > 500  # 500B ì´ìƒ
            logger.info(f"ğŸ“„ ì¸ì½”ë” íŒŒì¼: {encoder_size:,}B ({encoder_size}B) {'âœ…' if encoder_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")

        _model_available = model_valid and encoder_valid
        logger.info(f"ğŸ¤– ëª¨ë¸ ê°€ìš©ì„±: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if _model_available else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")

        return _model_available

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        _model_available = False
        return False


# â”€â”€â”€ 5. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_model():
    """Keras ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model

    if _model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
                return None

            model_size = os.path.getsize(MODEL_PATH)
            if model_size < 10000:
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {model_size} bytes")
                return None

            logger.info(f"ğŸ“¦ ëª¨ë¸ ë¡œë”© ì‹œì‘: {model_size:,}B ({model_size / 1024:.1f}KB)")

            try:
                import tensorflow as tf
                from tensorflow import keras
                load_model = keras.models.load_model
                logger.info(f"ğŸ“¦ TensorFlow {tf.__version__} ì‚¬ìš©")
            except ImportError:
                logger.error("âŒ TensorFlowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None

            _model = load_model(MODEL_PATH, compile=False)
            logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
            logger.info(f"ğŸ“Š ì…ë ¥ shape: {_model.input_shape}")
            logger.info(f"ğŸ“Š ì¶œë ¥ shape: {_model.output_shape}")

            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            test_input = np.random.random((1, 6)).astype(np.float32)
            test_output = _model.predict(test_input, verbose=0)
            logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì„±ê³µ: {test_output.shape}")

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            return None

    return _model


def get_saved_encoder():
    """ì €ì¥ëœ encoder.pklì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _encoder

    if _encoder is None:
        try:
            if not os.path.exists(ENCODER_PATH):
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")
                return None

            with open(ENCODER_PATH, "rb") as f:
                _encoder = pickle.load(f)
            logger.info("âœ… encoder.pkl ë¡œë“œ ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ encoder.pkl ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    return _encoder


def get_fallback_encoder():
    """Fallback OrdinalEncoderë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global _fallback_encoder

    if _fallback_encoder is None:
        try:
            from sklearn.preprocessing import OrdinalEncoder

            CATEGORIES = [
                ["men", "unisex", "women"],
                ["fall", "spring", "summer", "winter"],
                ["day", "night"],
                ["confident, fresh", "confident, mysterious", "elegant, friendly", "pure, friendly"],
                ["casual", "date", "work"],
                ["any", "cold", "hot", "rainy"]
            ]

            _fallback_encoder = OrdinalEncoder(
                categories=CATEGORIES,
                handle_unknown="error"
            )

            dummy_data = [
                ["men", "fall", "day", "confident, fresh", "casual", "any"],
                ["unisex", "spring", "night", "confident, mysterious", "date", "cold"],
                ["women", "summer", "day", "elegant, friendly", "work", "hot"],
                ["men", "winter", "night", "pure, friendly", "casual", "rainy"]
            ]

            _fallback_encoder.fit(dummy_data)
            logger.info("âœ… Fallback OrdinalEncoder ìƒì„± ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ Fallback encoder ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    return _fallback_encoder


def safe_transform_input(raw_features: list) -> np.ndarray:
    """ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ í•¨ìˆ˜"""
    try:
        encoder = get_saved_encoder()
        if encoder:
            try:
                transformed = encoder.transform([raw_features])
                logger.info(f"âœ… ì €ì¥ëœ ì¸ì½”ë” ë³€í™˜ ì„±ê³µ")
                return transformed
            except Exception as e:
                logger.warning(f"âš ï¸ ì €ì¥ëœ ì¸ì½”ë” ì‹¤íŒ¨: {e}")

        fallback_encoder = get_fallback_encoder()
        if fallback_encoder:
            transformed = fallback_encoder.transform([raw_features])
            logger.info(f"âœ… Fallback ì¸ì½”ë” ë³€í™˜ ì„±ê³µ")
            return transformed
        else:
            raise Exception("Fallback ì¸ì½”ë” ìƒì„± ì‹¤íŒ¨")

    except Exception as e:
        logger.error(f"âŒ ì…ë ¥ ë³€í™˜ ì™„ì „ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 6. AI ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜ (ëˆ„ë½ëœ í•¨ìˆ˜ ì¶”ê°€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def call_ai_model_for_first_recommendation(user_preferences: dict) -> Dict:
    """
    1ì°¨ ì¶”ì²œì„ ìœ„í•œ AI ëª¨ë¸ í˜¸ì¶œ í•¨ìˆ˜

    Args:
        user_preferences: ì‚¬ìš©ì ì„ í˜¸ë„ ë”•ì…”ë„ˆë¦¬

    Returns:
        Dict: AI ëª¨ë¸ ê²°ê³¼ (cluster, emotion_proba, selected_idx í¬í•¨)
    """
    try:
        logger.info(f"ğŸ¤– AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ í˜¸ì¶œ ì‹œì‘")

        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # ì…ë ¥ ë°ì´í„° ë³€í™˜
        raw_features = [
            user_preferences["gender"],
            user_preferences["season_tags"],
            user_preferences["time_tags"],
            user_preferences["desired_impression"],
            user_preferences["activity"],
            user_preferences["weather"]
        ]

        logger.info(f"ğŸ”® AI ëª¨ë¸ ì…ë ¥: {raw_features}")

        # ì…ë ¥ ë³€í™˜
        x_input = safe_transform_input(raw_features)

        # ëª¨ë¸ ì˜ˆì¸¡
        preds = model.predict(x_input, verbose=0)
        cluster_probabilities = preds[0]
        predicted_cluster = int(np.argmax(cluster_probabilities))
        confidence = float(cluster_probabilities[predicted_cluster])

        logger.info(f"ğŸ¯ ì˜ˆì¸¡ í´ëŸ¬ìŠ¤í„°: {predicted_cluster} (ì‹ ë¢°ë„: {confidence:.3f})")

        # í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
        else:
            cluster_perfumes = df.copy()

        # ì¶”ê°€ í•„í„°ë§
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == user_preferences["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered

        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    user_preferences["season_tags"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered

        # ìƒìœ„ 10ê°œ ì¸ë±ìŠ¤ ì„ íƒ
        selected_indices = cluster_perfumes.head(10).index.tolist()

        result = {
            "cluster": predicted_cluster,
            "confidence": confidence,
            "emotion_proba": [float(p) for p in cluster_probabilities],
            "selected_idx": selected_indices,
            "total_cluster_perfumes": len(cluster_perfumes)
        }

        logger.info(f"âœ… AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ ì™„ë£Œ: {len(selected_indices)}ê°œ í–¥ìˆ˜")
        return result

    except Exception as e:
        logger.error(f"âŒ AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 7. ìŠ¤í‚¤ë§ˆ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class UserPreferences(BaseModel):
    """1ì°¨ ì¶”ì²œì„ ìœ„í•œ ì‚¬ìš©ì ì„ í˜¸ë„"""
    gender: str = Field(..., description="ì„±ë³„", example="men")
    season_tags: str = Field(..., description="ê³„ì ˆ", example="winter")
    time_tags: str = Field(..., description="ì‹œê°„", example="night")
    desired_impression: str = Field(..., description="ì›í•˜ëŠ” ì¸ìƒ", example="mysterious, elegant")
    activity: str = Field(..., description="í™œë™", example="date")
    weather: str = Field(..., description="ë‚ ì”¨", example="cold")


class SecondRecommendRequest(BaseModel):
    """2ì°¨ ì¶”ì²œ ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    user_preferences: UserPreferences = Field(..., description="1ì°¨ ì¶”ì²œì„ ìœ„í•œ ì‚¬ìš©ì ì„ í˜¸ë„")

    # ğŸ”§ ì´ ë¶€ë¶„ì„ ìˆ˜ì • - example ì¶”ê°€
    user_note_scores: Dict[str, int] = Field(
        ...,
        description="ì‚¬ìš©ìì˜ ë…¸íŠ¸ë³„ ì„ í˜¸ë„ ì ìˆ˜ (0-5)",
        example={
            "amber": 1,
            "citrus": 4,
            "jasmine": 2,
            "musk": 5,
            "rose": 0,
            "vanilla": 3
        }
    )

    # ğŸ”§ ì´ ë¶€ë¶„ë“¤ë„ ìˆ˜ì • - example ì¶”ê°€
    emotion_proba: Optional[List[float]] = Field(
        None,
        description="6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„°ë³„ í™•ë¥  ë°°ì—´",
        example=[0.05, 0.10, 0.20, 0.15, 0.30, 0.20]
    )

    selected_idx: Optional[List[int]] = Field(
        None,
        description="1ì°¨ ì¶”ì²œì—ì„œ ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤ ëª©ë¡",
        example=[10, 58, 124, 256, 317, 405, 478, 551, 612, 719]
    )

    @validator('user_note_scores')
    def validate_note_scores(cls, v):
        for note, score in v.items():
            if not isinstance(score, int) or score < 0 or score > 5:
                raise ValueError(f"ë…¸íŠ¸ '{note}'ì˜ ì ìˆ˜ëŠ” 0-5 ì‚¬ì´ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return v

    @validator('emotion_proba')
    def validate_emotion_proba(cls, v):
        if v is None:
            return v
        if len(v) != 6:
            raise ValueError("emotion_probaëŠ” ì •í™•íˆ 6ê°œì˜ í™•ë¥ ê°’ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.")
        total = sum(v)
        if not (0.95 <= total <= 1.05):
            raise ValueError(f"emotion_probaì˜ í•©ì€ 1.0ì— ê°€ê¹Œì›Œì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {total}")
        return v

    # Config í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
    class Config:
        schema_extra = {
            "example": {
                "user_preferences": {
                    "gender": "men",
                    "season_tags": "winter",
                    "time_tags": "night",
                    "desired_impression": "mysterious, elegant",
                    "activity": "date",
                    "weather": "cold"
                },
                "user_note_scores": {
                    "amber": 1,
                    "citrus": 4,
                    "jasmine": 2,
                    "musk": 5,
                    "rose": 0,
                    "vanilla": 3
                },
                "emotion_proba": [0.05, 0.10, 0.20, 0.15, 0.30, 0.20],
                "selected_idx": [10, 58, 124, 256, 317, 405, 478, 551, 612, 719]
            }
        }

class SecondRecommendItem(BaseModel):
    """2ì°¨ ì¶”ì²œ ê²°ê³¼ ì•„ì´í…œ"""
    name: str = Field(..., description="í–¥ìˆ˜ ì´ë¦„")
    brand: str = Field(..., description="ë¸Œëœë“œëª…")
    final_score: float = Field(..., description="ìµœì¢… ì¶”ì²œ ì ìˆ˜", ge=0.0, le=1.0)
    emotion_cluster: int = Field(..., description="ê°ì • í´ëŸ¬ìŠ¤í„° ID", ge=0, le=5)
    image_url: str = Field(..., description="í–¥ìˆ˜ ì´ë¯¸ì§€ URL")  # ğŸ†• ì¶”ê°€

    class Config:
        schema_extra = {
            "example": {
                "name": "Black Opium Nuit Blanche",
                "brand": "Yves Saint Laurent",
                "final_score": 0.383,
                "emotion_cluster": 3,
                "image_url": "https://img.fragrancex.com/images/products/parent/medium/73667w.jpg"
            }
        }

# â”€â”€â”€ 8. ë…¸íŠ¸ ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_notes_from_string(notes_str: str) -> List[str]:
    """ë…¸íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ê°œë³„ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not notes_str or pd.isna(notes_str):
        return []
    notes = [note.strip().lower() for note in str(notes_str).split(',')]
    notes = [note for note in notes if note and note != '']
    return notes


def normalize_note_name(note: str) -> str:
    """ë…¸íŠ¸ëª…ì„ ì •ê·œí™”"""
    note = note.lower().strip()

    note_mappings = {
        'bergamot': ['bergamot', 'bergamotte'],
        'lemon': ['lemon', 'citron'],
        'orange': ['orange', 'sweet orange'],
        'rose': ['rose', 'bulgarian rose', 'damascus rose'],
        'jasmine': ['jasmine', 'sambac jasmine', 'star jasmine'],
        'lavender': ['lavender', 'french lavender'],
        'cedar': ['cedar', 'cedarwood', 'atlas cedar'],
        'sandalwood': ['sandalwood', 'mysore sandalwood'],
        'amber': ['amber', 'grey amber'],
        'musk': ['musk', 'white musk', 'red musk'],
        'vanilla': ['vanilla', 'madagascar vanilla'],
    }

    for normalized, variants in note_mappings.items():
        if note in variants:
            return normalized
    return note


def calculate_note_match_score(perfume_notes: List[str], user_note_scores: Dict[str, int]) -> float:
    """í–¥ìˆ˜ì˜ ë…¸íŠ¸ì™€ ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ë¹„êµí•˜ì—¬ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°"""
    if not perfume_notes or not user_note_scores:
        return 0.0

    normalized_perfume_notes = [normalize_note_name(note) for note in perfume_notes]
    total_score = 0.0
    matched_notes_count = 0
    total_preference_weight = sum(user_note_scores.values())

    if total_preference_weight == 0:
        return 0.0

    for user_note, preference_score in user_note_scores.items():
        normalized_user_note = normalize_note_name(user_note)

        if normalized_user_note in normalized_perfume_notes:
            normalized_preference = preference_score / 5.0
            weight = preference_score / total_preference_weight
            contribution = normalized_preference * weight
            total_score += contribution
            matched_notes_count += 1
        else:
            # ë¶€ë¶„ ë§¤ì¹­
            partial_matches = [note for note in normalized_perfume_notes
                               if normalized_user_note in note or note in normalized_user_note]
            if partial_matches:
                normalized_preference = (preference_score / 5.0) * 0.5
                weight = preference_score / total_preference_weight
                contribution = normalized_preference * weight
                total_score += contribution
                matched_notes_count += 0.5

    if matched_notes_count == 0:
        return 0.0

    match_ratio = matched_notes_count / len(user_note_scores)
    match_bonus = match_ratio * 0.1
    final_score = min(1.0, total_score + match_bonus)

    return final_score


def calculate_emotion_cluster_weight(perfume_cluster: int, emotion_proba: List[float]) -> float:
    """ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    if perfume_cluster < 0 or perfume_cluster >= len(emotion_proba):
        return 0.1
    cluster_weight = emotion_proba[perfume_cluster]
    cluster_weight = max(0.05, cluster_weight)
    return cluster_weight


def calculate_final_score(note_match_score: float, emotion_cluster_weight: float,
                          diversity_bonus: float = 0.0) -> float:
    """ìµœì¢… ì¶”ì²œ ì ìˆ˜ ê³„ì‚°"""
    final_score = (
            note_match_score * 0.70 +
            emotion_cluster_weight * 0.25 +
            diversity_bonus * 0.05
    )
    final_score = max(0.0, min(1.0, final_score))
    return final_score


# â”€â”€â”€ 9. ë©”ì¸ ì¶”ì²œ í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def process_second_recommendation_with_ai(
        user_preferences: dict,
        user_note_scores: Dict[str, int],
        emotion_proba: Optional[List[float]] = None,
        selected_idx: Optional[List[int]] = None
) -> List[Dict]:
    """AI ëª¨ë¸ì„ í¬í•¨í•œ ì™„ì „í•œ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ í•¨ìˆ˜"""

    start_time = datetime.now()
    logger.info(f"ğŸ¯ AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")

    # emotion_proba ë˜ëŠ” selected_idxê°€ ì—†ìœ¼ë©´ AI ëª¨ë¸ í˜¸ì¶œ
    if emotion_proba is None or selected_idx is None:
        logger.info("ğŸ¤– AI ëª¨ë¸ë¡œ 1ì°¨ ì¶”ì²œ ìˆ˜í–‰")

        try:
            ai_result = call_ai_model_for_first_recommendation(user_preferences)

            if emotion_proba is None:
                emotion_proba = ai_result["emotion_proba"]
                logger.info(f"âœ… AI ëª¨ë¸ì—ì„œ ê°ì • í™•ë¥  íšë“")

            if selected_idx is None:
                selected_idx = ai_result["selected_idx"]
                logger.info(f"âœ… AI ëª¨ë¸ì—ì„œ ì„ íƒ ì¸ë±ìŠ¤ íšë“: {len(selected_idx)}ê°œ")

        except Exception as e:
            logger.error(f"âŒ AI ëª¨ë¸ 1ì°¨ ì¶”ì²œ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ“‹ ë£° ê¸°ë°˜ í´ë°±ìœ¼ë¡œ ì „í™˜")

            emotion_proba = [0.1, 0.15, 0.4, 0.15, 0.1, 0.1]
            candidates = df.copy()
            if 'gender' in df.columns and user_preferences.get("gender"):
                gender_filtered = candidates[candidates['gender'] == user_preferences["gender"]]
                if not gender_filtered.empty:
                    candidates = gender_filtered
            selected_idx = candidates.head(10).index.tolist()
            logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ í´ë°±ìœ¼ë¡œ {len(selected_idx)}ê°œ ì¸ë±ìŠ¤ ìƒì„±")

    # ê¸°ì¡´ 2ì°¨ ì¶”ì²œ ë¡œì§ ìˆ˜í–‰
    return process_second_recommendation(user_note_scores, emotion_proba, selected_idx)


def process_second_recommendation(
        user_note_scores: Dict[str, int],
        emotion_proba: List[float],
        selected_idx: List[int]
) -> List[Dict]:
    """2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""

    start_time = datetime.now()
    logger.info(f"ğŸ¯ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì‹œì‘")

    # ì„ íƒëœ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ë“¤ í•„í„°ë§
    valid_indices = [idx for idx in selected_idx if idx < len(df)]

    if not valid_indices:
        raise ValueError("ìœ íš¨í•œ í–¥ìˆ˜ ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    selected_perfumes = df.iloc[valid_indices].copy()
    logger.info(f"âœ… {len(selected_perfumes)}ê°œ í–¥ìˆ˜ ì„ íƒë¨")

    # ê° í–¥ìˆ˜ì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚°
    results = []
    brand_count = {}

    for idx, (_, row) in enumerate(selected_perfumes.iterrows()):
        try:
            perfume_name = str(row['name'])
            perfume_brand = str(row['brand'])
            perfume_cluster = int(row.get('emotion_cluster', 0))
            perfume_notes_str = str(row.get('notes', ''))

            perfume_notes = parse_notes_from_string(perfume_notes_str)
            note_match_score = calculate_note_match_score(perfume_notes, user_note_scores)
            emotion_weight = calculate_emotion_cluster_weight(perfume_cluster, emotion_proba)

            brand_count[perfume_brand] = brand_count.get(perfume_brand, 0) + 1
            diversity_bonus = max(0.0, 0.1 - (brand_count[perfume_brand] - 1) * 0.02)

            final_score = calculate_final_score(note_match_score, emotion_weight, diversity_bonus)

            result_item = {
                'name': perfume_name,
                'brand': perfume_brand,
                'final_score': round(final_score, 3),
                'emotion_cluster': perfume_cluster,
                'image_url': str(row.get('image_url', '')),
                'note_match_score': round(note_match_score, 3),
                'emotion_weight': round(emotion_weight, 3),
                'diversity_bonus': round(diversity_bonus, 3),
                'perfume_notes': perfume_notes,
                'original_index': valid_indices[idx]
            }

            results.append(result_item)

        except Exception as e:
            logger.error(f"âŒ í–¥ìˆ˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            continue

    # ìµœì¢… ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    results.sort(key=lambda x: x['final_score'], reverse=True)

    processing_time = (datetime.now() - start_time).total_seconds()
    logger.info(f"âœ… 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ í–¥ìˆ˜ (ì†Œìš”ì‹œê°„: {processing_time:.3f}ì´ˆ)")

    return results


# â”€â”€â”€ 10. ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/perfumes", tags=["Second Recommendation"])

# ì‹œì‘ ì‹œ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
logger.info("ğŸš€ 2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
check_model_availability()
logger.info("âœ… 2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")


# â”€â”€â”€ 11. API ì—”ë“œí¬ì¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.post(
    "/recommend-2nd",
    response_model=List[SecondRecommendItem],
    summary="2ì°¨ í–¥ìˆ˜ ì¶”ì²œ - AI ëª¨ë¸ + ë…¸íŠ¸ ì„ í˜¸ë„ ê¸°ë°˜",
    description=(
            "ğŸ¯ **ì™„ì „í•œ End-to-End 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API**\n\n"
            "ì‚¬ìš©ì ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ 1ì°¨ ì¶”ì²œì„ ìˆ˜í–‰í•œ í›„,\n"
            "ë…¸íŠ¸ ì„ í˜¸ë„ì™€ ê²°í•©í•˜ì—¬ ì •ë°€í•œ 2ì°¨ ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤.\n\n"
            "**ğŸ“¥ ì…ë ¥ ì •ë³´:**\n"
            "- `user_preferences`: ì‚¬ìš©ì ê¸°ë³¸ ì„ í˜¸ë„ (AI ëª¨ë¸ ì…ë ¥ìš©)\n"
            "- `user_note_scores`: ì‚¬ìš©ìì˜ ë…¸íŠ¸ë³„ ì„ í˜¸ë„ ì ìˆ˜ (0-5)\n"
            "- `emotion_proba` (ì„ íƒ): ê°ì • í™•ë¥  ë°°ì—´\n"
            "- `selected_idx` (ì„ íƒ): ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤\n\n"
            "**ğŸ¤– ì²˜ë¦¬ ê³¼ì •:**\n"
            "1. AI ëª¨ë¸ í˜¸ì¶œ â†’ ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ + í–¥ìˆ˜ ì„ íƒ\n"
            "2. ë…¸íŠ¸ ë§¤ì¹­ â†’ ì •í™•í•œ ë…¸íŠ¸ ë¹„êµ\n"
            "3. ì ìˆ˜ ê³„ì‚° â†’ ë…¸íŠ¸(70%) + ê°ì •(25%) + ë‹¤ì–‘ì„±(5%)\n"
            "4. ìµœì¢… ì •ë ¬ â†’ ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ\n\n"
            "**âœ¨ íŠ¹ì§•:**\n"
            "- ğŸ¤– ì™„ì „ ìë™í™”ëœ ì¶”ì²œ íŒŒì´í”„ë¼ì¸\n"
            "- ğŸ¯ ì •ë°€í•œ ë…¸íŠ¸ ë§¤ì¹­\n"
            "- ğŸ”„ AI ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ í´ë°±\n"
            "- ğŸŒŸ ë¸Œëœë“œ ë‹¤ì–‘ì„± ë³´ì¥"
    )
)
def recommend_second_perfumes(request: SecondRecommendRequest):
    """AI ëª¨ë¸ í¬í•¨ ì™„ì „í•œ 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ API"""

    request_start_time = datetime.now()
    logger.info(f"ğŸ†• AI ëª¨ë¸ í¬í•¨ 2ì°¨ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­ ì ‘ìˆ˜")

    try:
        # ë©”ì¸ ì¶”ì²œ ì²˜ë¦¬
        results = process_second_recommendation_with_ai(
            user_preferences=request.user_preferences.dict(),
            user_note_scores=request.user_note_scores,
            emotion_proba=request.emotion_proba,
            selected_idx=request.selected_idx
        )

        if not results:
            raise HTTPException(
                status_code=404,
                detail="ì¶”ì²œí•  ìˆ˜ ìˆëŠ” í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        # ì‘ë‹µ í˜•íƒœë¡œ ë³€í™˜
        response_items = []
        for result in results:
            response_items.append(
                SecondRecommendItem(
                    name=result['name'],
                    brand=result['brand'],
                    final_score=result['final_score'],
                    emotion_cluster=result['emotion_cluster'],
                    image_url=result.get('image_url', '')
                )
            )

        total_processing_time = (datetime.now() - request_start_time).total_seconds()
        logger.info(f"âœ… AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì™„ë£Œ: {len(response_items)}ê°œ í–¥ìˆ˜")
        logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.3f}ì´ˆ")

        return response_items

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ AI ëª¨ë¸ í¬í•¨ 2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"2ì°¨ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# â”€â”€â”€ 12. ì¶”ê°€ ìœ í‹¸ë¦¬í‹° APIë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@router.get("/note-analysis/{perfume_index}", summary="í–¥ìˆ˜ ë…¸íŠ¸ ë¶„ì„")
def analyze_perfume_notes(perfume_index: int):
    """í–¥ìˆ˜ ë…¸íŠ¸ ë¶„ì„ API"""
    try:
        if perfume_index < 0 or perfume_index >= len(df):
            raise HTTPException(
                status_code=404,
                detail=f"ì˜ëª»ëœ í–¥ìˆ˜ ì¸ë±ìŠ¤: {perfume_index}"
            )

        perfume = df.iloc[perfume_index]
        notes_str = str(perfume.get('notes', ''))
        parsed_notes = parse_notes_from_string(notes_str)
        normalized_notes = [normalize_note_name(note) for note in parsed_notes]

        return {
            "perfume_index": perfume_index,
            "name": str(perfume['name']),
            "brand": str(perfume['brand']),
            "raw_notes": notes_str,
            "parsed_notes": parsed_notes,
            "normalized_notes": normalized_notes,
            "note_count": len(parsed_notes),
            "emotion_cluster": int(perfume.get('emotion_cluster', 0))
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/system-status", summary="2ì°¨ ì¶”ì²œ ì‹œìŠ¤í…œ ìƒíƒœ")
def get_system_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ API"""
    try:
        total_perfumes = len(df)
        unique_brands = df['brand'].nunique() if 'brand' in df.columns else 0

        cluster_distribution = {}
        if 'emotion_cluster' in df.columns:
            cluster_counts = df['emotion_cluster'].value_counts().to_dict()
            cluster_distribution = {int(k): int(v) for k, v in cluster_counts.items()}

        all_notes = []
        for _, row in df.head(100).iterrows():
            notes = parse_notes_from_string(str(row.get('notes', '')))
            all_notes.extend(notes)

        note_frequency = Counter(all_notes)
        top_notes = dict(note_frequency.most_common(20))

        return {
            "system_status": "operational",
            "ai_model_available": _model_available,
            "dataset_info": {
                "total_perfumes": total_perfumes,
                "unique_brands": unique_brands,
                "columns": list(df.columns)
            },
            "emotion_clusters": {
                "distribution": cluster_distribution
            },
            "note_analysis": {
                "top_20_notes": top_notes,
                "unique_notes_in_sample": len(note_frequency),
                "total_note_occurrences": len(all_notes)
            },
            "supported_features": [
                "AI ëª¨ë¸ ìë™ í˜¸ì¶œ",
                "ë…¸íŠ¸ ì„ í˜¸ë„ ê¸°ë°˜ ë§¤ì¹­",
                "ê°ì • í´ëŸ¬ìŠ¤í„° ê°€ì¤‘ì¹˜",
                "ë¸Œëœë“œ ë‹¤ì–‘ì„± ë³´ì¥",
                "ì•ˆì „í•œ í´ë°± ë©”ì»¤ë‹ˆì¦˜"
            ]
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))