# routers/emotion_tagging_router.py
# ğŸ¯ ê°ì • íƒœê¹… AI ëª¨ë¸ API ë¼ìš°í„° (async/await ì˜¤ë¥˜ í•´ê²°)

import os
import pickle
import logging
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
import pandas as pd

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("emotion_tagging")

# â”€â”€â”€ ê²½ë¡œ ì„¤ì • (ì˜¬ë°”ë¥¸ ì ˆëŒ€ê²½ë¡œ ì‚¬ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(__file__)
EMOTION_MODEL_PATH = os.path.join(BASE_DIR, "../emotion_models/scent_emotion_model_v6.keras")
VECTORIZER_PATH = os.path.join(BASE_DIR, "../emotion_models/vectorizer.pkl")

# â”€â”€â”€ ê¸€ë¡œë²Œ ë³€ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_emotion_model = None
_vectorizer = None
_model_loaded = False


# â”€â”€â”€ ìŠ¤í‚¤ë§ˆ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class EmotionTagRequest(BaseModel):
    text: str = Field(..., description="ê°ì • íƒœê¹…í•  í…ìŠ¤íŠ¸", example="ì´ í–¥ìˆ˜ëŠ” ì •ë§ ì¢‹ì•„ìš”! ê¸°ë¶„ì´ ìƒì¾Œí•´ì§‘ë‹ˆë‹¤.")


class EmotionTagResponse(BaseModel):
    text: str = Field(..., description="ì…ë ¥ í…ìŠ¤íŠ¸")
    emotion: str = Field(..., description="ì˜ˆì¸¡ëœ ê°ì •")
    confidence: float = Field(..., description="ì‹ ë¢°ë„ (0.0-1.0)")
    all_emotions: Dict[str, float] = Field(..., description="ëª¨ë“  ê°ì •ë³„ í™•ë¥ ")
    processing_time: float = Field(..., description="ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)")
    method: str = Field(..., description="ë¶„ì„ ë°©ë²•")


# â”€â”€â”€ ê°ì • í´ë˜ìŠ¤ ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_LABELS = {
    0: "ê¸°ì¨",
    1: "ë¶ˆì•ˆ",
    2: "ë‹¹í™©",
    3: "ë¶„ë…¸",
    4: "ìƒì²˜",
    5: "ìŠ¬í””",
    6: "ìš°ìš¸",
    7: "í¥ë¶„"
}


# â”€â”€â”€ ë™ê¸°ì‹ ê°ì • íƒœê±° í´ë˜ìŠ¤ (async ë¬¸ì œ í•´ê²°) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SyncEmotionTagger:
    """ë™ê¸°ì‹ ê°ì • íƒœê¹… AI ëª¨ë¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.model_path = EMOTION_MODEL_PATH
        self.vectorizer_path = VECTORIZER_PATH
        self.model = None
        self.vectorizer = None
        self.model_loaded = False

        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        self.check_files()

    def check_files(self):
        """ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        model_exists = os.path.exists(self.model_path)
        vectorizer_exists = os.path.exists(self.vectorizer_path)

        logger.info(f"ğŸ” ê°ì • ëª¨ë¸ íŒŒì¼ í™•ì¸:")
        logger.info(f"  - ëª¨ë¸ íŒŒì¼: {self.model_path} {'âœ…' if model_exists else 'âŒ'}")
        logger.info(f"  - ë²¡í„°ë¼ì´ì €: {self.vectorizer_path} {'âœ…' if vectorizer_exists else 'âŒ'}")

        if model_exists:
            model_size = os.path.getsize(self.model_path)
            logger.info(f"  - ëª¨ë¸ í¬ê¸°: {model_size:,} bytes ({model_size / 1024 / 1024:.1f}MB)")

        return model_exists and vectorizer_exists

    def load_model(self):
        """ëª¨ë¸ê³¼ ë²¡í„°ë¼ì´ì € ë¡œë”©"""
        if self.model_loaded:
            return True

        try:
            logger.info("ğŸ¤– ê°ì • íƒœê¹… ëª¨ë¸ ë¡œë”© ì‹œì‘...")

            # 1. TensorFlow ëª¨ë¸ ë¡œë”©
            try:
                import tensorflow as tf
                # Keras 3.x í˜¸í™˜ì„±ì„ ìœ„í•œ ë¡œë”©
                try:
                    from tensorflow import keras
                    self.model = keras.models.load_model(self.model_path, compile=False)
                except:
                    from tensorflow.keras.models import load_model
                    self.model = load_model(self.model_path, compile=False)

                logger.info(f"âœ… ê°ì • ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {self.model.input_shape} â†’ {self.model.output_shape}")
            except Exception as e:
                logger.error(f"âŒ TensorFlow ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
                return False

            # 2. ë²¡í„°ë¼ì´ì € ë¡œë”©
            try:
                with open(self.vectorizer_path, "rb") as f:
                    self.vectorizer = pickle.load(f)
                logger.info(f"âœ… ë²¡í„°ë¼ì´ì € ë¡œë“œ ì„±ê³µ")
            except Exception as e:
                logger.error(f"âŒ ë²¡í„°ë¼ì´ì € ë¡œë”© ì‹¤íŒ¨: {e}")
                # ë²¡í„°ë¼ì´ì €ê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ë”ë¯¸ ìƒì„±
                logger.info("ğŸ”§ ë”ë¯¸ ë²¡í„°ë¼ì´ì € ìƒì„±...")
                from sklearn.feature_extraction.text import TfidfVectorizer
                self.vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))
                # ë”ë¯¸ ë°ì´í„°ë¡œ fit
                dummy_texts = [
                    "ì¢‹ì•„ìš” í–¥ìˆ˜ ê¸°ë¶„ ì¢‹ì•„",
                    "ë‚˜ë¹ ìš” ì‹«ì–´ í™”ë‚˜",
                    "ìŠ¬í¼ìš” ìš°ìš¸í•´",
                    "ì‹ ë‚˜ìš” í¥ë¯¸ë¡œì›Œ"
                ]
                self.vectorizer.fit(dummy_texts)
                logger.info("âœ… ë”ë¯¸ ë²¡í„°ë¼ì´ì € ìƒì„± ì™„ë£Œ")

            self.model_loaded = True
            logger.info("ğŸ‰ ê°ì • íƒœê¹… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
            return True

        except Exception as e:
            logger.error(f"âŒ ê°ì • ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    def predict_emotion(self, text: str) -> Dict:
        """í…ìŠ¤íŠ¸ì˜ ê°ì • ì˜ˆì¸¡ (ë™ê¸°ì‹)"""
        start_time = datetime.now()

        try:
            # ëª¨ë¸ ë¡œë”© í™•ì¸
            if not self.model_loaded:
                if not self.load_model():
                    # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±
                    return self._keyword_based_prediction(text, start_time)

            # 1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ë²¡í„°í™”
            try:
                text_vector = self.vectorizer.transform([text])
            except Exception as e:
                logger.error(f"âŒ ë²¡í„°í™” ì‹¤íŒ¨: {e}")
                return self._keyword_based_prediction(text, start_time)

            # 2. ëª¨ë¸ ì˜ˆì¸¡
            try:
                predictions = self.model.predict(text_vector, verbose=0)
                emotion_probs = predictions[0]
            except Exception as e:
                logger.error(f"âŒ ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                return self._keyword_based_prediction(text, start_time)

            # 3. ê²°ê³¼ ì²˜ë¦¬
            predicted_emotion_idx = int(np.argmax(emotion_probs))
            predicted_emotion = EMOTION_LABELS.get(predicted_emotion_idx, "ì•Œìˆ˜ì—†ìŒ")
            confidence = float(emotion_probs[predicted_emotion_idx])

            # 4. ëª¨ë“  ê°ì • í™•ë¥ 
            all_emotions = {}
            for idx, prob in enumerate(emotion_probs):
                emotion_name = EMOTION_LABELS.get(idx, f"ê°ì •{idx}")
                all_emotions[emotion_name] = round(float(prob), 3)

            # 5. ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = (datetime.now() - start_time).total_seconds()

            result = {
                "text": text,
                "emotion": predicted_emotion,
                "confidence": round(confidence, 3),
                "all_emotions": all_emotions,
                "processing_time": round(processing_time, 3),
                "method": "AI ëª¨ë¸ ì˜ˆì¸¡"
            }

            logger.info(f"ğŸ¯ AI ëª¨ë¸ ê°ì • ì˜ˆì¸¡ ì™„ë£Œ: '{text[:30]}...' â†’ {predicted_emotion} ({confidence:.3f})")

            return result

        except Exception as e:
            logger.error(f"âŒ ê°ì • ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._keyword_based_prediction(text, start_time)

    def _keyword_based_prediction(self, text: str, start_time: datetime) -> Dict:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ì˜ˆì¸¡ (í´ë°±)"""
        logger.info("ğŸ“‹ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„ìœ¼ë¡œ í´ë°±")

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì‚¬ì „
        emotion_keywords = {
            "ê¸°ì¨": ["ì¢‹ì•„", "í–‰ë³µ", "ê¸°ë»", "ì‚¬ë‘", "ì™„ë²½", "ìµœê³ ", "ìƒì¾Œ", "ë‹¬ì½¤", "ì˜ˆìœ"],
            "ë¶ˆì•ˆ": ["ë¶ˆì•ˆ", "ê±±ì •", "ê¸´ì¥", "ë¬´ì„œìš´", "ë¶€ë‹´", "ìŠ¤íŠ¸ë ˆìŠ¤"],
            "ë‹¹í™©": ["ë‹¹í™©", "ë†€ë€", "í˜¼ë€", "ì´ìƒ", "ì˜ì™¸", "íŠ¹ì´"],
            "ë¶„ë…¸": ["í™”ê°€", "ì§œì¦", "ì—´ë°›", "ì‹«ì–´", "ìµœì•…", "ìê·¹ì "],
            "ìƒì²˜": ["ìƒì²˜", "ì•„í”ˆ", "ì‹¤ë§", "ê·¸ë¦¬ìš´", "ì„œìš´"],
            "ìŠ¬í””": ["ìŠ¬í¼", "ëˆˆë¬¼", "ì™¸ë¡œìš´", "ì“¸ì“¸", "ì²˜ëŸ‰"],
            "ìš°ìš¸": ["ìš°ìš¸", "ë‹µë‹µ", "ë¬´ê¸°ë ¥", "ì ˆë§", "ì–´ë‘ "],
            "í¥ë¶„": ["í¥ë¶„", "ì‹ ë‚˜", "ì„¤ë ˜", "í™œê¸°", "ì—ë„ˆì§€"]
        }

        text_lower = text.lower()
        emotion_scores = {}

        # í‚¤ì›Œë“œ ë§¤ì¹­
        for emotion, keywords in emotion_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in text_lower:
                    score += 1
            if score > 0:
                emotion_scores[emotion] = score / len(keywords)

        # ê²°ê³¼ ì²˜ë¦¬
        if emotion_scores:
            predicted_emotion = max(emotion_scores.keys(), key=lambda x: emotion_scores[x])
            confidence = emotion_scores[predicted_emotion]
        else:
            predicted_emotion = "ê¸°ì¨"  # ê¸°ë³¸ê°’
            confidence = 0.3

        # ëª¨ë“  ê°ì • í™•ë¥  (ì •ê·œí™”)
        all_emotions = {}
        for emotion in EMOTION_LABELS.values():
            all_emotions[emotion] = emotion_scores.get(emotion, 0.0)

        # ì •ê·œí™”
        total_score = sum(all_emotions.values()) or 1.0
        for emotion in all_emotions:
            all_emotions[emotion] = round(all_emotions[emotion] / total_score, 3)

        processing_time = (datetime.now() - start_time).total_seconds()

        return {
            "text": text,
            "emotion": predicted_emotion,
            "confidence": round(confidence, 3),
            "all_emotions": all_emotions,
            "processing_time": round(processing_time, 3),
            "method": "í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ (ëª¨ë¸ í´ë°±)"
        }


# â”€â”€â”€ ê¸€ë¡œë²Œ ê°ì • íƒœê±° ì¸ìŠ¤í„´ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
emotion_tagger = SyncEmotionTagger()

# â”€â”€â”€ ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/emotions", tags=["Emotion Tagging"])


@router.post(
    "/predict",
    response_model=EmotionTagResponse,
    summary="AI ëª¨ë¸ ê°ì • íƒœê¹…",
    description=(
            "ğŸ­ **AI ëª¨ë¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„**\n\n"
            "TensorFlow ê°ì • ë¶„ë¥˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ 8ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.\n"
            "ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ìë™ í´ë°±ë©ë‹ˆë‹¤.\n\n"
            "**ğŸ“¥ ì…ë ¥:**\n"
            "- ê°ì • ë¶„ì„í•  í…ìŠ¤íŠ¸ (í•œêµ­ì–´ ê¶Œì¥)\n\n"
            "**ğŸ“¤ ì¶œë ¥:**\n"
            "- ì˜ˆì¸¡ëœ ì£¼ìš” ê°ì • ë° ì‹ ë¢°ë„\n"
            "- 8ê°€ì§€ ê°ì •ë³„ ìƒì„¸ í™•ë¥ \n"
            "- ë¶„ì„ ë°©ë²• (AI ëª¨ë¸ ë˜ëŠ” í‚¤ì›Œë“œ ê¸°ë°˜)\n\n"
            "**ğŸ¯ ì§€ì› ê°ì •:**\n"
            "ê¸°ì¨, ë¶ˆì•ˆ, ë‹¹í™©, ë¶„ë…¸, ìƒì²˜, ìŠ¬í””, ìš°ìš¸, í¥ë¶„"
    )
)
def predict_emotion(request: EmotionTagRequest):
    """í…ìŠ¤íŠ¸ ê°ì • ì˜ˆì¸¡ API (ë™ê¸°ì‹)"""

    try:
        # ì…ë ¥ ê²€ì¦
        if not request.text or len(request.text.strip()) == 0:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        if len(request.text) > 1000:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 1000ì).")

        # ğŸ”§ í•µì‹¬ ìˆ˜ì •: ë™ê¸°ì‹ ê°ì • ì˜ˆì¸¡ (async ì—†ìŒ)
        result = emotion_tagger.predict_emotion(request.text.strip())

        return EmotionTagResponse(**result)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ê°ì • ì˜ˆì¸¡ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@router.get(
    "/status",
    summary="ê°ì • íƒœê¹… ì‹œìŠ¤í…œ ìƒíƒœ",
    description="ê°ì • íƒœê¹… AI ëª¨ë¸ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def get_emotion_system_status():
    """ê°ì • íƒœê¹… ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""

    try:
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€
        model_exists = os.path.exists(EMOTION_MODEL_PATH)
        vectorizer_exists = os.path.exists(VECTORIZER_PATH)

        # íŒŒì¼ í¬ê¸°
        model_size = os.path.getsize(EMOTION_MODEL_PATH) if model_exists else 0
        vectorizer_size = os.path.getsize(VECTORIZER_PATH) if vectorizer_exists else 0

        return {
            "system_status": "operational" if model_exists else "model_file_missing",
            "model_info": {
                "model_file": EMOTION_MODEL_PATH,
                "model_exists": model_exists,
                "model_size_mb": round(model_size / 1024 / 1024, 2) if model_exists else 0,
                "vectorizer_file": VECTORIZER_PATH,
                "vectorizer_exists": vectorizer_exists,
                "vectorizer_size_kb": round(vectorizer_size / 1024, 2) if vectorizer_exists else 0
            },
            "model_loaded": emotion_tagger.model_loaded,
            "supported_emotions": list(EMOTION_LABELS.values()),
            "max_text_length": 1000,
            "features": [
                "TensorFlow AI ëª¨ë¸ ì˜ˆì¸¡",
                "í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°±",
                "8ê°€ì§€ ê°ì • ë¶„ë¥˜",
                "ë™ê¸°ì‹ ì²˜ë¦¬ (async ë¬¸ì œ í•´ê²°)"
            ],
            "last_checked": datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
        return {
            "system_status": "error",
            "error": str(e),
            "last_checked": datetime.now().isoformat()
        }


@router.get(
    "/emotions",
    summary="ì§€ì› ê°ì • ëª©ë¡",
    description="ì‹œìŠ¤í…œì—ì„œ ì§€ì›í•˜ëŠ” ëª¨ë“  ê°ì • ì¹´í…Œê³ ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
)
def get_supported_emotions():
    """ì§€ì›í•˜ëŠ” ê°ì • ëª©ë¡ ë°˜í™˜"""

    return {
        "emotions": EMOTION_LABELS,
        "total_count": len(EMOTION_LABELS),
        "categories": [
            {"id": k, "name": v, "description": f"{v} ê´€ë ¨ ê°ì •"}
            for k, v in EMOTION_LABELS.items()
        ]
    }


@router.post(
    "/test-model",
    summary="ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸",
    description="ê°ì • ë¶„ì„ ëª¨ë¸ì˜ ë¡œë”© ìƒíƒœë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
)
def test_model_loading():
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""

    try:
        # ê°•ì œë¡œ ëª¨ë¸ ë¡œë”© ì‹œë„
        emotion_tagger.model_loaded = False
        success = emotion_tagger.load_model()

        return {
            "model_loading_success": success,
            "model_loaded": emotion_tagger.model_loaded,
            "model_path": EMOTION_MODEL_PATH,
            "vectorizer_path": VECTORIZER_PATH,
            "test_time": datetime.now().isoformat()
        }

    except Exception as e:
        return {
            "model_loading_success": False,
            "error": str(e),
            "test_time": datetime.now().isoformat()
        }