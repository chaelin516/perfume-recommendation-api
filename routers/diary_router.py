# routers/diary_router.py - ë£° ê¸°ë°˜ ê°ì •ë¶„ì„ ì‹œìŠ¤í…œ

from fastapi import APIRouter, Query, Depends, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from schemas.diary import DiaryCreateRequest, DiaryResponse
from schemas.common import BaseResponse
from datetime import datetime, date
from typing import Optional, List, Dict, Any
from utils.auth_utils import verify_firebase_token_optional, get_firebase_status
import os
import json
import uuid
import logging
import asyncio
import time
from collections import Counter
from pydantic import BaseModel, Field
import re

# ğŸ­ ë¡œê±° ì„¤ì •
logger = logging.getLogger("diary_router")

# âœ… ë¼ìš°í„° ìƒì„±
router = APIRouter(prefix="/diaries", tags=["Diary"])

# ğŸ“‚ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DIARY_PATH = os.path.join(BASE_DIR, "../data/diary_data.json")

# ğŸ¯ ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ ì‚¬ì „ ì •ì˜
EMOTION_RULES = {
    "ê¸°ì¨": {
        "keywords": [
            "ì¢‹", "í›Œë¥­", "í–¥ê¸‹", "ë‹¬ì½¤", "ìƒí¼", "ê¹”ë”", "ì‚¬ë‘", "ì™„ë²½", "ìµœê³ ", "ë©‹ì§„",
            "í™˜ìƒì ", "ë†€ë¼ìš´", "ì•„ë¦„ë‹¤ìš´", "ìš°ì•„í•œ", "ì„¸ë ¨ëœ", "ê³ ê¸‰ìŠ¤ëŸ¬ìš´", "ë§¤ë ¥ì ",
            "ê¸°ë¶„ì¢‹", "í–‰ë³µ", "ì¦ê±°ìš´", "ë§Œì¡±", "ê°ë™", "í™©í™€", "ë°˜í•¨", "ì¢‹ì•„í•´", "ë§ˆìŒì— ë“¤",
            "í¬ê·¼", "ë”°ëœ»", "í¸ì•ˆ", "ë¶€ë“œëŸ¬ìš´", "ì€ì€í•œ", "ìš°ì•„", "ê³ í˜¹ì ", "ì‹ ë¹„ë¡œìš´"
        ],
        "tags": ["#happy", "#joyful", "#pleasant", "#nice", "#satisfied", "#lovely"],
        "base_confidence": 0.7
    },
    "ì„¤ë ˜": {
        "keywords": [
            "ì„¤ë ˆ", "ë‘ê·¼", "ë–¨ë¦¼", "ê¸°ëŒ€", "í˜¸ê¸°ì‹¬", "ê¶ê¸ˆ", "ì‹ ê¸°", "ìƒˆë¡œìš´", "íŠ¹ë³„í•œ",
            "ë…íŠ¹í•œ", "ë§¤í˜¹ì ", "í¥ë¯¸ë¡œìš´", "ì¬ë¯¸ìˆ", "ì‹ ì„ í•œ", "ìƒë™ê°", "í™œê¸°ì°¬",
            "ì§œë¦¿", "ìŠ¤ë¦´", "í¥ë¶„", "ê°€ìŠ´ì´ ë›°", "ì‹¬ì¥ì´", "ë–¨ë ¤"
        ],
        "tags": ["#excited", "#curious", "#anticipation", "#thrilling", "#fascinating"],
        "base_confidence": 0.65
    },
    "í‰ì˜¨": {
        "keywords": [
            "í‰ì˜¨", "ê³ ìš”", "ì”ì”", "ì°¨ë¶„", "ì•ˆì •", "í‰í™”", "ì¡°ìš©", "í¸ì•ˆ", "ì—¬ìœ ë¡œìš´",
            "ëŠê¸‹", "ë¦´ë ‰ìŠ¤", "íœ´ì‹", "ì¹˜ìœ ", "íë§", "ì§„ì •", "ë§ˆìŒì´ í¸í•´", "ìŠ¤íŠ¸ë ˆìŠ¤",
            "í”¼ë¡œê°€ í’€", "ìˆ¨ì„ ì‰¬ê¸°", "ê¹Šê²Œ í˜¸í¡", "ëª…ìƒ", "ì‚¬ìƒ‰", "ìƒê°ì— ì ê¸°"
        ],
        "tags": ["#calm", "#peaceful", "#relaxed", "#healing", "#serene"],
        "base_confidence": 0.6
    },
    "ìì‹ ê°": {
        "keywords": [
            "ìì‹ ê°", "ë‹¹ë‹¹", "ì„¸ë ¨", "ê³ ê¸‰", "í’ˆê²©", "ìš°ì•„", "ì¹´ë¦¬ìŠ¤ë§ˆ", "ë§¤ë ¥", "íŒŒì›Œí’€",
            "ê°•ë ¬", "ë„ì „", "ìš©ê¸°", "í™•ì‹ ", "ë¯¿ìŒ", "í”„ë¡œí˜ì…”ë„", "ì„¸ë ¨", "ìŠ¤íƒ€ì¼ë¦¬ì‹œ",
            "íŠ¸ë Œë””", "ëª¨ë˜", "ì‹œí¬", "ì—˜ë ˆê°„íŠ¸", "í´ë˜ì‹", "ëŸ­ì…”ë¦¬"
        ],
        "tags": ["#confident", "#elegant", "#powerful", "#sophisticated", "#stylish"],
        "base_confidence": 0.65
    },
    "ê·¸ë¦¬ì›€": {
        "keywords": [
            "ê·¸ë¦¬ìš´", "ê·¸ë¦½", "ì¶”ì–µ", "ì˜›ë‚ ", "ê³¼ê±°", "ì˜ˆì „", "ì–´ë¦´ ë•Œ", "í•™ì°½ì‹œì ˆ", "ê³ í–¥",
            "ì—„ë§ˆ", "ì•„ë¹ ", "ê°€ì¡±", "ì¹œêµ¬", "ì—°ì¸", "ì²«ì‚¬ë‘", "ì¶”ì–µì— ì ê¸°", "ìƒê°ë‚˜",
            "ë– ì˜¬", "íšŒìƒ", "í–¥ìˆ˜", "ê·¸ë•Œ ê·¸ ì‹œì ˆ", "ì•„ë ¨", "ë¨¹ë¨¹", "ìš¸ì»¥"
        ],
        "tags": ["#nostalgic", "#memory", "#longing", "#sentimental", "#reminiscent"],
        "base_confidence": 0.6
    },
    "í™œë ¥": {
        "keywords": [
            "í™œë ¥", "ì—ë„ˆì§€", "ìƒê¸°", "í™œê¸°", "ì—­ë™", "íŒŒì›Œ", "í˜", "ì›ê¸°", "ê±´ê°•", "í™œë°œ",
            "ìƒì¾Œ", "ì‹œì›", "ì²­ëŸ‰", "ì‹ ì„ ", "ë§‘ì€", "ê¹¨ë—", "ì •í™”", "ë¦¬í”„ë ˆì‹œ", "ê¸°ìš´",
            "íˆ¬ëª…", "ê¹”ë”", "ì‹œì›ì‹œì›", "í†¡í†¡", "ìƒí¼ë°œë„", "ìƒê¸°ë°œë„"
        ],
        "tags": ["#energetic", "#fresh", "#vibrant", "#lively", "#refreshing"],
        "base_confidence": 0.7
    },
    "ë¡œë§¨í‹±": {
        "keywords": [
            "ë¡œë§¨í‹±", "ë‚­ë§Œ", "ì‚¬ë‘", "ì—°ì¸", "ë°ì´íŠ¸", "ë¡œë§¨ìŠ¤", "ë‹¬ì½¤í•œ", "ë‹¬ë‹¬í•œ",
            "ë¡œì¦ˆ", "ê½ƒ", "í”Œë¡œëŸ´", "ì—¬ì„±ìŠ¤ëŸ¬ìš´", "ë¶€ë“œëŸ¬ìš´", "ì„¬ì„¸í•œ", "ìš°ì•„í•œ",
            "ë¶„í™", "ì˜ˆìœ", "ì•„ë¦„ë‹¤ìš´", "ì‚¬ë‘ìŠ¤ëŸ¬ìš´", "ê·€ì—¬ìš´", "ë§¤ë ¥ì ", "í˜¹ì‹œë‚˜",
            "ì„¤ë ˆê²Œ í•˜ëŠ”", "ë§ˆìŒì„ ë…¹ì´ëŠ”", "ê°ë¯¸ë¡œìš´"
        ],
        "tags": ["#romantic", "#lovely", "#sweet", "#floral", "#feminine"],
        "base_confidence": 0.65
    },
    "ì‹¤ë§": {
        "keywords": [
            "ì‹¤ë§", "ì•„ì‰¬", "í›„íšŒ", "ë³„ë¡œ", "ì´ìƒ", "ì•ˆì¢‹", "ì‹«", "ë‚˜ìœ", "ì‹¤ìˆ˜", "ë§í•¨",
            "ê¸°ëŒ€ ì´í•˜", "ì•„ë‹ˆë‹¤", "ë§ì§€ ì•Š", "ì–´ìš¸ë¦¬ì§€ ì•Š", "ë„ˆë¬´", "ê³¼í•˜", "ë¶€ë‹´ìŠ¤ëŸ¬ìš´",
            "ë¬´ê±°ìš´", "ë‹µë‹µ", "ìˆ¨ë§‰íˆ", "ê±°ë¶€ê°", "ê±°ìŠ¬ë¦¬", "ë¶ˆí¸", "ì–´ìƒ‰"
        ],
        "tags": ["#disappointed", "#regretful", "#unsatisfied", "#uncomfortable"],
        "base_confidence": 0.7
    },
    "ì¤‘ë¦½": {
        "keywords": [
            "í‰ë²”", "ë¬´ë‚œ", "ê·¸ëƒ¥", "ê´œì°®", "ë³´í†µ", "ì ë‹¹", "ì ì ˆ", "ì¼ë°˜ì ", "íŠ¹ë³„í•˜ì§€ ì•Š",
            "ê·¸ëŸ°ëŒ€ë¡œ", "ë‚˜ì˜ì§€ ì•Š", "ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„", "ê·¸ì € ê·¸ëŸ°", "í‰í‰í•œ", "ë°‹ë°‹"
        ],
        "tags": ["#neutral", "#normal", "#okay", "#moderate"],
        "base_confidence": 0.5
    }
}

# ğŸŒŸ ê³„ì ˆ/ì‹œê°„/ìƒí™©ë³„ ê°ì • ë³´ì • ë£°
CONTEXT_EMOTION_MODIFIERS = {
    "ê³„ì ˆ": {
        "ë´„": {"ì„¤ë ˜": 0.2, "í™œë ¥": 0.15, "ë¡œë§¨í‹±": 0.1},
        "ì—¬ë¦„": {"í™œë ¥": 0.25, "ìì‹ ê°": 0.15, "ê¸°ì¨": 0.1},
        "ê°€ì„": {"ê·¸ë¦¬ì›€": 0.2, "í‰ì˜¨": 0.15, "ë¡œë§¨í‹±": 0.1},
        "ê²¨ìš¸": {"í‰ì˜¨": 0.2, "ê·¸ë¦¬ì›€": 0.15, "ë¡œë§¨í‹±": 0.1}
    },
    "ì‹œê°„": {
        "ì•„ì¹¨": {"í™œë ¥": 0.2, "ìì‹ ê°": 0.15},
        "ë‚®": {"ê¸°ì¨": 0.15, "í™œë ¥": 0.1},
        "ì €ë…": {"ë¡œë§¨í‹±": 0.2, "í‰ì˜¨": 0.15},
        "ë°¤": {"ê·¸ë¦¬ì›€": 0.2, "í‰ì˜¨": 0.15, "ë¡œë§¨í‹±": 0.1}
    },
    "ìƒí™©": {
        "ë°ì´íŠ¸": {"ë¡œë§¨í‹±": 0.3, "ì„¤ë ˜": 0.2},
        "ì—…ë¬´": {"ìì‹ ê°": 0.2, "í™œë ¥": 0.15},
        "íœ´ì‹": {"í‰ì˜¨": 0.25, "ê¸°ì¨": 0.1},
        "ì™¸ì¶œ": {"í™œë ¥": 0.15, "ìì‹ ê°": 0.1}
    }
}

# ğŸ¨ í–¥ìˆ˜ íƒ€ì…ë³„ ê°ì • ë§¤í•‘
PERFUME_TYPE_EMOTIONS = {
    "í”Œë¡œëŸ´": ["ë¡œë§¨í‹±", "ê¸°ì¨", "í‰ì˜¨"],
    "ì‹œíŠ¸ëŸ¬ìŠ¤": ["í™œë ¥", "ê¸°ì¨", "ìì‹ ê°"],
    "ìš°ë””": ["ìì‹ ê°", "í‰ì˜¨", "ê·¸ë¦¬ì›€"],
    "ë°”ë‹ë¼": ["í‰ì˜¨", "ë¡œë§¨í‹±", "ê·¸ë¦¬ì›€"],
    "ë¨¸ìŠ¤í¬": ["ìì‹ ê°", "ë¡œë§¨í‹±", "í‰ì˜¨"],
    "í”„ë£¨í‹°": ["ê¸°ì¨", "í™œë ¥", "ì„¤ë ˜"]
}


def load_diary_data():
    """ì‹œí–¥ ì¼ê¸° ë°ì´í„° ë¡œë”©"""
    if os.path.exists(DIARY_PATH):
        try:
            with open(DIARY_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            logger.info(f"âœ… ì‹œí–¥ ì¼ê¸° ë°ì´í„° ë¡œë”©: {len(data)}ê°œ")
            return data
        except Exception as e:
            logger.error(f"âŒ ì‹œí–¥ ì¼ê¸° ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
    return []


def save_diary_data(data):
    """ì‹œí–¥ ì¼ê¸° ë°ì´í„° ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(DIARY_PATH), exist_ok=True)
        with open(DIARY_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        logger.error(f"âŒ ì‹œí–¥ ì¼ê¸° ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def extract_context_from_text(text: str) -> Dict[str, str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ê³„ì ˆ, ì‹œê°„, ìƒí™© ì •ë³´ ì¶”ì¶œ"""
    context = {"ê³„ì ˆ": None, "ì‹œê°„": None, "ìƒí™©": None}
    text_lower = text.lower()

    # ê³„ì ˆ í‚¤ì›Œë“œ
    season_keywords = {
        "ë´„": ["ë´„", "ë²šê½ƒ", "ê°œí™”", "ë”°ëœ»í•´ì§€", "ì‹ ë¡"],
        "ì—¬ë¦„": ["ì—¬ë¦„", "ë¥", "ì‹œì›", "í•´ë³€", "ë°”ìº‰ìŠ¤", "íœ´ê°€"],
        "ê°€ì„": ["ê°€ì„", "ë‹¨í’", "ìŒ€ìŒ€", "ì„ ì„ ", "ì¶”ì„"],
        "ê²¨ìš¸": ["ê²¨ìš¸", "ì¶¥", "ëˆˆ", "í¬ë¦¬ìŠ¤ë§ˆìŠ¤", "ì—°ë§"]
    }

    # ì‹œê°„ í‚¤ì›Œë“œ
    time_keywords = {
        "ì•„ì¹¨": ["ì•„ì¹¨", "ìƒˆë²½", "ì¶œê·¼", "ëª¨ë‹"],
        "ë‚®": ["ë‚®", "ì ì‹¬", "ì˜¤í›„", "ë°ì´íƒ€ì„"],
        "ì €ë…": ["ì €ë…", "í‡´ê·¼", "ì´ë¸Œë‹"],
        "ë°¤": ["ë°¤", "ì•¼ê°„", "ë‚˜ì´íŠ¸", "ì ë“¤ê¸° ì „"]
    }

    # ìƒí™© í‚¤ì›Œë“œ
    situation_keywords = {
        "ë°ì´íŠ¸": ["ë°ì´íŠ¸", "ì•½ì†", "ë§Œë‚¨", "ì—°ì¸", "ì»¤í”Œ"],
        "ì—…ë¬´": ["íšŒì‚¬", "ì—…ë¬´", "ë¯¸íŒ…", "ì¶œê·¼", "ì§ì¥"],
        "íœ´ì‹": ["íœ´ì‹", "ì‰¬ëŠ”", "ì—¬ìœ ", "ë¦´ë ‰ìŠ¤", "íë§"],
        "ì™¸ì¶œ": ["ì™¸ì¶œ", "ë‚˜ë“¤ì´", "ì‡¼í•‘", "ì‚°ì±…"]
    }

    # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­
    for season, keywords in season_keywords.items():
        if any(keyword in text_lower for keyword in keywords):
            context["ê³„ì ˆ"] = season
            break

    for time_period, keywords in time_keywords.items():
        if any(keyword in text_lower for keyword in keywords):
            context["ì‹œê°„"] = time_period
            break

    for situation, keywords in situation_keywords.items():
        if any(keyword in text_lower for keyword in keywords):
            context["ìƒí™©"] = situation
            break

    return context


def detect_perfume_type(perfume_name: str) -> str:
    """í–¥ìˆ˜ ì´ë¦„ì—ì„œ íƒ€ì… ì¶”ì •"""
    perfume_lower = perfume_name.lower()

    type_keywords = {
        "í”Œë¡œëŸ´": ["rose", "jasmine", "lily", "peony", "gardenia", "í”Œë¡œëŸ´", "ë¡œì¦ˆ", "ììŠ¤ë¯¼"],
        "ì‹œíŠ¸ëŸ¬ìŠ¤": ["lemon", "orange", "bergamot", "grapefruit", "ì‹œíŠ¸ëŸ¬ìŠ¤", "ë ˆëª¬", "ì˜¤ë Œì§€"],
        "ìš°ë””": ["wood", "cedar", "sandalwood", "oak", "ìš°ë””", "ë‚˜ë¬´", "ì‹œë”"],
        "ë°”ë‹ë¼": ["vanilla", "ë°”ë‹ë¼", "ë‹¬ì½¤"],
        "ë¨¸ìŠ¤í¬": ["musk", "ë¨¸ìŠ¤í¬", "musk", "ì•°ë²„"],
        "í”„ë£¨í‹°": ["berry", "apple", "peach", "fruit", "ë² ë¦¬", "ì‚¬ê³¼", "ë³µìˆ­ì•„"]
    }

    for perfume_type, keywords in type_keywords.items():
        if any(keyword in perfume_lower for keyword in keywords):
            return perfume_type

    return "ê¸°íƒ€"


async def rule_based_emotion_analysis(text: str, perfume_name: str = "") -> Dict[str, Any]:
    """ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ ë©”ì¸ í•¨ìˆ˜"""
    try:
        if not text or not text.strip():
            return {
                "success": True,
                "primary_emotion": "ì¤‘ë¦½",
                "confidence": 0.3,
                "emotion_tags": ["#neutral"],
                "analysis_method": "no_content",
                "emotion_scores": {},
                "context_detected": {}
            }

        text_lower = text.lower()
        emotion_scores = {}

        # 1. ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ê°ì • ì ìˆ˜ ê³„ì‚°
        for emotion, rule in EMOTION_RULES.items():
            score = 0
            matched_keywords = []

            for keyword in rule["keywords"]:
                if keyword in text_lower:
                    score += 1
                    matched_keywords.append(keyword)

            # í‚¤ì›Œë“œ ê°œìˆ˜ì— ë”°ë¥¸ ì ìˆ˜ ì •ê·œí™”
            if matched_keywords:
                emotion_scores[emotion] = {
                    "base_score": score,
                    "matched_keywords": matched_keywords,
                    "confidence": min(rule["base_confidence"] + (score - 1) * 0.1, 0.95)
                }

        # 2. ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ
        context = extract_context_from_text(text)

        # 3. í–¥ìˆ˜ íƒ€ì… ê°ì • ë³´ì •
        perfume_type = detect_perfume_type(perfume_name)
        if perfume_type in PERFUME_TYPE_EMOTIONS:
            for emotion in PERFUME_TYPE_EMOTIONS[perfume_type]:
                if emotion in emotion_scores:
                    emotion_scores[emotion]["confidence"] += 0.1
                else:
                    emotion_scores[emotion] = {
                        "base_score": 0.5,
                        "matched_keywords": [f"í–¥ìˆ˜íƒ€ì…:{perfume_type}"],
                        "confidence": 0.4
                    }

        # 4. ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì • ë³´ì •
        for context_type, context_value in context.items():
            if context_value and context_type in CONTEXT_EMOTION_MODIFIERS:
                modifiers = CONTEXT_EMOTION_MODIFIERS[context_type].get(context_value, {})
                for emotion, boost in modifiers.items():
                    if emotion in emotion_scores:
                        emotion_scores[emotion]["confidence"] += boost
                    else:
                        emotion_scores[emotion] = {
                            "base_score": 0.3,
                            "matched_keywords": [f"ì»¨í…ìŠ¤íŠ¸:{context_value}"],
                            "confidence": 0.3 + boost
                        }

        # 5. ìµœì¢… ê°ì • ê²°ì •
        if not emotion_scores:
            primary_emotion = "ì¤‘ë¦½"
            confidence = 0.3
            emotion_tags = ["#neutral"]
        else:
            # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ê°ì • ì„ íƒ
            primary_emotion = max(emotion_scores.keys(),
                                  key=lambda x: emotion_scores[x]["confidence"])
            confidence = emotion_scores[primary_emotion]["confidence"]
            emotion_tags = EMOTION_RULES[primary_emotion]["tags"].copy()

            # ìƒìœ„ 2ê°œ ê°ì •ì˜ íƒœê·¸ë„ í¬í•¨
            sorted_emotions = sorted(emotion_scores.items(),
                                     key=lambda x: x[1]["confidence"], reverse=True)
            for emotion, data in sorted_emotions[1:3]:  # 2, 3ë²ˆì§¸ ê°ì •
                if data["confidence"] > 0.4:  # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ
                    emotion_tags.extend(EMOTION_RULES[emotion]["tags"][:2])

        # ì¤‘ë³µ íƒœê·¸ ì œê±°
        emotion_tags = list(set(emotion_tags))

        # 6. ë¶„ì„ ê²°ê³¼ ì •ë¦¬
        analysis_result = {
            "success": True,
            "primary_emotion": primary_emotion,
            "confidence": round(min(confidence, 0.95), 3),
            "emotion_tags": emotion_tags,
            "analysis_method": "rule_based",
            "emotion_scores": {k: round(v["confidence"], 3) for k, v in emotion_scores.items()},
            "context_detected": context,
            "perfume_type": perfume_type,
            "matched_keywords_summary": {
                emotion: data["matched_keywords"]
                for emotion, data in emotion_scores.items()
            }
        }

        logger.info(f"ğŸ¯ ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ ì™„ë£Œ: {primary_emotion} ({confidence:.3f})")
        return analysis_result

    except Exception as e:
        logger.error(f"âŒ ë£° ê¸°ë°˜ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "primary_emotion": "ì¤‘ë¦½",
            "confidence": 0.3,
            "emotion_tags": ["#neutral"],
            "analysis_method": "error_fallback",
            "error": str(e)
        }


# ì „ì—­ ë°ì´í„°
diary_data = load_diary_data()


# âœ… API ì—”ë“œí¬ì¸íŠ¸ë“¤

@router.get("/emotion-status", summary="ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ ìƒíƒœ")
async def check_emotion_status():
    """ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return JSONResponse(content={
        "emotion_analyzer_available": False,
        "analysis_method": "rule_based",
        "supported_emotions": list(EMOTION_RULES.keys()),
        "system_status": "rule_based_only",
        "context_modifiers": list(CONTEXT_EMOTION_MODIFIERS.keys()),
        "perfume_types": list(PERFUME_TYPE_EMOTIONS.keys())
    })


@router.post("/", summary="ì‹œí–¥ ì¼ê¸° ì‘ì„±")
async def write_diary(
        entry: DiaryCreateRequest,
        background_tasks: BackgroundTasks,
        user=Depends(verify_firebase_token_optional)
):
    try:
        user_id = user["uid"]
        now = datetime.now().isoformat()
        diary_id = str(uuid.uuid4())

        logger.info(f"ğŸ“ ìƒˆ ì¼ê¸° ì‘ì„±: {user.get('name', 'ìµëª…')} - {entry.perfume_name}")

        # ë£° ê¸°ë°˜ ê°ì • ë¶„ì„
        initial_analysis = None
        if entry.content and entry.content.strip():
            try:
                initial_analysis = await asyncio.wait_for(
                    rule_based_emotion_analysis(entry.content, entry.perfume_name),
                    timeout=5.0  # ë£° ê¸°ë°˜ì´ë¯€ë¡œ ë” ë¹ ë¦„
                )
            except Exception as e:
                logger.error(f"âŒ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
                initial_analysis = {
                    "success": False,
                    "primary_emotion": "ì¤‘ë¦½",
                    "confidence": 0.3,
                    "emotion_tags": ["#neutral"],
                    "analysis_method": "error"
                }

        # ì¼ê¸° ë°ì´í„° ìƒì„±
        diary = {
            "id": diary_id,
            "user_id": user_id,
            "user_name": user.get("name", "ìµëª… ì‚¬ìš©ì"),
            "user_profile_image": user.get("picture", ""),
            "perfume_id": f"perfume_{entry.perfume_name.lower().replace(' ', '_')}",
            "perfume_name": entry.perfume_name,
            "brand": "Unknown Brand",
            "content": entry.content or "",
            "tags": entry.emotion_tags or [],
            "likes": 0,
            "comments": 0,
            "is_public": entry.is_public,
            "created_at": now,
            "updated_at": now,

            # ê°ì • ë¶„ì„ ì •ë³´
            "emotion_analysis": initial_analysis,
            "primary_emotion": initial_analysis.get("primary_emotion", "ì¤‘ë¦½") if initial_analysis else "ì¤‘ë¦½",
            "emotion_confidence": initial_analysis.get("confidence", 0.0) if initial_analysis else 0.0,
            "emotion_tags_auto": initial_analysis.get("emotion_tags", []) if initial_analysis else [],
            "emotion_analysis_status": "completed" if initial_analysis and initial_analysis.get(
                "success") else "failed",
            "analysis_method": "rule_based"
        }

        # íƒœê·¸ ë³‘í•© (ì‚¬ìš©ì ì…ë ¥ íƒœê·¸ + ìë™ ë¶„ì„ íƒœê·¸)
        if initial_analysis and initial_analysis.get("emotion_tags"):
            auto_tags = initial_analysis.get("emotion_tags", [])
            manual_tags = entry.emotion_tags or []
            diary["tags"] = list(set(manual_tags + auto_tags))

        # ì €ì¥
        diary_data.append(diary)
        save_diary_data(diary_data)

        return JSONResponse(
            status_code=200,
            content={
                "message": "ì‹œí–¥ ì¼ê¸°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "diary_id": diary_id,
                "emotion_analysis": {
                    "status": diary["emotion_analysis_status"],
                    "method": "rule_based",
                    "primary_emotion": diary["primary_emotion"],
                    "confidence": diary["emotion_confidence"],
                    "context_detected": initial_analysis.get("context_detected", {}) if initial_analysis else {},
                    "perfume_type": initial_analysis.get("perfume_type", "ê¸°íƒ€") if initial_analysis else "ê¸°íƒ€"
                }
            }
        )

    except Exception as e:
        logger.error(f"âŒ ì¼ê¸° ì €ì¥ ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={"message": f"ì¼ê¸° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
        )


@router.get("/", summary="ì‹œí–¥ ì¼ê¸° ëª©ë¡ ì¡°íšŒ")
async def get_diary_list(
        public: Optional[bool] = Query(None, description="ê³µê°œ ì—¬ë¶€ í•„í„°"),
        page: Optional[int] = Query(1, description="í˜ì´ì§€ ë²ˆí˜¸"),
        size: Optional[int] = Query(10, description="í˜ì´ì§€ í¬ê¸°"),
        keyword: Optional[str] = Query(None, description="ê²€ìƒ‰ í‚¤ì›Œë“œ")
):
    try:
        filtered_data = diary_data.copy()

        # í•„í„°ë§
        if public is not None:
            filtered_data = [d for d in filtered_data if d.get("is_public") == public]

        if keyword:
            filtered_data = [d for d in filtered_data
                             if keyword.lower() in d.get("content", "").lower()
                             or keyword.lower() in d.get("perfume_name", "").lower()]

        # ì •ë ¬ ë° í˜ì´ì§•
        filtered_data.sort(key=lambda x: x.get("created_at", ""), reverse=True)
        start = (page - 1) * size
        end = start + size
        paginated_data = filtered_data[start:end]

        # ì‘ë‹µ ë°ì´í„° ë³€í™˜
        response_data = []
        for item in paginated_data:
            response_data.append({
                "id": item.get("id", ""),
                "user_name": item.get("user_name", "ìµëª…"),
                "perfume_name": item.get("perfume_name", ""),
                "content": item.get("content", ""),
                "tags": item.get("tags", []),
                "primary_emotion": item.get("primary_emotion", "ì¤‘ë¦½"),
                "emotion_confidence": item.get("emotion_confidence", 0.0),
                "analysis_method": item.get("analysis_method", "rule_based"),
                "likes": item.get("likes", 0),
                "created_at": item.get("created_at", "")
            })

        return BaseResponse(
            message=f"ì‹œí–¥ ì¼ê¸° ëª©ë¡ ì¡°íšŒ ì„±ê³µ (ì´ {len(filtered_data)}ê°œ)",
            result={
                "diaries": response_data,
                "total_count": len(filtered_data),
                "page": page,
                "size": size,
                "has_next": end < len(filtered_data),
                "analysis_method": "rule_based"
            }
        )

    except Exception as e:
        logger.error(f"âŒ ì¼ê¸° ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={"message": f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"}
        )


@router.post("/{diary_id}/like", summary="ì‹œí–¥ ì¼ê¸° ì¢‹ì•„ìš”")
async def like_diary(diary_id: str):
    try:
        for diary in diary_data:
            if diary.get("id") == diary_id:
                diary["likes"] = diary.get("likes", 0) + 1
                diary["updated_at"] = datetime.now().isoformat()
                save_diary_data(diary_data)
                return JSONResponse(content={"message": "ì¢‹ì•„ìš”ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."})

        return JSONResponse(status_code=404, content={"message": "ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

    except Exception as e:
        return JSONResponse(status_code=500, content={"message": f"ì˜¤ë¥˜: {str(e)}"})


@router.delete("/{diary_id}/unlike", summary="ì‹œí–¥ ì¼ê¸° ì¢‹ì•„ìš” ì·¨ì†Œ")
async def unlike_diary(diary_id: str):
    try:
        for diary in diary_data:
            if diary.get("id") == diary_id:
                diary["likes"] = max(0, diary.get("likes", 0) - 1)
                diary["updated_at"] = datetime.now().isoformat()
                save_diary_data(diary_data)
                return JSONResponse(content={"message": "ì¢‹ì•„ìš”ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."})

        return JSONResponse(status_code=404, content={"message": "ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

    except Exception as e:
        return JSONResponse(status_code=500, content={"message": f"ì˜¤ë¥˜: {str(e)}"})


@router.get("/emotions/rules", summary="ê°ì • ë¶„ì„ ë£° ì¡°íšŒ")
async def get_emotion_rules():
    """í˜„ì¬ ì ìš© ì¤‘ì¸ ê°ì • ë¶„ì„ ë£° ë°˜í™˜"""
    return JSONResponse(content={
        "emotion_rules": {
            emotion: {
                "keyword_count": len(rules["keywords"]),
                "sample_keywords": rules["keywords"][:5],
                "tags": rules["tags"],
                "base_confidence": rules["base_confidence"]
            }
            for emotion, rules in EMOTION_RULES.items()
        },
        "context_modifiers": CONTEXT_EMOTION_MODIFIERS,
        "perfume_type_emotions": PERFUME_TYPE_EMOTIONS,
        "total_emotions": len(EMOTION_RULES)
    })


@router.post("/test-analysis", summary="ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸")
async def test_emotion_analysis(
        text: str = Query(..., description="ë¶„ì„í•  í…ìŠ¤íŠ¸"),
        perfume_name: str = Query("", description="í–¥ìˆ˜ ì´ë¦„")
):
    """ê°ì • ë¶„ì„ ë£° í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸"""
    try:
        result = await rule_based_emotion_analysis(text, perfume_name)
        return JSONResponse(content={
            "input": {"text": text, "perfume_name": perfume_name},
            "analysis_result": result
        })
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"}
        )