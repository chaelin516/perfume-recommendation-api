import os
import pickle
import logging
import random
import sys
import subprocess
import requests
import numpy as np
from datetime import datetime
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Literal, Optional, Dict, Any
import pandas as pd
from sklearn.preprocessing import OneHotEncoder

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recommend_router")

# â”€â”€â”€ 1. perfume_final_dataset.csv ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/perfume_final_dataset.csv")
try:
    df = pd.read_csv(DATA_PATH)
    df.fillna("", inplace=True)
    logger.info(f"âœ… Perfume dataset loaded: {df.shape[0]} rows")
    logger.info(f"ğŸ“‹ Available columns: {list(df.columns)}")

    # âœ… ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    required_columns = ['name', 'brand', 'image_url', 'notes']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        logger.error(f"âŒ Missing required columns: {missing_columns}")
        raise RuntimeError(f"Missing required columns: {missing_columns}")

    # âœ… emotion ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
    if 'desired_impression' in df.columns:
        logger.info("âœ… Using 'desired_impression' column for emotion data")
    if 'emotion_cluster' in df.columns:
        logger.info("âœ… Using 'emotion_cluster' column for cluster data")
        # emotion_cluster ì»¬ëŸ¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        df['emotion_cluster'] = pd.to_numeric(df['emotion_cluster'], errors='coerce').fillna(0).astype(int)
        logger.info(f"ğŸ“Š Emotion clusters: {sorted(df['emotion_cluster'].unique())}")
    else:
        logger.warning("âš ï¸ No emotion_cluster column found")

    # ğŸ“Š ë°ì´í„° ìƒ˜í”Œ ë¡œê·¸
    if len(df) > 0:
        sample_row = df.iloc[0]
        logger.info(f"ğŸ“ Sample data: {sample_row['name']} by {sample_row['brand']}")

except Exception as e:
    logger.error(f"âŒ perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    raise RuntimeError(f"perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# â”€â”€â”€ 2. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "../models/final_model_perfume.keras")
ENCODER_PATH = os.path.join(BASE_DIR, "../models/encoder.pkl")

# â”€â”€â”€ 3. ì „ì—­ ë³€ìˆ˜ ë° ìƒíƒœ ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_model = None
_encoder = None
_model_available = False
_fallback_encoder = None
_model_download_attempted = False

# â”€â”€â”€ 4. ê°ì • í´ëŸ¬ìŠ¤í„° ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_CLUSTER_MAP = {
    0: "ì°¨ë¶„í•œ, í¸ì•ˆí•œ",
    1: "ìì‹ ê°, ì‹ ì„ í•¨",
    2: "ìš°ì•„í•¨, ì¹œê·¼í•¨",
    3: "ìˆœìˆ˜í•¨, ì¹œê·¼í•¨",
    4: "ì‹ ë¹„ë¡œìš´, ë§¤ë ¥ì ",
    5: "í™œê¸°ì°¬, ì—ë„ˆì§€"
}


# â”€â”€â”€ 5. Git LFS í¬ì¸í„° íŒŒì¼ ê°ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def is_git_lfs_pointer_file(file_path: str) -> bool:
    """íŒŒì¼ì´ Git LFS í¬ì¸í„° íŒŒì¼ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        if not os.path.exists(file_path):
            return False

        with open(file_path, 'r', encoding='utf-8') as f:
            first_line = f.readline().strip()
            return first_line.startswith('version https://git-lfs.github.com/spec/')
    except (UnicodeDecodeError, IOError):
        # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì´ë©´ Git LFS í¬ì¸í„°ê°€ ì•„ë‹˜
        return False


def get_file_info(file_path: str) -> Dict[str, Any]:
    """íŒŒì¼ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not os.path.exists(file_path):
        return {"exists": False}

    info = {
        "exists": True,
        "size": os.path.getsize(file_path),
        "is_lfs_pointer": is_git_lfs_pointer_file(file_path)
    }

    # íŒŒì¼ ì‹œì‘ ë¶€ë¶„ í™•ì¸
    try:
        with open(file_path, 'rb') as f:
            first_bytes = f.read(100)
            info["first_bytes_hex"] = first_bytes[:20].hex()
            info["is_binary"] = not all(32 <= b < 127 or b in [9, 10, 13] for b in first_bytes[:50])
    except Exception as e:
        info["read_error"] = str(e)

    return info


# â”€â”€â”€ 6. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_model_file(url: str, file_path: str, description: str) -> bool:
    """URLì—ì„œ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        logger.info(f"ğŸ“¥ {description} ë‹¤ìš´ë¡œë“œ ì‹œì‘: {url}")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        response = requests.get(url, stream=True, timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        response.raise_for_status()

        total_size = int(response.headers.get('content-length', 0))
        downloaded_size = 0

        with open(file_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded_size += len(chunk)

                    # ì§„í–‰ë¥  ë¡œê·¸ (10MBë§ˆë‹¤)
                    if downloaded_size % (10 * 1024 * 1024) == 0:
                        progress = (downloaded_size / total_size * 100) if total_size > 0 else 0
                        logger.info(f"ğŸ“Š ë‹¤ìš´ë¡œë“œ ì§„í–‰ë¥ : {progress:.1f}% ({downloaded_size:,} bytes)")

        logger.info(f"âœ… {description} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_path} ({downloaded_size:,} bytes)")
        return True

    except Exception as e:
        logger.error(f"âŒ {description} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


def download_models_if_needed():
    """í•„ìš”í•œ ê²½ìš° ëª¨ë¸ íŒŒì¼ë“¤ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model_download_attempted

    if _model_download_attempted:
        return

    _model_download_attempted = True

    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë‹¤ìš´ë¡œë“œ URL í™•ì¸
    model_url = os.getenv('MODEL_DOWNLOAD_URL')
    encoder_url = os.getenv('ENCODER_DOWNLOAD_URL')

    # ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(MODEL_PATH) or is_git_lfs_pointer_file(MODEL_PATH):
        if model_url:
            download_model_file(model_url, MODEL_PATH, "Keras ëª¨ë¸")
        else:
            logger.warning("âš ï¸ MODEL_DOWNLOAD_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ì¸ì½”ë” íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    if not os.path.exists(ENCODER_PATH) or is_git_lfs_pointer_file(ENCODER_PATH):
        if encoder_url:
            download_model_file(encoder_url, ENCODER_PATH, "Encoder")
        else:
            logger.warning("âš ï¸ ENCODER_DOWNLOAD_URL í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


# â”€â”€â”€ 7. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_model_availability():
    """ëª¨ë¸ íŒŒì¼ë“¤ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    global _model_available

    logger.info("ğŸ” ëª¨ë¸ íŒŒì¼ ê°€ìš©ì„± í™•ì¸ ì¤‘...")

    # ë¨¼ì € íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œë„
    download_models_if_needed()

    model_info = get_file_info(MODEL_PATH)
    encoder_info = get_file_info(ENCODER_PATH)

    logger.info(f"ğŸ“„ ëª¨ë¸ íŒŒì¼ ì •ë³´: {model_info}")
    logger.info(f"ğŸ“„ ì¸ì½”ë” íŒŒì¼ ì •ë³´: {encoder_info}")

    # Git LFS í¬ì¸í„° íŒŒì¼ ê°ì§€
    if model_info.get("is_lfs_pointer"):
        logger.warning(f"âš ï¸ {MODEL_PATH}ëŠ” Git LFS í¬ì¸í„° íŒŒì¼ì…ë‹ˆë‹¤.")
        _model_available = False
        return False

    if encoder_info.get("is_lfs_pointer"):
        logger.warning(f"âš ï¸ {ENCODER_PATH}ëŠ” Git LFS í¬ì¸í„° íŒŒì¼ì…ë‹ˆë‹¤.")
        _model_available = False
        return False

    # ì‹¤ì œ ë°”ì´ë„ˆë¦¬ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
    model_available = (
            model_info.get("exists", False) and
            not model_info.get("is_lfs_pointer", False) and
            model_info.get("size", 0) > 1000000  # ìµœì†Œ 1MB ì´ìƒ
    )

    encoder_available = (
            encoder_info.get("exists", False) and
            not encoder_info.get("is_lfs_pointer", False) and
            encoder_info.get("size", 0) > 100  # ìµœì†Œ 100B ì´ìƒ
    )

    _model_available = model_available and encoder_available

    logger.info(f"ğŸ¤– ëª¨ë¸ ê°€ìš©ì„±: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if _model_available else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")

    return _model_available


def get_model():
    """Keras ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model

    if _model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
                return None

            if is_git_lfs_pointer_file(MODEL_PATH):
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ Git LFS í¬ì¸í„°ì…ë‹ˆë‹¤: {MODEL_PATH}")
                return None

            # íŒŒì¼ í¬ê¸° í™•ì¸
            model_size = os.path.getsize(MODEL_PATH)
            if model_size < 1000000:  # 1MB ë¯¸ë§Œ
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {model_size} bytes")
                return None

            # TensorFlow ë™ì  ì„í¬íŠ¸
            try:
                tf_start = datetime.now()
                from tensorflow.keras.models import load_model
                tf_load_time = (datetime.now() - tf_start).total_seconds()

                logger.info(f"ğŸ“¦ Keras ëª¨ë¸ ë¡œë”© ì‹œë„ (TF ë¡œë”©: {tf_load_time:.3f}ì´ˆ)")

                model_start = datetime.now()
                _model = load_model(MODEL_PATH, compile=False)  # compile=Falseë¡œ ë¹ ë¥¸ ë¡œë”©
                model_load_time = (datetime.now() - model_start).total_seconds()

                # ëª¨ë¸ êµ¬ì¡° í™•ì¸
                logger.info(f"âœ… Keras ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ëª¨ë¸ ë¡œë”©: {model_load_time:.3f}ì´ˆ)")
                logger.info(f"ğŸ“Š ëª¨ë¸ ì…ë ¥ shape: {_model.input_shape}")
                logger.info(f"ğŸ“Š ëª¨ë¸ ì¶œë ¥ shape: {_model.output_shape}")

                # ì¶œë ¥ í¬ê¸° í™•ì¸
                output_size = _model.output_shape[-1]
                if output_size == 6:
                    logger.info("ğŸ¯ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ ëª¨ë¸ë¡œ ì¸ì‹ë¨")
                else:
                    logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì¶œë ¥ í¬ê¸°: {output_size}")

            except ImportError as e:
                logger.error(f"âŒ TensorFlowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return None
            except Exception as e:
                logger.error(f"âŒ Keras ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜ˆì™¸: {e}")
            return None

    return _model


def get_saved_encoder():
    """ì €ì¥ëœ encoder.pklì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _encoder

    if _encoder is None:
        try:
            if not os.path.exists(ENCODER_PATH):
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")
                return None

            if is_git_lfs_pointer_file(ENCODER_PATH):
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ Git LFS í¬ì¸í„°ì…ë‹ˆë‹¤: {ENCODER_PATH}")
                return None

            logger.info(f"ğŸ“¦ ì¸ì½”ë” ë¡œë”© ì‹œë„: {ENCODER_PATH}")
            with open(ENCODER_PATH, "rb") as f:
                _encoder = pickle.load(f)
            logger.info("âœ… encoder.pkl ë¡œë“œ ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ encoder.pkl ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    return _encoder


def get_fallback_encoder():
    """Fallback OneHotEncoderë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global _fallback_encoder

    if _fallback_encoder is None:
        try:
            logger.info("ğŸ”§ Fallback OneHotEncoder ìƒì„± ì¤‘...")

            CATEGORIES = [
                ["women", "men", "unisex"],  # gender
                ["spring", "summer", "fall", "winter"],  # season
                ["day", "night"],  # time
                ["confident", "elegant", "pure", "friendly", "mysterious", "fresh"],  # impression
                ["casual", "work", "date"],  # activity
                ["hot", "cold", "rainy", "any"]  # weather
            ]

            _fallback_encoder = OneHotEncoder(
                categories=CATEGORIES,
                handle_unknown="ignore",
                sparse=False
            )

            # ë”ë¯¸ ë°ì´í„°ë¡œ fit
            dummy_data = [
                ["women", "spring", "day", "confident", "casual", "hot"],
                ["men", "summer", "night", "elegant", "work", "cold"],
                ["unisex", "fall", "day", "pure", "date", "rainy"],
                ["women", "winter", "night", "friendly", "casual", "any"],
                ["men", "spring", "day", "mysterious", "work", "hot"],
                ["unisex", "summer", "night", "fresh", "date", "cold"]
            ]

            _fallback_encoder.fit(dummy_data)
            logger.info("âœ… Fallback OneHotEncoder ìƒì„± ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ Fallback encoder ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    return _fallback_encoder


# â”€â”€â”€ 8. AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_with_emotion_cluster_model(request_dict: dict) -> pd.DataFrame:
    """ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ì‚¬ìš©í•œ AI ì¶”ì²œ"""

    try:
        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # ì¸ì½”ë”ë¡œ ì…ë ¥ ë°ì´í„° ë³€í™˜
        raw_features = [
            request_dict["gender"],
            request_dict["season"],
            request_dict["time"],
            request_dict["impression"],
            request_dict["activity"],
            request_dict["weather"]
        ]

        # ì¸ì½”ë” ì‚¬ìš©
        encoder = get_saved_encoder()
        if encoder:
            try:
                x_input = encoder.transform([raw_features])
                encoder_method = "ì €ì¥ëœ ì¸ì½”ë”"
            except Exception as e:
                logger.warning(f"âš ï¸ encoder.pkl ì‹¤íŒ¨ ({e}), fallback encoder ì‚¬ìš©")
                fallback_encoder = get_fallback_encoder()
                if fallback_encoder:
                    x_input = fallback_encoder.transform([raw_features])
                    encoder_method = "Fallback ì¸ì½”ë”"
                else:
                    raise Exception("Fallback encoder ìƒì„± ì‹¤íŒ¨")
        else:
            fallback_encoder = get_fallback_encoder()
            if fallback_encoder:
                x_input = fallback_encoder.transform([raw_features])
                encoder_method = "Fallback ì¸ì½”ë”"
            else:
                raise Exception("Fallback encoder ìƒì„± ì‹¤íŒ¨")

        logger.info(f"ğŸ”® ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì‹œì‘ (ì…ë ¥ shape: {x_input.shape}, ì¸ì½”ë”: {encoder_method})")

        # ëª¨ë¸ ì˜ˆì¸¡ (ê°ì • í´ëŸ¬ìŠ¤í„°)
        preds = model.predict(x_input, verbose=0)  # (1, 6) ì¶œë ¥
        cluster_probabilities = preds[0]  # [0.1, 0.8, 0.05, 0.02, 0.02, 0.01]
        predicted_cluster = int(np.argmax(cluster_probabilities))  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„°
        confidence = float(cluster_probabilities[predicted_cluster])

        cluster_name = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")
        logger.info(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°: {predicted_cluster} ({cluster_name}) - ì‹ ë¢°ë„: {confidence:.3f}")

        # ê°ì • í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
            logger.info(f"ğŸ“‹ í´ëŸ¬ìŠ¤í„° {predicted_cluster} í–¥ìˆ˜ ê°œìˆ˜: {len(cluster_perfumes)}ê°œ")
        else:
            logger.warning("âš ï¸ emotion_cluster ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ë°ì´í„° ì‚¬ìš©")
            cluster_perfumes = df.copy()

        # í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
        if cluster_perfumes.empty:
            logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {predicted_cluster}ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìŒ")
            # ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
            second_best = int(np.argsort(cluster_probabilities)[-2])
            cluster_perfumes = df[df['emotion_cluster'] == second_best].copy()
            predicted_cluster = second_best
            confidence = float(cluster_probabilities[second_best])
            logger.info(f"ğŸ“‹ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° {second_best} ì‚¬ìš©: {len(cluster_perfumes)}ê°œ")

        # ì¶”ê°€ í•„í„°ë§ (ì„±ë³„, ê³„ì ˆ ë“±)
        original_count = len(cluster_perfumes)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == request_dict["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered
                logger.info(f"  ì„±ë³„ '{request_dict['gender']}' í•„í„°ë§: {original_count} â†’ {len(cluster_perfumes)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    request_dict["season"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered
                logger.info(f"  ê³„ì ˆ '{request_dict['season']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in cluster_perfumes.columns:
            time_filtered = cluster_perfumes[
                cluster_perfumes['time_tags'].str.contains(
                    request_dict["time"], na=False, case=False
                )
            ]
            if not time_filtered.empty:
                cluster_perfumes = time_filtered
                logger.info(f"  ì‹œê°„ '{request_dict['time']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # AI ì‹ ë¢°ë„ ê¸°ë°˜ ì ìˆ˜ í• ë‹¹
        cluster_perfumes = cluster_perfumes.copy()

        # í´ëŸ¬ìŠ¤í„° ì‹ ë¢°ë„ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ ì‚¬ìš©
        base_score = confidence * 0.8  # AI ì‹ ë¢°ë„ì˜ 80%ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ

        scores = []
        for idx, (_, row) in enumerate(cluster_perfumes.iterrows()):
            score = base_score

            # ì¶”ê°€ ì¡°ê±´ ì¼ì¹˜ ë³´ë„ˆìŠ¤
            if 'season_tags' in row and request_dict["season"].lower() in str(row['season_tags']).lower():
                score += 0.08
            if 'time_tags' in row and request_dict["time"].lower() in str(row['time_tags']).lower():
                score += 0.06
            if 'desired_impression' in row and request_dict["impression"].lower() in str(
                    row['desired_impression']).lower():
                score += 0.05

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']
            if any(popular in str(row.get('brand', '')) for popular in popular_brands):
                score += 0.03

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜ (ì•ìª½ì¼ìˆ˜ë¡ ì•½ê°„ ë†’ì€ ì ìˆ˜)
            position_bonus = (len(cluster_perfumes) - idx) / len(cluster_perfumes) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.03, 0.05)

            # ì •ê·œí™” (0.4 ~ 0.95 ë²”ìœ„)
            score = max(0.4, min(0.95, score))
            scores.append(score)

        cluster_perfumes['score'] = scores

        # ìƒìœ„ 10ê°œ ì„ íƒ
        top_10 = cluster_perfumes.nlargest(10, 'score')

        logger.info(f"âœ… AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì™„ë£Œ: {len(top_10)}ê°œ")
        if not top_10.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_10['score'].min():.3f} ~ {top_10['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_10['score'].mean():.3f}")

        return top_10

    except Exception as e:
        logger.error(f"âŒ AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 9. ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def rule_based_recommendation(request_data: dict, top_k: int = 10) -> List[dict]:
    """ë£° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ (AI ëª¨ë¸ ëŒ€ì²´)"""
    logger.info("ğŸ¯ ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘")

    try:
        # í•„í„°ë§ ì¡°ê±´
        gender = request_data["gender"]
        season = request_data["season"]
        time = request_data["time"]
        impression = request_data["impression"]
        activity = request_data["activity"]
        weather = request_data["weather"]

        logger.info(f"ğŸ” í•„í„°ë§ ì¡°ê±´: gender={gender}, season={season}, time={time}, "
                    f"impression={impression}, activity={activity}, weather={weather}")

        # ì„±ë³„ ë§¤í•‘
        gender_map = {"women": "women", "men": "men", "unisex": "unisex"}
        mapped_gender = gender_map.get(gender, "unisex")

        # 1ë‹¨ê³„: ê¸°ë³¸ í•„í„°ë§
        candidates = df.copy()
        original_count = len(candidates)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in df.columns:
            gender_filtered = candidates[candidates['gender'] == mapped_gender]
            if not gender_filtered.empty:
                candidates = gender_filtered
                logger.info(f"  ì„±ë³„ '{mapped_gender}' í•„í„°ë§: {original_count} â†’ {len(candidates)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in df.columns:
            season_filtered = candidates[
                candidates['season_tags'].str.contains(season, na=False, case=False)
            ]
            if not season_filtered.empty:
                candidates = season_filtered
                logger.info(f"  ê³„ì ˆ '{season}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in df.columns:
            time_filtered = candidates[
                candidates['time_tags'].str.contains(time, na=False, case=False)
            ]
            if not time_filtered.empty:
                candidates = time_filtered
                logger.info(f"  ì‹œê°„ '{time}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì¸ìƒ í•„í„°ë§
        if 'desired_impression' in df.columns:
            impression_filtered = candidates[
                candidates['desired_impression'].str.contains(impression, na=False, case=False)
            ]
            if not impression_filtered.empty:
                candidates = impression_filtered
                logger.info(f"  ì¸ìƒ '{impression}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # í™œë™ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'activity' in df.columns:
            activity_filtered = candidates[
                candidates['activity'].str.contains(activity, na=False, case=False)
            ]
            if not activity_filtered.empty:
                candidates = activity_filtered
                logger.info(f"  í™œë™ '{activity}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ë‚ ì”¨ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'weather' in df.columns and weather != 'any':
            weather_filtered = candidates[
                candidates['weather'].str.contains(weather, na=False, case=False)
            ]
            if not weather_filtered.empty:
                candidates = weather_filtered
                logger.info(f"  ë‚ ì”¨ '{weather}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # 2ë‹¨ê³„: ìŠ¤ì½”ì–´ë§
        if candidates.empty:
            logger.warning("âš ï¸ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ì—ì„œ ë‹¤ì–‘ì„± ê¸°ë°˜ ì„ íƒ")
            # ë‹¤ì–‘í•œ ë¸Œëœë“œì—ì„œ ê³ ë¥´ê²Œ ì„ íƒ
            if 'brand' in df.columns:
                unique_brands = df['brand'].unique()
                candidates_list = []
                per_brand = max(1, top_k // len(unique_brands))

                for brand in unique_brands:
                    brand_perfumes = df[df['brand'] == brand].sample(
                        n=min(per_brand, len(df[df['brand'] == brand])),
                        random_state=42
                    )
                    candidates_list.append(brand_perfumes)

                candidates = pd.concat(candidates_list).head(top_k)
            else:
                candidates = df.sample(n=min(top_k, len(df)), random_state=42)

        # ì ìˆ˜ ê³„ì‚° (ë” ì •êµí•˜ê³  ë‹¤ì–‘í•œ ë¡œì§)
        candidates = candidates.copy()
        scores = []

        # ë¸Œëœë“œë³„ ê°€ì¤‘ì¹˜ (ì¸ê¸° ë¸Œëœë“œ ì˜ˆì‹œ)
        popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']

        for idx, (_, row) in enumerate(candidates.iterrows()):
            score = 0.3  # ë” ë‚®ì€ ê¸°ë³¸ ì ìˆ˜

            # 1. ì¡°ê±´ ì¼ì¹˜ë„ ì ìˆ˜ (ì´ë¯¸ í•„í„°ë§ë˜ì—ˆìœ¼ë¯€ë¡œ ì„¸ë°€í•œ ì°¨ì´)
            brand_name = str(row.get('brand', ''))
            notes_text = str(row.get('notes', ''))

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            if any(popular in brand_name for popular in popular_brands):
                score += 0.15

            # ë…¸íŠ¸ ë³µì¡ì„± (ë” ë§ì€ ë…¸íŠ¸ = ë” ë³µì¡í•œ í–¥ìˆ˜)
            note_count = len([n.strip() for n in notes_text.split(',') if n.strip()])
            if note_count >= 8:
                score += 0.10
            elif note_count >= 5:
                score += 0.05

            # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì •í™•ë„ (ë¶€ë¶„ ë§¤ì¹­)
            impression_match_count = 0
            if 'desired_impression' in row:
                impressions = str(row['desired_impression']).lower().split(',')
                impression_match_count = sum(1 for imp in impressions if impression.lower() in imp.strip())
                score += impression_match_count * 0.08

            # ê³„ì ˆ/ì‹œê°„ ë§¤ì¹­ ì •í™•ë„
            if 'season_tags' in row:
                season_tags = str(row['season_tags']).lower()
                if season.lower() in season_tags:
                    # ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ ì‹œ ë” ë†’ì€ ì ìˆ˜
                    if f' {season.lower()} ' in f' {season_tags} ':
                        score += 0.12
                    else:
                        score += 0.08

            if 'time_tags' in row:
                time_tags = str(row['time_tags']).lower()
                if time.lower() in time_tags:
                    if f' {time.lower()} ' in f' {time_tags} ':
                        score += 0.12
                    else:
                        score += 0.08

            # í™œë™ ë§¤ì¹­
            if 'activity' in row and activity.lower() in str(row['activity']).lower():
                score += 0.08

            # ë‚ ì”¨ ë§¤ì¹­
            if 'weather' in row and weather != 'any':
                if weather.lower() in str(row['weather']).lower():
                    score += 0.06
            elif weather == 'any':
                score += 0.03  # any weatherëŠ” ì‘ì€ ë³´ë„ˆìŠ¤

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜ (ì•ìª½ì¼ìˆ˜ë¡ ì•½ê°„ ë†’ì€ ì ìˆ˜)
            position_bonus = (len(candidates) - idx) / len(candidates) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë” í° ë²”ìœ„ë¡œ ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.15, 0.15)

            # ì ìˆ˜ ì •ê·œí™” (0.2 ~ 0.95 ë²”ìœ„)
            score = max(0.2, min(0.95, score))
            scores.append(score)

        candidates['score'] = scores

        # ìƒìœ„ Kê°œ ì„ íƒ
        top_candidates = candidates.nlargest(top_k, 'score')

        logger.info(f"âœ… ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ: ìµœì¢… {len(top_candidates)}ê°œ ì„ íƒ")
        if not top_candidates.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_candidates['score'].min():.3f} ~ {top_candidates['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_candidates['score'].mean():.3f}")

        return top_candidates.to_dict('records')

    except Exception as e:
        logger.error(f"âŒ ë£° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {e}")
        # ìµœì¢… ì•ˆì „ì¥ì¹˜: ì™„ì „ ëœë¤ ì¶”ì²œ
        logger.info("ğŸ² ì™„ì „ ëœë¤ ì¶”ì²œìœ¼ë¡œ ëŒ€ì²´")
        random_sample = df.sample(n=min(top_k, len(df)), random_state=42)
        random_sample = random_sample.copy()
        random_sample['score'] = [random.uniform(0.4, 0.7) for _ in range(len(random_sample))]
        return random_sample.to_dict('records')


def get_emotion_text(row):
    """ê°ì • ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # 1ìˆœìœ„: desired_impression
    if 'desired_impression' in df.columns and pd.notna(row.get('desired_impression')):
        return str(row['desired_impression'])

    # 2ìˆœìœ„: emotion_clusterë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if 'emotion_cluster' in df.columns and pd.notna(row.get('emotion_cluster')):
        cluster_id = int(row['emotion_cluster']) if str(row['emotion_cluster']).isdigit() else 0
        return EMOTION_CLUSTER_MAP.get(cluster_id, "ê· í˜•ì¡íŒ")

    return "ë‹¤ì–‘í•œ ê°ì •"


def get_recommendation_reason(score: float, method: str) -> str:
    """ì ìˆ˜ì™€ ë°©ë²•ì— ë”°ë¥¸ ì¶”ì²œ ì´ìœ  ìƒì„±"""

    if method.startswith("AI"):
        if score >= 0.9:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì˜ ì™„ë²½í•œ í–¥ìˆ˜ë¼ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤!"
        elif score >= 0.8:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì—ê²Œ ì˜ ë§ì„ ê²ƒì´ë¼ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤."
        elif score >= 0.6:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒˆë¡œìš´ ì‹œë„í•´ë³¼ ë§Œí•œ í–¥ìˆ˜ë¡œ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤."
        else:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒ‰ë‹¤ë¥¸ ë§¤ë ¥ì„ ì œì•ˆí•©ë‹ˆë‹¤."
    else:
        # ë£° ê¸°ë°˜ - ë” ë‹¤ì–‘í•œ ë©”ì‹œì§€
        if score >= 0.9:
            return f"ğŸ¯ ì¡°ê±´ ì™„ë²½ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ì´ë³´ë‹¤ ì™„ë²½í•  ìˆœ ì—†ì–´ìš”!"
        elif score >= 0.8:
            return f"â­ ì¡°ê±´ ë†’ì€ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ê°•ë ¥ ì¶”ì²œ!"
        elif score >= 0.6:
            return f"âœ¨ ì¡°ê±´ ì í•© (ì¼ì¹˜ë„ {score:.1%}) - ê³ ë ¤í•´ë³´ì„¸ìš”!"
        elif score >= 0.4:
            return f"ğŸ” ë¶€ë¶„ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ìƒˆë¡œìš´ ë°œê²¬ì´ ë  ìˆ˜ë„!"
        else:
            return f"ğŸ² ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ì œì•ˆ (ì¼ì¹˜ë„ {score:.1%}) - ë„ì „í•´ë³´ì„¸ìš”!"


# â”€â”€â”€ 10. ìŠ¤í‚¤ë§ˆ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class RecommendRequest(BaseModel):
    gender: Literal["women", "men", "unisex"]
    season: Literal["spring", "summer", "fall", "winter"]
    time: Literal["day", "night"]
    impression: Literal["confident", "elegant", "pure", "friendly", "mysterious", "fresh"]
    activity: Literal["casual", "work", "date"]
    weather: Literal["hot", "cold", "rainy", "any"]


class PerfumeRecommendItem(BaseModel):
    name: str
    brand: str
    image_url: str
    notes: str
    emotions: str
    reason: str
    score: Optional[float] = None
    method: Optional[str] = None


# â”€â”€â”€ 11. ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/perfumes", tags=["Perfume"])

# ì‹œì‘ ì‹œ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
logger.info("ğŸš€ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
check_model_availability()
logger.info("âœ… ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")


# â”€â”€â”€ 12. API ì—”ë“œí¬ì¸íŠ¸ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post(
    "/recommend",
    response_model=List[PerfumeRecommendItem],
    summary="í–¥ìˆ˜ ì¶”ì²œ (AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ + ë£° ê¸°ë°˜ Fallback)",
    description=(
            "ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n\n"
            "**ğŸ¤– ì¶”ì²œ ë°©ì‹:**\n"
            "1. **AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸**: 6ê°œ ì…ë ¥ â†’ 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ â†’ í•´ë‹¹ í´ëŸ¬ìŠ¤í„° í–¥ìˆ˜ ì¶”ì²œ\n"
            "2. **ë£° ê¸°ë°˜ Fallback**: ì¡°ê±´ë¶€ í•„í„°ë§ + ìŠ¤ì½”ì–´ë§ (ëª¨ë¸ì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°)\n"
            "3. **ë‹¤ì–‘ì„± ë³´ì¥**: ë¸Œëœë“œë³„ ê· í˜• ì¡íŒ ì¶”ì²œ\n\n"
            "**ğŸ“‹ ì…ë ¥ íŒŒë¼ë¯¸í„°:**\n"
            "- `gender`: ì„±ë³„ (women/men/unisex)\n"
            "- `season`: ê³„ì ˆ (spring/summer/fall/winter)\n"
            "- `time`: ì‹œê°„ëŒ€ (day/night)\n"
            "- `impression`: ì›í•˜ëŠ” ì¸ìƒ (confident/elegant/pure/friendly/mysterious/fresh)\n"
            "- `activity`: í™œë™ (casual/work/date)\n"
            "- `weather`: ë‚ ì”¨ (hot/cold/rainy/any)\n\n"
            "**ğŸ§  AI ëª¨ë¸ ì„¸ë¶€ì‚¬í•­:**\n"
            "- ëª¨ë¸ êµ¬ì¡°: Sequential (Dense 256 â†’ 128 â†’ 64 â†’ 6)\n"
            "- ì¶œë ¥: 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° í™•ë¥  (softmax)\n"
            "- í•™ìŠµ ë°ì´í„°: 2025-05-26 ì €ì¥\n"
            "- Keras ë²„ì „: 2.13.1\n\n"
            "**âœ¨ íŠ¹ì§•:**\n"
            "- Git LFS í¬ì¸í„° íŒŒì¼ ìë™ ê°ì§€\n"
            "- ëª¨ë¸ íŒŒì¼ ìë™ ë‹¤ìš´ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì‹œ)\n"
            "- ê²¬ê³ í•œ ì—ëŸ¬ í•¸ë“¤ë§\n"
            "- ìƒì„¸í•œ ì¶”ì²œ ì´ìœ  ì œê³µ"
    )
)
def recommend_perfumes(request: RecommendRequest):
    request_start_time = datetime.now()
    logger.info(f"ğŸ¯ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­ ì‹œì‘: {request}")

    # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    request_dict = request.dict()

    method_used = "ì•Œ ìˆ˜ ì—†ìŒ"

    # 1) AI ëª¨ë¸ ì‹œë„
    if _model_available:
        model_start_time = datetime.now()
        try:
            logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹œë„")

            # ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ë¡œ ì¶”ì²œ
            top_10 = predict_with_emotion_cluster_model(request_dict)
            method_used = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"

            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.info(f"âœ… AI ëª¨ë¸ ì¶”ì²œ ì„±ê³µ (ë°©ë²•: {method_used}, ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ)")

        except Exception as e:
            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.warning(f"âš ï¸ AI ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ): {e}")
            logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ ì „í™˜")

            rule_start_time = datetime.now()
            rule_results = rule_based_recommendation(request_dict, 10)
            top_10 = pd.DataFrame(rule_results)
            rule_time = (datetime.now() - rule_start_time).total_seconds()
            method_used = "ë£° ê¸°ë°˜ (AI ëª¨ë¸ ì‹¤íŒ¨)"
            logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")
    else:
        logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì‚¬ìš© (ëª¨ë¸ íŒŒì¼ ì—†ìŒ)")
        rule_start_time = datetime.now()
        rule_results = rule_based_recommendation(request_dict, 10)
        top_10 = pd.DataFrame(rule_results)
        rule_time = (datetime.now() - rule_start_time).total_seconds()
        method_used = "ë£° ê¸°ë°˜ (ëª¨ë¸ ì—†ìŒ)"
        logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")

    # 2) ê²°ê³¼ ê°€ê³µ
    response_list: List[PerfumeRecommendItem] = []
    for idx, (_, row) in enumerate(top_10.iterrows(), 1):
        emotions_text = get_emotion_text(row)
        score = float(row.get('score', 0.0))

        # ì¶”ì²œ ì´ìœ  ìƒì„±
        reason = get_recommendation_reason(score, method_used)

        response_list.append(
            PerfumeRecommendItem(
                name=str(row["name"]),
                brand=str(row["brand"]),
                image_url=str(row["image_url"]),
                notes=str(row["notes"]),
                emotions=emotions_text,
                reason=reason,
                score=score,
                method=method_used
            )
        )

    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    total_processing_time = (datetime.now() - request_start_time).total_seconds()

    logger.info(f"âœ… í–¥ìˆ˜ ì¶”ì²œ ì™„ë£Œ: {len(response_list)}ê°œ ({method_used})")
    logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.3f}ì´ˆ")
    if response_list:
        logger.info(
            f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {min(item.score for item in response_list):.3f} ~ {max(item.score for item in response_list):.3f}")
        logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {sum(item.score for item in response_list) / len(response_list):.3f}")

    return response_list


@router.get(
    "/model-status",
    summary="ëª¨ë¸ ìƒíƒœ í™•ì¸",
    description="AI ëª¨ë¸ê³¼ ê´€ë ¨ íŒŒì¼ë“¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def get_model_status():
    """ëª¨ë¸ ë° ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    model_info = get_file_info(MODEL_PATH)
    encoder_info = get_file_info(ENCODER_PATH)

    # í™˜ê²½ë³€ìˆ˜ í™•ì¸
    env_info = {
        "model_download_url": "ì„¤ì •ë¨" if os.getenv('MODEL_DOWNLOAD_URL') else "ì—†ìŒ",
        "encoder_download_url": "ì„¤ì •ë¨" if os.getenv('ENCODER_DOWNLOAD_URL') else "ì—†ìŒ",
        "render_env": "ì„¤ì •ë¨" if os.getenv('RENDER') else "ì—†ìŒ",
        "port": os.getenv('PORT', 'ê¸°ë³¸ê°’'),
    }

    # ì‹œìŠ¤í…œ ì •ë³´
    system_info = {
        "python_version": sys.version,
        "current_directory": os.getcwd(),
        "router_location": BASE_DIR,
        "dataset_loaded": len(df) > 0,
        "dataset_size": len(df)
    }

    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ (ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš°)
    model_structure = None
    if _model is not None:
        try:
            model_structure = {
                "input_shape": str(_model.input_shape),
                "output_shape": str(_model.output_shape),
                "total_params": _model.count_params(),
                "layers": len(_model.layers)
            }
        except:
            model_structure = "ëª¨ë¸ ì •ë³´ ì½ê¸° ì‹¤íŒ¨"

    return {
        "timestamp": datetime.now().isoformat(),
        "model_available": _model_available,
        "download_attempted": _model_download_attempted,
        "files": {
            "keras_model": {
                "path": MODEL_PATH,
                "absolute_path": os.path.abspath(MODEL_PATH),
                **model_info
            },
            "encoder": {
                "path": ENCODER_PATH,
                "absolute_path": os.path.abspath(ENCODER_PATH),
                **encoder_info
            }
        },
        "model_structure": model_structure,
        "emotion_clusters": EMOTION_CLUSTER_MAP,
        "recommendation_method": "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸" if _model_available else "ë£° ê¸°ë°˜",
        "fallback_encoder_ready": _fallback_encoder is not None,
        "environment_variables": env_info,
        "system": system_info,
        "dataset_info": {
            "total_perfumes": len(df),
            "columns": list(df.columns),
            "sample_brands": df['brand'].unique()[:5].tolist() if 'brand' in df.columns else [],
            "emotion_cluster_distribution": dict(
                df['emotion_cluster'].value_counts()) if 'emotion_cluster' in df.columns else None
        }
    }


@router.get(
    "/debug/filesystem",
    summary="íŒŒì¼ ì‹œìŠ¤í…œ ë””ë²„ê·¸ (ê°œë°œìš©)",
    description="ì„œë²„ì˜ íŒŒì¼ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ìƒì„¸íˆ í™•ì¸í•©ë‹ˆë‹¤."
)
def debug_filesystem():
    """ì„œë²„ì˜ íŒŒì¼ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë””ë²„ê·¸í•©ë‹ˆë‹¤."""

    debug_info = {
        "timestamp": datetime.now().isoformat(),
        "current_directory": os.getcwd(),
        "router_file_location": BASE_DIR,
        "model_paths": {
            "model_relative": MODEL_PATH,
            "encoder_relative": ENCODER_PATH,
            "model_absolute": os.path.abspath(MODEL_PATH),
            "encoder_absolute": os.path.abspath(ENCODER_PATH)
        }
    }

    # íŒŒì¼ ì¡´ì¬ ë° ìƒì„¸ ì •ë³´
    debug_info["files_detailed"] = {
        "model": get_file_info(MODEL_PATH),
        "encoder": get_file_info(ENCODER_PATH)
    }

    # models ë””ë ‰í† ë¦¬ ë‚´ìš©
    models_dir = os.path.dirname(MODEL_PATH)
    if os.path.exists(models_dir):
        debug_info["models_directory"] = {
            "path": models_dir,
            "exists": True,
            "contents": []
        }

        try:
            for item in os.listdir(models_dir):
                item_path = os.path.join(models_dir, item)
                item_info = {
                    "name": item,
                    "is_file": os.path.isfile(item_path),
                    "size": os.path.getsize(item_path) if os.path.isfile(item_path) else 0
                }

                # íŒŒì¼ ìƒì„¸ ì •ë³´
                if os.path.isfile(item_path):
                    item_info.update(get_file_info(item_path))

                debug_info["models_directory"]["contents"].append(item_info)
        except Exception as e:
            debug_info["models_directory"]["error"] = str(e)
    else:
        debug_info["models_directory"] = {
            "path": models_dir,
            "exists": False
        }

    # í”„ë¡œì íŠ¸ êµ¬ì¡° (ì œí•œì )
    project_root = os.path.abspath(os.path.join(BASE_DIR, ".."))
    debug_info["project_structure"] = {}

    try:
        for root, dirs, files in os.walk(project_root):
            level = root.replace(project_root, '').count(os.sep)
            if level < 2:  # 2ë ˆë²¨ê¹Œì§€ë§Œ
                rel_path = os.path.relpath(root, project_root)
                debug_info["project_structure"][rel_path] = {
                    "dirs": dirs[:10],
                    "files": [f for f in files if not f.startswith('.')][:15]
                }
    except Exception as e:
        debug_info["project_structure_error"] = str(e)

    # Git LFS ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
    try:
        lfs_info = subprocess.run(['git', 'lfs', 'ls-files'],
                                  capture_output=True, text=True, cwd=project_root)
        if lfs_info.returncode == 0:
            debug_info["git_lfs_files"] = lfs_info.stdout.strip().split('\n')
        else:
            debug_info["git_lfs_error"] = lfs_info.stderr
    except Exception as e:
        debug_info["git_lfs_not_available"] = str(e)

    # í™˜ê²½ë³€ìˆ˜
    debug_info["environment"] = {
        "RENDER": os.getenv("RENDER"),
        "PORT": os.getenv("PORT"),
        "PWD": os.getenv("PWD"),
        "HOME": os.getenv("HOME"),
        "PYTHON_VERSION": sys.version,
        "MODEL_DOWNLOAD_URL": "ì„¤ì •ë¨" if os.getenv('MODEL_DOWNLOAD_URL') else "ì—†ìŒ",
        "ENCODER_DOWNLOAD_URL": "ì„¤ì •ë¨" if os.getenv('ENCODER_DOWNLOAD_URL') else "ì—†ìŒ"
    }

    return debug_info


@router.post(
    "/debug/test-recommendation",
    summary="ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ê°œë°œìš©)",
    description="ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ ì¶”ì²œ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
)
def test_recommendation_system():
    """ì¶”ì²œ ì‹œìŠ¤í…œì„ ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""

    test_cases = [
        {
            "name": "ì—¬ì„±ìš© ë´„ ë°ì´ í–¥ìˆ˜",
            "request": {
                "gender": "women",
                "season": "spring",
                "time": "day",
                "impression": "fresh",
                "activity": "casual",
                "weather": "any"
            }
        },
        {
            "name": "ë‚¨ì„±ìš© ê²¨ìš¸ ë‚˜ì´íŠ¸ í–¥ìˆ˜",
            "request": {
                "gender": "men",
                "season": "winter",
                "time": "night",
                "impression": "confident",
                "activity": "date",
                "weather": "cold"
            }
        },
        {
            "name": "ìœ ë‹ˆì„¹ìŠ¤ ì—¬ë¦„ í–¥ìˆ˜",
            "request": {
                "gender": "unisex",
                "season": "summer",
                "time": "day",
                "impression": "mysterious",
                "activity": "work",
                "weather": "hot"
            }
        }
    ]

    results = []

    for test_case in test_cases:
        try:
            start_time = datetime.now()

            # AI ëª¨ë¸ ë˜ëŠ” ë£° ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
            if _model_available:
                try:
                    ai_results = predict_with_emotion_cluster_model(test_case["request"])
                    result_data = ai_results.to_dict('records')[:3]
                    method = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"
                except:
                    rule_results = rule_based_recommendation(test_case["request"], 5)
                    result_data = rule_results[:3]
                    method = "ë£° ê¸°ë°˜ (AI ì‹¤íŒ¨)"
            else:
                rule_results = rule_based_recommendation(test_case["request"], 5)
                result_data = rule_results[:3]
                method = "ë£° ê¸°ë°˜ (ëª¨ë¸ ì—†ìŒ)"

            processing_time = (datetime.now() - start_time).total_seconds()

            results.append({
                "test_name": test_case["name"],
                "request": test_case["request"],
                "success": True,
                "method": method,
                "result_count": len(result_data),
                "processing_time_seconds": processing_time,
                "sample_results": [
                    {
                        "name": r.get("name", ""),
                        "brand": r.get("brand", ""),
                        "score": r.get("score", 0)
                    } for r in result_data
                ]
            })

        except Exception as e:
            results.append({
                "test_name": test_case["name"],
                "request": test_case["request"],
                "success": False,
                "error": str(e),
                "processing_time_seconds": 0
            })

    return {
        "timestamp": datetime.now().isoformat(),
        "model_available": _model_available,
        "fallback_encoder_available": _fallback_encoder is not None,
        "dataset_size": len(df),
        "emotion_clusters": EMOTION_CLUSTER_MAP,
        "test_results": results,
        "summary": {
            "total_tests": len(test_cases),
            "successful_tests": sum(1 for r in results if r["success"]),
            "average_processing_time": sum(r.get("processing_time_seconds", 0) for r in results) / len(results)
        }
    }


@router.get(
    "/health",
    summary="ì¶”ì²œ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬",
    description="ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def health_check():
    """ì¶”ì²œ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""

    health_status = {
        "timestamp": datetime.now().isoformat(),
        "status": "healthy",
        "checks": {}
    }

    # ë°ì´í„°ì…‹ í™•ì¸
    try:
        health_status["checks"]["dataset"] = {
            "status": "ok" if len(df) > 0 else "error",
            "perfume_count": len(df),
            "columns_available": len(df.columns)
        }
    except Exception as e:
        health_status["checks"]["dataset"] = {
            "status": "error",
            "error": str(e)
        }

    # ëª¨ë¸ íŒŒì¼ í™•ì¸
    try:
        model_exists = os.path.exists(MODEL_PATH) and not is_git_lfs_pointer_file(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH) and not is_git_lfs_pointer_file(ENCODER_PATH)

        health_status["checks"]["model_files"] = {
            "status": "ok" if model_exists and encoder_exists else "warning",
            "model_available": model_exists,
            "encoder_available": encoder_exists,
            "fallback_ready": _fallback_encoder is not None
        }
    except Exception as e:
        health_status["checks"]["model_files"] = {
            "status": "error",
            "error": str(e)
        }

    # ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    try:
        test_request = {
            "gender": "women",
            "season": "spring",
            "time": "day",
            "impression": "fresh",
            "activity": "casual",
            "weather": "any"
        }

        start_time = datetime.now()
        if _model_available:
            try:
                test_results = predict_with_emotion_cluster_model(test_request)
                method = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"
            except:
                rule_results = rule_based_recommendation(test_request, 3)
                test_results = pd.DataFrame(rule_results)
                method = "ë£° ê¸°ë°˜ (AI ì‹¤íŒ¨)"
        else:
            rule_results = rule_based_recommendation(test_request, 3)
            test_results = pd.DataFrame(rule_results)
            method = "ë£° ê¸°ë°˜ (ëª¨ë¸ ì—†ìŒ)"

        processing_time = (datetime.now() - start_time).total_seconds()

        health_status["checks"]["recommendation_system"] = {
            "status": "ok" if len(test_results) > 0 else "error",
            "test_result_count": len(test_results),
            "processing_time_seconds": processing_time,
            "method": method
        }
    except Exception as e:
        health_status["checks"]["recommendation_system"] = {
            "status": "error",
            "error": str(e)
        }

    # ì „ì²´ ìƒíƒœ ê²°ì •
    all_checks = health_status["checks"].values()
    if any(check.get("status") == "error" for check in all_checks):
        health_status["status"] = "unhealthy"
    elif any(check.get("status") == "warning" for check in all_checks):
        health_status["status"] = "degraded"

    return health_status