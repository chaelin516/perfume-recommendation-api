import os
import pickle
import logging
import random
import sys
import numpy as np
from datetime import datetime
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Literal, Optional, Dict, Any
import pandas as pd
from sklearn.preprocessing import OneHotEncoder

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recommend_router")

# â”€â”€â”€ 1. perfume_final_dataset.csv ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/perfume_final_dataset.csv")
try:
    df = pd.read_csv(DATA_PATH)
    df.fillna("", inplace=True)
    logger.info(f"âœ… Perfume dataset loaded: {df.shape[0]} rows")
    logger.info(f"ğŸ“‹ Available columns: {list(df.columns)}")

    # âœ… ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    required_columns = ['name', 'brand', 'image_url', 'notes']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        logger.error(f"âŒ Missing required columns: {missing_columns}")
        raise RuntimeError(f"Missing required columns: {missing_columns}")

    # âœ… emotion ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
    if 'desired_impression' in df.columns:
        logger.info("âœ… Using 'desired_impression' column for emotion data")
    if 'emotion_cluster' in df.columns:
        logger.info("âœ… Using 'emotion_cluster' column for cluster data")
        # emotion_cluster ì»¬ëŸ¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        df['emotion_cluster'] = pd.to_numeric(df['emotion_cluster'], errors='coerce').fillna(0).astype(int)
        logger.info(f"ğŸ“Š Emotion clusters: {sorted(df['emotion_cluster'].unique())}")
    else:
        logger.warning("âš ï¸ No emotion_cluster column found")

    # ğŸ“Š ë°ì´í„° ìƒ˜í”Œ ë¡œê·¸
    if len(df) > 0:
        sample_row = df.iloc[0]
        logger.info(f"ğŸ“ Sample data: {sample_row['name']} by {sample_row['brand']}")

except Exception as e:
    logger.error(f"âŒ perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    raise RuntimeError(f"perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# â”€â”€â”€ 2. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "../models/final_model.keras")
ENCODER_PATH = os.path.join(BASE_DIR, "../models/encoder.pkl")

# â”€â”€â”€ 3. ì „ì—­ ë³€ìˆ˜ ë° ìƒíƒœ ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_model = None
_encoder = None
_model_available = False
_fallback_encoder = None

# â”€â”€â”€ 4. ê°ì • í´ëŸ¬ìŠ¤í„° ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_CLUSTER_MAP = {
    0: "ì°¨ë¶„í•œ, í¸ì•ˆí•œ",
    1: "ìì‹ ê°, ì‹ ì„ í•¨",
    2: "ìš°ì•„í•¨, ì¹œê·¼í•¨",
    3: "ìˆœìˆ˜í•¨, ì¹œê·¼í•¨",
    4: "ì‹ ë¹„ë¡œìš´, ë§¤ë ¥ì ",
    5: "í™œê¸°ì°¬, ì—ë„ˆì§€"
}


# â”€â”€â”€ 5. ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ (31KB ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_model_availability():
    """ëª¨ë¸ íŒŒì¼ë“¤ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    global _model_available

    logger.info("ğŸ” ëª¨ë¸ íŒŒì¼ ê°€ìš©ì„± í™•ì¸ ì¤‘...")

    try:
        # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
        model_exists = os.path.exists(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH)

        model_valid = False
        encoder_valid = False

        if model_exists:
            model_size = os.path.getsize(MODEL_PATH)
            # âœ… ì‹¤ì œ ëª¨ë¸ íŒŒì¼ í¬ê¸°ì— ë§ê²Œ ìˆ˜ì •: 31KB ëª¨ë¸ì´ë¯€ë¡œ 10KB ì´ìƒìœ¼ë¡œ ì²´í¬
            model_valid = model_size > 10000  # 10KB ì´ìƒ (ê¸°ì¡´: 100KB)
            logger.info(f"ğŸ“„ ëª¨ë¸ íŒŒì¼: {model_size:,}B ({model_size / 1024:.1f}KB) {'âœ…' if model_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")

        if encoder_exists:
            encoder_size = os.path.getsize(ENCODER_PATH)
            # âœ… ì¸ì½”ë”ëŠ” 1KBì´ë¯€ë¡œ 500B ì´ìƒìœ¼ë¡œ ì²´í¬ (ê¸°ì¡´: 100B)
            encoder_valid = encoder_size > 500  # 500B ì´ìƒ
            logger.info(f"ğŸ“„ ì¸ì½”ë” íŒŒì¼: {encoder_size:,}B ({encoder_size}B) {'âœ…' if encoder_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")

        _model_available = model_valid and encoder_valid

        logger.info(f"ğŸ¤– ëª¨ë¸ ê°€ìš©ì„±: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if _model_available else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")

        if _model_available:
            logger.info(f"âœ¨ ëª¨ë¸ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ - í¬ê¸°: {model_size / 1024:.1f}KB")
        else:
            if not model_valid:
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ í¬ê¸° ë¶€ì¡±: {model_size}B (ìµœì†Œ 10KB í•„ìš”)")
            if not encoder_valid:
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ í¬ê¸° ë¶€ì¡±: {encoder_size}B (ìµœì†Œ 500B í•„ìš”)")

        return _model_available

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        _model_available = False
        return False


# â”€â”€â”€ 6. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤ (Keras 3.8.0 í˜¸í™˜ ë° í¬ê¸° ì²´í¬ ìˆ˜ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_model():
    """Keras ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model

    if _model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
                return None

            # âœ… íŒŒì¼ í¬ê¸° í™•ì¸ - 31KB ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •
            model_size = os.path.getsize(MODEL_PATH)
            if model_size < 10000:  # 10KB ë¯¸ë§Œ (ê¸°ì¡´: 100KB)
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {model_size} bytes ({model_size / 1024:.1f}KB)")
                return None

            logger.info(f"ğŸ“¦ ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸ ì™„ë£Œ: {model_size:,}B ({model_size / 1024:.1f}KB)")

            # TensorFlow ë™ì  ì„í¬íŠ¸ ë° Keras 3.x í˜¸í™˜ì„± ê³ ë ¤
            try:
                tf_start = datetime.now()

                # âœ… Keras 3.x ì§€ì›ì„ ìœ„í•œ ì„í¬íŠ¸ ë°©ì‹ ê°œì„ 
                try:
                    # Keras 3.x ë°©ì‹ ì‹œë„
                    import tensorflow as tf
                    from tensorflow import keras
                    load_model = keras.models.load_model
                    logger.info(f"ğŸ“¦ TensorFlow {tf.__version__} + Keras 3.x ìŠ¤íƒ€ì¼ ë¡œë”©")
                except:
                    # ê¸°ì¡´ ë°©ì‹ í´ë°±
                    from tensorflow.keras.models import load_model
                    logger.info(f"ğŸ“¦ TensorFlow ê¸°ì¡´ ìŠ¤íƒ€ì¼ ë¡œë”©")

                tf_load_time = (datetime.now() - tf_start).total_seconds()

                logger.info(f"ğŸ“¦ Keras ëª¨ë¸ ë¡œë”© ì‹œë„ (TF ë¡œë”©: {tf_load_time:.3f}ì´ˆ)")
                logger.info(f"ğŸ“Š ì˜ˆìƒ ëª¨ë¸ êµ¬ì¡°: ì…ë ¥(6) â†’ Dense(64,relu) â†’ Dense(6,softmax)")

                model_start = datetime.now()

                # âœ… compile=Falseë¡œ ë¹ ë¥¸ ë¡œë”©, Keras 3.x í˜¸í™˜
                _model = load_model(MODEL_PATH, compile=False)
                model_load_time = (datetime.now() - model_start).total_seconds()

                # âœ… ëª¨ë¸ êµ¬ì¡° ê²€ì¦
                logger.info(f"âœ… Keras ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ëª¨ë¸ ë¡œë”©: {model_load_time:.3f}ì´ˆ)")
                logger.info(f"ğŸ“Š ì‹¤ì œ ëª¨ë¸ ì…ë ¥ shape: {_model.input_shape}")
                logger.info(f"ğŸ“Š ì‹¤ì œ ëª¨ë¸ ì¶œë ¥ shape: {_model.output_shape}")

                # âœ… ë ˆì´ì–´ ì •ë³´ ì¶œë ¥
                logger.info(f"ğŸ“Š ëª¨ë¸ ë ˆì´ì–´ ìˆ˜: {len(_model.layers)}")
                for i, layer in enumerate(_model.layers):
                    layer_info = f"  Layer {i + 1}: {layer.__class__.__name__}"
                    if hasattr(layer, 'units'):
                        layer_info += f" (units: {layer.units})"
                    if hasattr(layer, 'activation'):
                        layer_info += f" (activation: {layer.activation.__name__})"
                    logger.info(layer_info)

                # âœ… ì¶œë ¥ í¬ê¸° ê²€ì¦ (6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„°)
                output_size = _model.output_shape[-1]
                if output_size == 6:
                    logger.info("ğŸ¯ 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ ëª¨ë¸ë¡œ í™•ì¸ë¨")
                else:
                    logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì¶œë ¥ í¬ê¸°: {output_size} (ì˜ˆìƒ: 6)")

                # âœ… ì…ë ¥ í¬ê¸° ê²€ì¦ (6ê°œ íŠ¹ì„±)
                input_size = _model.input_shape[-1]
                if input_size == 6:
                    logger.info("ğŸ¯ 6ê°œ ì…ë ¥ íŠ¹ì„± ëª¨ë¸ë¡œ í™•ì¸ë¨")
                else:
                    logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì…ë ¥ í¬ê¸°: {input_size} (ì˜ˆìƒ: 6)")

                # âœ… ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¶”ë¡  (ëª¨ë¸ ë™ì‘ í™•ì¸)
                try:
                    test_input = np.random.random((1, 6)).astype(np.float32)
                    test_output = _model.predict(test_input, verbose=0)
                    logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì„±ê³µ: ì…ë ¥{test_input.shape} â†’ ì¶œë ¥{test_output.shape}")
                    logger.info(f"ğŸ§ª ì¶œë ¥ í•©ê³„: {test_output.sum():.3f} (softmaxì´ë©´ ~1.0)")

                    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° í™•ì¸
                    predicted_cluster = int(np.argmax(test_output[0]))
                    confidence = float(test_output[0][predicted_cluster])
                    logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡: í´ëŸ¬ìŠ¤í„° {predicted_cluster} (ì‹ ë¢°ë„: {confidence:.3f})")
                except Exception as test_e:
                    logger.warning(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹¤íŒ¨: {test_e}")

            except ImportError as e:
                logger.error(f"âŒ TensorFlowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return None
            except Exception as e:
                logger.error(f"âŒ Keras ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                logger.error(f"  íŒŒì¼ ê²½ë¡œ: {MODEL_PATH}")
                logger.error(f"  íŒŒì¼ í¬ê¸°: {model_size}B")
                return None

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜ˆì™¸: {e}")
            return None

    return _model


def get_saved_encoder():
    """ì €ì¥ëœ encoder.pklì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _encoder

    if _encoder is None:
        try:
            if not os.path.exists(ENCODER_PATH):
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")
                return None

            encoder_size = os.path.getsize(ENCODER_PATH)
            logger.info(f"ğŸ“¦ ì¸ì½”ë” ë¡œë”© ì‹œë„: {ENCODER_PATH} ({encoder_size}B)")

            with open(ENCODER_PATH, "rb") as f:
                _encoder = pickle.load(f)
            logger.info("âœ… encoder.pkl ë¡œë“œ ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ encoder.pkl ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    return _encoder


def get_fallback_encoder():
    """Fallback OneHotEncoderë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global _fallback_encoder

    if _fallback_encoder is None:
        try:
            logger.info("ğŸ”§ Fallback OneHotEncoder ìƒì„± ì¤‘...")

            CATEGORIES = [
                ["women", "men", "unisex"],  # gender
                ["spring", "summer", "fall", "winter"],  # season_tags
                ["day", "night"],  # time_tags
                ["confident", "elegant", "pure", "friendly", "mysterious", "fresh"],  # desired_impression
                ["casual", "work", "date"],  # activity
                ["hot", "cold", "rainy", "any"]  # weather
            ]

            _fallback_encoder = OneHotEncoder(
                categories=CATEGORIES,
                handle_unknown="ignore",
                sparse=False
            )

            # ë”ë¯¸ ë°ì´í„°ë¡œ fit
            dummy_data = [
                ["women", "spring", "day", "confident", "casual", "hot"],
                ["men", "summer", "night", "elegant", "work", "cold"],
                ["unisex", "fall", "day", "pure", "date", "rainy"],
                ["women", "winter", "night", "friendly", "casual", "any"],
                ["men", "spring", "day", "mysterious", "work", "hot"],
                ["unisex", "summer", "night", "fresh", "date", "cold"]
            ]

            _fallback_encoder.fit(dummy_data)
            logger.info("âœ… Fallback OneHotEncoder ìƒì„± ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ Fallback encoder ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    return _fallback_encoder


# â”€â”€â”€ 7. AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_with_emotion_cluster_model(request_dict: dict) -> pd.DataFrame:
    """ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ì‚¬ìš©í•œ AI ì¶”ì²œ"""

    try:
        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # ì¸ì½”ë”ë¡œ ì…ë ¥ ë°ì´í„° ë³€í™˜
        raw_features = [
            request_dict["gender"],
            request_dict["season_tags"],
            request_dict["time_tags"],
            request_dict["desired_impression"],
            request_dict["activity"],
            request_dict["weather"]
        ]

        logger.info(f"ğŸ”® AI ëª¨ë¸ ì…ë ¥ ë°ì´í„°: {raw_features}")

        # ì¸ì½”ë” ì‚¬ìš©
        encoder = get_saved_encoder()
        if encoder:
            try:
                x_input = encoder.transform([raw_features])
                encoder_method = "ì €ì¥ëœ ì¸ì½”ë”"
            except Exception as e:
                logger.warning(f"âš ï¸ encoder.pkl ì‹¤íŒ¨ ({e}), fallback encoder ì‚¬ìš©")
                fallback_encoder = get_fallback_encoder()
                if fallback_encoder:
                    x_input = fallback_encoder.transform([raw_features])
                    encoder_method = "Fallback ì¸ì½”ë”"
                else:
                    raise Exception("Fallback encoder ìƒì„± ì‹¤íŒ¨")
        else:
            fallback_encoder = get_fallback_encoder()
            if fallback_encoder:
                x_input = fallback_encoder.transform([raw_features])
                encoder_method = "Fallback ì¸ì½”ë”"
            else:
                raise Exception("Fallback encoder ìƒì„± ì‹¤íŒ¨")

        logger.info(f"ğŸ”® ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì‹œì‘ (ì…ë ¥ shape: {x_input.shape}, ì¸ì½”ë”: {encoder_method})")

        # ëª¨ë¸ ì˜ˆì¸¡ (ê°ì • í´ëŸ¬ìŠ¤í„°)
        preds = model.predict(x_input, verbose=0)  # (1, 6) ì¶œë ¥
        cluster_probabilities = preds[0]  # [0.1, 0.8, 0.05, 0.02, 0.02, 0.01]
        predicted_cluster = int(np.argmax(cluster_probabilities))  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„°
        confidence = float(cluster_probabilities[predicted_cluster])

        cluster_name = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")
        logger.info(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°: {predicted_cluster} ({cluster_name}) - ì‹ ë¢°ë„: {confidence:.3f}")

        # ëª¨ë“  í´ëŸ¬ìŠ¤í„° í™•ë¥  ë¡œê·¸
        for i, prob in enumerate(cluster_probabilities):
            cluster_desc = EMOTION_CLUSTER_MAP.get(i, f"í´ëŸ¬ìŠ¤í„° {i}")
            logger.info(f"  í´ëŸ¬ìŠ¤í„° {i} ({cluster_desc}): {prob:.3f}")

        # ê°ì • í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
            logger.info(f"ğŸ“‹ í´ëŸ¬ìŠ¤í„° {predicted_cluster} í–¥ìˆ˜ ê°œìˆ˜: {len(cluster_perfumes)}ê°œ")
        else:
            logger.warning("âš ï¸ emotion_cluster ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ë°ì´í„° ì‚¬ìš©")
            cluster_perfumes = df.copy()

        # í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
        if cluster_perfumes.empty:
            logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {predicted_cluster}ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìŒ")
            # ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
            second_best = int(np.argsort(cluster_probabilities)[-2])
            cluster_perfumes = df[df['emotion_cluster'] == second_best].copy()
            predicted_cluster = second_best
            confidence = float(cluster_probabilities[second_best])
            logger.info(f"ğŸ“‹ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° {second_best} ì‚¬ìš©: {len(cluster_perfumes)}ê°œ")

        # ì¶”ê°€ í•„í„°ë§ (ì„±ë³„, ê³„ì ˆ ë“±)
        original_count = len(cluster_perfumes)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == request_dict["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered
                logger.info(f"  ì„±ë³„ '{request_dict['gender']}' í•„í„°ë§: {original_count} â†’ {len(cluster_perfumes)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    request_dict["season_tags"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered
                logger.info(f"  ê³„ì ˆ '{request_dict['season_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in cluster_perfumes.columns:
            time_filtered = cluster_perfumes[
                cluster_perfumes['time_tags'].str.contains(
                    request_dict["time_tags"], na=False, case=False
                )
            ]
            if not time_filtered.empty:
                cluster_perfumes = time_filtered
                logger.info(f"  ì‹œê°„ '{request_dict['time_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # AI ì‹ ë¢°ë„ ê¸°ë°˜ ì ìˆ˜ í• ë‹¹
        cluster_perfumes = cluster_perfumes.copy()

        # í´ëŸ¬ìŠ¤í„° ì‹ ë¢°ë„ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ ì‚¬ìš©
        base_score = confidence * 0.8  # AI ì‹ ë¢°ë„ì˜ 80%ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ

        scores = []
        for idx, (_, row) in enumerate(cluster_perfumes.iterrows()):
            score = base_score

            # ì¶”ê°€ ì¡°ê±´ ì¼ì¹˜ ë³´ë„ˆìŠ¤
            if 'season_tags' in row and request_dict["season_tags"].lower() in str(row['season_tags']).lower():
                score += 0.08
            if 'time_tags' in row and request_dict["time_tags"].lower() in str(row['time_tags']).lower():
                score += 0.06
            if 'desired_impression' in row and request_dict["desired_impression"].lower() in str(
                    row['desired_impression']).lower():
                score += 0.05

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']
            if any(popular in str(row.get('brand', '')) for popular in popular_brands):
                score += 0.03

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜ (ì•ìª½ì¼ìˆ˜ë¡ ì•½ê°„ ë†’ì€ ì ìˆ˜)
            position_bonus = (len(cluster_perfumes) - idx) / len(cluster_perfumes) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.03, 0.05)

            # ì •ê·œí™” (0.4 ~ 0.95 ë²”ìœ„)
            score = max(0.4, min(0.95, score))
            scores.append(score)

        cluster_perfumes['score'] = scores

        # ìƒìœ„ 10ê°œ ì„ íƒ
        top_10 = cluster_perfumes.nlargest(10, 'score')

        logger.info(f"âœ… AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì™„ë£Œ: {len(top_10)}ê°œ")
        if not top_10.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_10['score'].min():.3f} ~ {top_10['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_10['score'].mean():.3f}")

        return top_10

    except Exception as e:
        logger.error(f"âŒ AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 8. ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def rule_based_recommendation(request_data: dict, top_k: int = 10) -> List[dict]:
    """ë£° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ (AI ëª¨ë¸ ëŒ€ì²´)"""
    logger.info("ğŸ¯ ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘")

    try:
        # í•„í„°ë§ ì¡°ê±´
        gender = request_data["gender"]
        season_tags = request_data["season_tags"]
        time_tags = request_data["time_tags"]
        desired_impression = request_data["desired_impression"]
        activity = request_data["activity"]
        weather = request_data["weather"]

        logger.info(f"ğŸ” í•„í„°ë§ ì¡°ê±´: gender={gender}, season_tags={season_tags}, time_tags={time_tags}, "
                    f"desired_impression={desired_impression}, activity={activity}, weather={weather}")

        # ì„±ë³„ ë§¤í•‘
        gender_map = {"women": "women", "men": "men", "unisex": "unisex"}
        mapped_gender = gender_map.get(gender, "unisex")

        # 1ë‹¨ê³„: ê¸°ë³¸ í•„í„°ë§
        candidates = df.copy()
        original_count = len(candidates)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in df.columns:
            gender_filtered = candidates[candidates['gender'] == mapped_gender]
            if not gender_filtered.empty:
                candidates = gender_filtered
                logger.info(f"  ì„±ë³„ '{mapped_gender}' í•„í„°ë§: {original_count} â†’ {len(candidates)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in df.columns:
            season_filtered = candidates[
                candidates['season_tags'].str.contains(season_tags, na=False, case=False)
            ]
            if not season_filtered.empty:
                candidates = season_filtered
                logger.info(f"  ê³„ì ˆ '{season_tags}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in df.columns:
            time_filtered = candidates[
                candidates['time_tags'].str.contains(time_tags, na=False, case=False)
            ]
            if not time_filtered.empty:
                candidates = time_filtered
                logger.info(f"  ì‹œê°„ '{time_tags}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì¸ìƒ í•„í„°ë§
        if 'desired_impression' in df.columns:
            impression_filtered = candidates[
                candidates['desired_impression'].str.contains(desired_impression, na=False, case=False)
            ]
            if not impression_filtered.empty:
                candidates = impression_filtered
                logger.info(f"  ì¸ìƒ '{desired_impression}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # í™œë™ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'activity' in df.columns:
            activity_filtered = candidates[
                candidates['activity'].str.contains(activity, na=False, case=False)
            ]
            if not activity_filtered.empty:
                candidates = activity_filtered
                logger.info(f"  í™œë™ '{activity}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ë‚ ì”¨ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'weather' in df.columns and weather != 'any':
            weather_filtered = candidates[
                candidates['weather'].str.contains(weather, na=False, case=False)
            ]
            if not weather_filtered.empty:
                candidates = weather_filtered
                logger.info(f"  ë‚ ì”¨ '{weather}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # 2ë‹¨ê³„: ìŠ¤ì½”ì–´ë§
        if candidates.empty:
            logger.warning("âš ï¸ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ì—ì„œ ë‹¤ì–‘ì„± ê¸°ë°˜ ì„ íƒ")
            # ë‹¤ì–‘í•œ ë¸Œëœë“œì—ì„œ ê³ ë¥´ê²Œ ì„ íƒ
            if 'brand' in df.columns:
                unique_brands = df['brand'].unique()
                candidates_list = []
                per_brand = max(1, top_k // len(unique_brands))

                for brand in unique_brands:
                    brand_perfumes = df[df['brand'] == brand].sample(
                        n=min(per_brand, len(df[df['brand'] == brand])),
                        random_state=42
                    )
                    candidates_list.append(brand_perfumes)

                candidates = pd.concat(candidates_list).head(top_k)
            else:
                candidates = df.sample(n=min(top_k, len(df)), random_state=42)

        # ì ìˆ˜ ê³„ì‚°
        candidates = candidates.copy()
        scores = []

        # ë¸Œëœë“œë³„ ê°€ì¤‘ì¹˜ (ì¸ê¸° ë¸Œëœë“œ ì˜ˆì‹œ)
        popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']

        for idx, (_, row) in enumerate(candidates.iterrows()):
            score = 0.3  # ê¸°ë³¸ ì ìˆ˜

            # 1. ì¡°ê±´ ì¼ì¹˜ë„ ì ìˆ˜
            brand_name = str(row.get('brand', ''))
            notes_text = str(row.get('notes', ''))

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            if any(popular in brand_name for popular in popular_brands):
                score += 0.15

            # ë…¸íŠ¸ ë³µì¡ì„± (ë” ë§ì€ ë…¸íŠ¸ = ë” ë³µì¡í•œ í–¥ìˆ˜)
            note_count = len([n.strip() for n in notes_text.split(',') if n.strip()])
            if note_count >= 8:
                score += 0.10
            elif note_count >= 5:
                score += 0.05

            # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì •í™•ë„
            impression_match_count = 0
            if 'desired_impression' in row:
                impressions = str(row['desired_impression']).lower().split(',')
                impression_match_count = sum(1 for imp in impressions if desired_impression.lower() in imp.strip())
                score += impression_match_count * 0.08

            # ê³„ì ˆ/ì‹œê°„ ë§¤ì¹­ ì •í™•ë„
            if 'season_tags' in row:
                season_tags_data = str(row['season_tags']).lower()
                if season_tags.lower() in season_tags_data:
                    score += 0.12 if f' {season_tags.lower()} ' in f' {season_tags_data} ' else 0.08

            if 'time_tags' in row:
                time_tags_data = str(row['time_tags']).lower()
                if time_tags.lower() in time_tags_data:
                    score += 0.12 if f' {time_tags.lower()} ' in f' {time_tags_data} ' else 0.08

            # í™œë™ ë§¤ì¹­
            if 'activity' in row and activity.lower() in str(row['activity']).lower():
                score += 0.08

            # ë‚ ì”¨ ë§¤ì¹­
            if 'weather' in row and weather != 'any':
                if weather.lower() in str(row['weather']).lower():
                    score += 0.06
            elif weather == 'any':
                score += 0.03

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜
            position_bonus = (len(candidates) - idx) / len(candidates) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.15, 0.15)

            # ì ìˆ˜ ì •ê·œí™” (0.2 ~ 0.95 ë²”ìœ„)
            score = max(0.2, min(0.95, score))
            scores.append(score)

        candidates['score'] = scores

        # ìƒìœ„ Kê°œ ì„ íƒ
        top_candidates = candidates.nlargest(top_k, 'score')

        logger.info(f"âœ… ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ: ìµœì¢… {len(top_candidates)}ê°œ ì„ íƒ")
        if not top_candidates.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_candidates['score'].min():.3f} ~ {top_candidates['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_candidates['score'].mean():.3f}")

        return top_candidates.to_dict('records')

    except Exception as e:
        logger.error(f"âŒ ë£° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {e}")
        # ìµœì¢… ì•ˆì „ì¥ì¹˜: ì™„ì „ ëœë¤ ì¶”ì²œ
        logger.info("ğŸ² ì™„ì „ ëœë¤ ì¶”ì²œìœ¼ë¡œ ëŒ€ì²´")
        random_sample = df.sample(n=min(top_k, len(df)), random_state=42)
        random_sample = random_sample.copy()
        random_sample['score'] = [random.uniform(0.4, 0.7) for _ in range(len(random_sample))]
        return random_sample.to_dict('records')


# â”€â”€â”€ 9. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_emotion_text(row):
    """ê°ì • ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # 1ìˆœìœ„: desired_impression
    if 'desired_impression' in df.columns and pd.notna(row.get('desired_impression')):
        return str(row['desired_impression'])

    # 2ìˆœìœ„: emotion_clusterë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if 'emotion_cluster' in df.columns and pd.notna(row.get('emotion_cluster')):
        cluster_id = int(row['emotion_cluster']) if str(row['emotion_cluster']).isdigit() else 0
        return EMOTION_CLUSTER_MAP.get(cluster_id, "ê· í˜•ì¡íŒ")

    return "ë‹¤ì–‘í•œ ê°ì •"


def get_recommendation_reason(score: float, method: str) -> str:
    """ì ìˆ˜ì™€ ë°©ë²•ì— ë”°ë¥¸ ì¶”ì²œ ì´ìœ  ìƒì„±"""

    if method.startswith("AI"):
        if score >= 0.9:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì˜ ì™„ë²½í•œ í–¥ìˆ˜ë¼ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤!"
        elif score >= 0.8:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì—ê²Œ ì˜ ë§ì„ ê²ƒì´ë¼ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤."
        elif score >= 0.6:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒˆë¡œìš´ ì‹œë„í•´ë³¼ ë§Œí•œ í–¥ìˆ˜ë¡œ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤."
        else:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒ‰ë‹¤ë¥¸ ë§¤ë ¥ì„ ì œì•ˆí•©ë‹ˆë‹¤."
    else:
        # ë£° ê¸°ë°˜ - ë” ë‹¤ì–‘í•œ ë©”ì‹œì§€
        if score >= 0.9:
            return f"ğŸ¯ ì¡°ê±´ ì™„ë²½ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ì´ë³´ë‹¤ ì™„ë²½í•  ìˆœ ì—†ì–´ìš”!"
        elif score >= 0.8:
            return f"â­ ì¡°ê±´ ë†’ì€ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ê°•ë ¥ ì¶”ì²œ!"
        elif score >= 0.6:
            return f"âœ¨ ì¡°ê±´ ì í•© (ì¼ì¹˜ë„ {score:.1%}) - ê³ ë ¤í•´ë³´ì„¸ìš”!"
        elif score >= 0.4:
            return f"ğŸ” ë¶€ë¶„ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ìƒˆë¡œìš´ ë°œê²¬ì´ ë  ìˆ˜ë„!"
        else:
            return f"ğŸ² ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ì œì•ˆ (ì¼ì¹˜ë„ {score:.1%}) - ë„ì „í•´ë³´ì„¸ìš”!"


# â”€â”€â”€ 10. ìŠ¤í‚¤ë§ˆ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class RecommendRequest(BaseModel):
    gender: Literal["women", "men", "unisex"]
    season_tags: Literal["spring", "summer", "fall", "winter"]
    time_tags: Literal["day", "night"]
    desired_impression: Literal["confident", "elegant", "pure", "friendly", "mysterious", "fresh"]
    activity: Literal["casual", "work", "date"]
    weather: Literal["hot", "cold", "rainy", "any"]


class PerfumeRecommendItem(BaseModel):
    name: str
    brand: str
    image_url: str
    notes: str
    emotions: str
    reason: str
    score: Optional[float] = None
    method: Optional[str] = None


# â”€â”€â”€ 11. ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/perfumes", tags=["Perfume"])

# ì‹œì‘ ì‹œ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
logger.info("ğŸš€ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
check_model_availability()
if _model_available:
    logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
else:
    logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œ ë™ì‘")
logger.info("âœ… ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")


# â”€â”€â”€ 12. API ì—”ë“œí¬ì¸íŠ¸ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post(
    "/recommend",
    response_model=List[PerfumeRecommendItem],
    summary="í–¥ìˆ˜ ì¶”ì²œ (AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ + ë£° ê¸°ë°˜ Fallback)",
    description=(
            "ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n\n"
            "**ğŸ¤– ì¶”ì²œ ë°©ì‹:**\n"
            "1. **AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸**: 6ê°œ ì…ë ¥ â†’ 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ â†’ í•´ë‹¹ í´ëŸ¬ìŠ¤í„° í–¥ìˆ˜ ì¶”ì²œ\n"
            "2. **ë£° ê¸°ë°˜ Fallback**: ì¡°ê±´ë¶€ í•„í„°ë§ + ìŠ¤ì½”ì–´ë§ (ëª¨ë¸ì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°)\n"
            "3. **ë‹¤ì–‘ì„± ë³´ì¥**: ë¸Œëœë“œë³„ ê· í˜• ì¡íŒ ì¶”ì²œ\n\n"
            "**ğŸ“‹ ì…ë ¥ íŒŒë¼ë¯¸í„°:**\n"
            "- `gender`: ì„±ë³„ (women/men/unisex)\n"
            "- `season_tags`: ê³„ì ˆ (spring/summer/fall/winter)\n"
            "- `time_tags`: ì‹œê°„ëŒ€ (day/night)\n"
            "- `desired_impression`: ì›í•˜ëŠ” ì¸ìƒ (confident/elegant/pure/friendly/mysterious/fresh)\n"
            "- `activity`: í™œë™ (casual/work/date)\n"
            "- `weather`: ë‚ ì”¨ (hot/cold/rainy/any)\n\n"
            "**ğŸ§  AI ëª¨ë¸ ì„¸ë¶€ì‚¬í•­:**\n"
            "- ëª¨ë¸ êµ¬ì¡°: Sequential (Input 6 â†’ Dense 64 â†’ Dense 6)\n"
            "- ì¶œë ¥: 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° í™•ë¥  (softmax)\n"
            "- Keras ë²„ì „: 3.8.0\n"
            "- ëª¨ë¸ í¬ê¸°: ~31KB\n\n"
            "**âœ¨ íŠ¹ì§•:**\n"
            "- ì‹¤ì œ ëª¨ë¸ íŒŒì¼ í¬ê¸° ê¸°ë°˜ ìœ íš¨ì„± ê²€ì¦\n"
            "- ê²¬ê³ í•œ ì—ëŸ¬ í•¸ë“¤ë§\n"
            "- ìƒì„¸í•œ ì¶”ì²œ ì´ìœ  ì œê³µ"
    )
)
def recommend_perfumes(request: RecommendRequest):
    request_start_time = datetime.now()
    logger.info(f"ğŸ¯ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­ ì‹œì‘: {request}")

    # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    request_dict = request.dict()

    method_used = "ì•Œ ìˆ˜ ì—†ìŒ"

    # 1) AI ëª¨ë¸ ì‹œë„
    if _model_available:
        model_start_time = datetime.now()
        try:
            logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹œë„")

            # ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ë¡œ ì¶”ì²œ
            top_10 = predict_with_emotion_cluster_model(request_dict)
            method_used = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"

            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.info(f"âœ… AI ëª¨ë¸ ì¶”ì²œ ì„±ê³µ (ë°©ë²•: {method_used}, ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ)")

        except Exception as e:
            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.warning(f"âš ï¸ AI ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ): {e}")
            logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ ì „í™˜")

            rule_start_time = datetime.now()
            rule_results = rule_based_recommendation(request_dict, 10)
            top_10 = pd.DataFrame(rule_results)
            rule_time = (datetime.now() - rule_start_time).total_seconds()
            method_used = "ë£° ê¸°ë°˜ (AI ëª¨ë¸ ì‹¤íŒ¨)"
            logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")
    else:
        logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì‚¬ìš© (ëª¨ë¸ íŒŒì¼ í¬ê¸° ë¶€ì¡±)")
        rule_start_time = datetime.now()
        rule_results = rule_based_recommendation(request_dict, 10)
        top_10 = pd.DataFrame(rule_results)
        rule_time = (datetime.now() - rule_start_time).total_seconds()
        method_used = "ë£° ê¸°ë°˜ (ëª¨ë¸ í¬ê¸° ë¶€ì¡±)"
        logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")

    # 2) ê²°ê³¼ ê°€ê³µ
    response_list: List[PerfumeRecommendItem] = []
    for idx, (_, row) in enumerate(top_10.iterrows(), 1):
        emotions_text = get_emotion_text(row)
        score = float(row.get('score', 0.0))

        # ì¶”ì²œ ì´ìœ  ìƒì„±
        reason = get_recommendation_reason(score, method_used)

        response_list.append(
            PerfumeRecommendItem(
                name=str(row["name"]),
                brand=str(row["brand"]),
                image_url=str(row["image_url"]),
                notes=str(row["notes"]),
                emotions=emotions_text,
                reason=reason,
                score=score,
                method=method_used
            )
        )

    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    total_processing_time = (datetime.now() - request_start_time).total_seconds()

    logger.info(f"âœ… í–¥ìˆ˜ ì¶”ì²œ ì™„ë£Œ: {len(response_list)}ê°œ ({method_used})")
    logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.3f}ì´ˆ")
    if response_list:
        logger.info(
            f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {min(item.score for item in response_list):.3f} ~ {max(item.score for item in response_list):.3f}")
        logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {sum(item.score for item in response_list) / len(response_list):.3f}")

    return response_list


@router.get(
    "/model-status",
    summary="ëª¨ë¸ ìƒíƒœ í™•ì¸",
    description="AI ëª¨ë¸ê³¼ ê´€ë ¨ íŒŒì¼ë“¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def get_model_status():
    """ëª¨ë¸ ë° ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    # íŒŒì¼ ìƒíƒœ í™•ì¸
    model_exists = os.path.exists(MODEL_PATH)
    encoder_exists = os.path.exists(ENCODER_PATH)

    model_size = os.path.getsize(MODEL_PATH) if model_exists else 0
    encoder_size = os.path.getsize(ENCODER_PATH) if encoder_exists else 0

    # âœ… ìˆ˜ì •ëœ ìœ íš¨ì„± ê¸°ì¤€
    model_size_valid = model_size > 10000  # 10KB ì´ìƒ (ê¸°ì¡´: 100KB)
    encoder_size_valid = encoder_size > 500  # 500B ì´ìƒ (ê¸°ì¡´: 100B)

    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ (ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš°)
    model_structure = None
    if _model is not None:
        try:
            model_structure = {
                "input_shape": str(_model.input_shape),
                "output_shape": str(_model.output_shape),
                "total_params": _model.count_params(),
                "layers": len(_model.layers),
                "layer_details": [
                    {
                        "name": layer.name,
                        "type": layer.__class__.__name__,
                        "units": getattr(layer, 'units', None),
                        "activation": getattr(layer.activation, '__name__', None) if hasattr(layer,
                                                                                             'activation') else None
                    } for layer in _model.layers
                ]
            }
        except:
            model_structure = "ëª¨ë¸ ì •ë³´ ì½ê¸° ì‹¤íŒ¨"

    return {
        "timestamp": datetime.now().isoformat(),
        "model_available": _model_available,
        "files": {
            "keras_model": {
                "path": MODEL_PATH,
                "exists": model_exists,
                "size_bytes": model_size,
                "size_kb": round(model_size / 1024, 2),  # KB ë‹¨ìœ„ ì¶”ê°€
                "size_mb": round(model_size / (1024 * 1024), 2),
                "valid": model_size_valid,
                "min_required_kb": 10,  # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ëª…ì‹œ
                "status": "âœ… ìœ íš¨" if model_size_valid else "âŒ í¬ê¸° ë¶€ì¡±"
            },
            "encoder": {
                "path": ENCODER_PATH,
                "exists": encoder_exists,
                "size_bytes": encoder_size,
                "size_kb": round(encoder_size / 1024, 2),
                "valid": encoder_size_valid,
                "min_required_bytes": 500,  # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ëª…ì‹œ
                "status": "âœ… ìœ íš¨" if encoder_size_valid else "âŒ í¬ê¸° ë¶€ì¡±"
            }
        },
        "model_info": {
            "expected_structure": {
                "input_shape": "(None, 6)",
                "layers": [
                    "Dense(64, activation='relu')",
                    "Dense(6, activation='softmax')"
                ],
                "output_shape": "(None, 6)",
                "purpose": "6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜"
            },
            "keras_version": "3.8.0 (detected from file)",
            "saved_date": "2025-06-05@05:09:56"
        },
        "model_structure": model_structure,
        "emotion_clusters": EMOTION_CLUSTER_MAP,
        "recommendation_method": "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸" if _model_available else "ë£° ê¸°ë°˜",
        "fallback_encoder_ready": _fallback_encoder is not None,
        "system": {
            "python_version": sys.version.split()[0],
            "current_directory": os.getcwd(),
            "router_location": BASE_DIR,
            "dataset_loaded": len(df) > 0,
            "dataset_size": len(df)
        },
        "dataset_info": {
            "total_perfumes": len(df),
            "columns": list(df.columns),
            "sample_brands": df['brand'].unique()[:5].tolist() if 'brand' in df.columns else [],
            "emotion_cluster_distribution": dict(
                df['emotion_cluster'].value_counts()) if 'emotion_cluster' in df.columns else None
        }
    }


@router.get(
    "/health",
    summary="ì¶”ì²œ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬",
    description="ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def health_check():
    """ì¶”ì²œ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""

    health_status = {
        "timestamp": datetime.now().isoformat(),
        "status": "healthy",
        "checks": {}
    }

    # ë°ì´í„°ì…‹ í™•ì¸
    try:
        health_status["checks"]["dataset"] = {
            "status": "ok" if len(df) > 0 else "error",
            "perfume_count": len(df),
            "columns_available": len(df.columns)
        }
    except Exception as e:
        health_status["checks"]["dataset"] = {
            "status": "error",
            "error": str(e)
        }

    # ëª¨ë¸ íŒŒì¼ í™•ì¸ (ìˆ˜ì •ëœ ê¸°ì¤€)
    try:
        model_exists = os.path.exists(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH)
        model_size = os.path.getsize(MODEL_PATH) if model_exists else 0
        encoder_size = os.path.getsize(ENCODER_PATH) if encoder_exists else 0

        # âœ… ìˆ˜ì •ëœ í¬ê¸° ê¸°ì¤€
        model_valid = model_exists and model_size > 10000  # 10KB ì´ìƒ
        encoder_valid = encoder_exists and encoder_size > 500  # 500B ì´ìƒ

        health_status["checks"]["model_files"] = {
            "status": "ok" if model_valid and encoder_valid else "warning",
            "model_available": model_valid,
            "encoder_available": encoder_valid,
            "model_size_kb": round(model_size / 1024, 2),
            "encoder_size_bytes": encoder_size,
            "fallback_ready": _fallback_encoder is not None
        }
    except Exception as e:
        health_status["checks"]["model_files"] = {
            "status": "error",
            "error": str(e)
        }

    # ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    try:
        test_request = {
            "gender": "women",
            "season_tags": "spring",
            "time_tags": "day",
            "desired_impression": "fresh",
            "activity": "casual",
            "weather": "any"
        }

        start_time = datetime.now()
        if _model_available:
            try:
                test_results = predict_with_emotion_cluster_model(test_request)
                method = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"
            except:
                rule_results = rule_based_recommendation(test_request, 3)
                test_results = pd.DataFrame(rule_results)
                method = "ë£° ê¸°ë°˜ (AI ì‹¤íŒ¨)"
        else:
            rule_results = rule_based_recommendation(test_request, 3)
            test_results = pd.DataFrame(rule_results)
            method = "ë£° ê¸°ë°˜ (ëª¨ë¸ í¬ê¸° ë¶€ì¡±)"

        processing_time = (datetime.now() - start_time).total_seconds()

        health_status["checks"]["recommendation_system"] = {
            "status": "ok" if len(test_results) > 0 else "error",
            "test_result_count": len(test_results),
            "processing_time_seconds": round(processing_time, 3),
            "method": method
        }
    except Exception as e:
        health_status["checks"]["recommendation_system"] = {
            "status": "error",
            "error": str(e)
        }

    # ì „ì²´ ìƒíƒœ ê²°ì •
    all_checks = health_status["checks"].values()
    if any(check.get("status") == "error" for check in all_checks):
        health_status["status"] = "unhealthy"
    elif any(check.get("status") == "warning" for check in all_checks):
        health_status["status"] = "degraded"

    return health_status


@router.post(
    "/test-recommendation",
    summary="ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ê°œë°œìš©)",
    description="ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ ì¶”ì²œ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
)
def test_recommendation_system():
    """ì¶”ì²œ ì‹œìŠ¤í…œì„ ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""

    test_cases = [
        {
            "name": "ì—¬ì„±ìš© ë´„ ë°ì´ í–¥ìˆ˜",
            "request": {
                "gender": "women",
                "season_tags": "spring",
                "time_tags": "day",
                "desired_impression": "fresh",
                "activity": "casual",
                "weather": "any"
            }
        },
        {
            "name": "ë‚¨ì„±ìš© ê²¨ìš¸ ë‚˜ì´íŠ¸ í–¥ìˆ˜",
            "request": {
                "gender": "men",
                "season_tags": "winter",
                "time_tags": "night",
                "desired_impression": "confident",
                "activity": "date",
                "weather": "cold"
            }
        },
        {
            "name": "ìœ ë‹ˆì„¹ìŠ¤ ì—¬ë¦„ í–¥ìˆ˜",
            "request": {
                "gender": "unisex",
                "season_tags": "summer",
                "time_tags": "day",
                "desired_impression": "mysterious",
                "activity": "work",
                "weather": "hot"
            }
        }
    ]

    results = []

    for test_case in test_cases:
        try:
            start_time = datetime.now()

            # AI ëª¨ë¸ ë˜ëŠ” ë£° ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
            if _model_available:
                try:
                    ai_results = predict_with_emotion_cluster_model(test_case["request"])
                    result_data = ai_results.to_dict('records')[:3]
                    method = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"
                except:
                    rule_results = rule_based_recommendation(test_case["request"], 5)
                    result_data = rule_results[:3]
                    method = "ë£° ê¸°ë°˜ (AI ì‹¤íŒ¨)"
            else:
                rule_results = rule_based_recommendation(test_case["request"], 5)
                result_data = rule_results[:3]
                method = "ë£° ê¸°ë°˜ (ëª¨ë¸ í¬ê¸° ë¶€ì¡±)"

            processing_time = (datetime.now() - start_time).total_seconds()

            results.append({
                "test_name": test_case["name"],
                "request": test_case["request"],
                "success": True,
                "method": method,
                "result_count": len(result_data),
                "processing_time_seconds": round(processing_time, 3),
                "sample_results": [
                    {
                        "name": r.get("name", ""),
                        "brand": r.get("brand", ""),
                        "score": round(r.get("score", 0), 3)
                    } for r in result_data
                ]
            })

        except Exception as e:
            results.append({
                "test_name": test_case["name"],
                "request": test_case["request"],
                "success": False,
                "error": str(e),
                "processing_time_seconds": 0
            })

    return {
        "timestamp": datetime.now().isoformat(),
        "model_available": _model_available,
        "model_size_kb": round(os.path.getsize(MODEL_PATH) / 1024, 2) if os.path.exists(MODEL_PATH) else 0,
        "encoder_size_bytes": os.path.getsize(ENCODER_PATH) if os.path.exists(ENCODER_PATH) else 0,
        "fallback_encoder_available": _fallback_encoder is not None,
        "dataset_size": len(df),
        "emotion_clusters": EMOTION_CLUSTER_MAP,
        "test_results": results,
        "summary": {
            "total_tests": len(test_cases),
            "successful_tests": sum(1 for r in results if r["success"]),
            "average_processing_time": round(
                sum(r.get("processing_time_seconds", 0) for r in results) / len(results), 3
            )
        }
    }