import os
import pickle
import logging
import random
import sys
import numpy as np
from datetime import datetime
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Literal, Optional, Dict, Any
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from collections import Counter

# âœ… schemas/recommend.pyì—ì„œ ìŠ¤í‚¤ë§ˆ ì„í¬íŠ¸
from schemas.recommend import (
    RecommendRequest,
    RecommendedPerfume,
    RecommendResponse,
    ClusterRecommendResponse,  # ğŸ†• ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ
    SUPPORTED_CATEGORIES,
    EMOTION_CLUSTER_DESCRIPTIONS,
    validate_request_categories,
    map_single_to_combined_impression
)

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recommend_router")

# â”€â”€â”€ 1. perfume_final_dataset.csv ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/perfume_final_dataset.csv")
try:
    df = pd.read_csv(DATA_PATH)
    df.fillna("", inplace=True)
    logger.info(f"âœ… Perfume dataset loaded: {df.shape[0]} rows")
    logger.info(f"ğŸ“‹ Available columns: {list(df.columns)}")

    # âœ… ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    required_columns = ['name', 'brand', 'image_url', 'notes']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        logger.error(f"âŒ Missing required columns: {missing_columns}")
        raise RuntimeError(f"Missing required columns: {missing_columns}")

    # âœ… emotion ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
    if 'desired_impression' in df.columns:
        logger.info("âœ… Using 'desired_impression' column for emotion data")
    if 'emotion_cluster' in df.columns:
        logger.info("âœ… Using 'emotion_cluster' column for cluster data")
        # emotion_cluster ì»¬ëŸ¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        df['emotion_cluster'] = pd.to_numeric(df['emotion_cluster'], errors='coerce').fillna(0).astype(int)
        logger.info(f"ğŸ“Š Emotion clusters: {sorted(df['emotion_cluster'].unique())}")
    else:
        logger.warning("âš ï¸ No emotion_cluster column found")

    # ğŸ“Š ë°ì´í„° ìƒ˜í”Œ ë¡œê·¸
    if len(df) > 0:
        sample_row = df.iloc[0]
        logger.info(f"ğŸ“ Sample data: {sample_row['name']} by {sample_row['brand']}")

except Exception as e:
    logger.error(f"âŒ perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    raise RuntimeError(f"perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# â”€â”€â”€ 2. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "../models/final_model.keras")
ENCODER_PATH = os.path.join(BASE_DIR, "../models/encoder.pkl")

# â”€â”€â”€ 3. ì „ì—­ ë³€ìˆ˜ ë° ìƒíƒœ ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_model = None
_encoder = None
_model_available = False
_fallback_encoder = None

# â”€â”€â”€ 4. ê°ì • í´ëŸ¬ìŠ¤í„° ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_CLUSTER_MAP = {
    0: "ì°¨ë¶„í•œ, í¸ì•ˆí•œ",
    1: "ìì‹ ê°, ì‹ ì„ í•¨",
    2: "ìš°ì•„í•¨, ì¹œê·¼í•¨",
    3: "ìˆœìˆ˜í•¨, ì¹œê·¼í•¨",
    4: "ì‹ ë¹„ë¡œìš´, ë§¤ë ¥ì ",
    5: "í™œê¸°ì°¬, ì—ë„ˆì§€"
}

# âœ… encoder.pklê³¼ í˜¸í™˜ë˜ëŠ” ì¹´í…Œê³ ë¦¬ ë§¤í•‘
API_TO_MODEL_MAPPING = {
    "gender": {
        "men": "men",
        "unisex": "unisex",
        "women": "women"
    },
    "season_tags": {
        "fall": "fall",
        "spring": "spring",
        "summer": "summer",
        "winter": "winter"
    },
    "time_tags": {
        "day": "day",
        "night": "night"
    },
    "desired_impression": {
        "confident, fresh": "confident, fresh",
        "confident, mysterious": "confident, mysterious",
        "elegant, friendly": "elegant, friendly",
        "pure, friendly": "pure, friendly"
    },
    "activity": {
        "casual": "casual",
        "date": "date",
        "work": "work"
    },
    "weather": {
        "any": "any",
        "cold": "cold",
        "hot": "hot",
        "rainy": "rainy"
    }
}


# â”€â”€â”€ 5. ğŸ†• ë…¸íŠ¸ ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (í´ëŸ¬ìŠ¤í„° ì¶”ì²œìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_notes_from_string(notes_str: str) -> List[str]:
    """
    ë…¸íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ê°œë³„ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    (í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œì—ì„œ ì‚¬ìš©)
    """
    if not notes_str or pd.isna(notes_str):
        return []

    # ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°
    notes = [note.strip().lower() for note in str(notes_str).split(',')]

    # ë¹ˆ ë¬¸ìì—´ ì œê±°
    notes = [note for note in notes if note and note != '']

    return notes


def get_top_notes_from_cluster(cluster_perfumes: pd.DataFrame, top_k: int = 15) -> List[str]:
    """
    í´ëŸ¬ìŠ¤í„°ì— ì†í•œ í–¥ìˆ˜ë“¤ì˜ ë…¸íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìƒìœ„ Kê°œ ë…¸íŠ¸ ë°˜í™˜
    (í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œì—ì„œ ì‚¬ìš©)
    """
    all_notes = []

    for _, row in cluster_perfumes.iterrows():
        notes = parse_notes_from_string(row.get('notes', ''))
        all_notes.extend(notes)

    if not all_notes:
        # ë…¸íŠ¸ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ í–¥ìˆ˜ ë…¸íŠ¸ ë°˜í™˜
        return [
                   "bergamot", "jasmine", "rose", "vanilla", "sandalwood",
                   "cedar", "musk", "amber", "lavender", "citrus",
                   "woody", "floral", "fresh", "sweet", "spicy"
               ][:top_k]

    # ë¹ˆë„ ê³„ì‚° ë° ìƒìœ„ Kê°œ ì„ íƒ
    note_counter = Counter(all_notes)
    top_notes = [note for note, count in note_counter.most_common(top_k)]

    logger.info(f"ğŸ“Š í´ëŸ¬ìŠ¤í„° ë…¸íŠ¸ ë¶„ì„: ì´ {len(all_notes)}ê°œ ë…¸íŠ¸ â†’ ìƒìœ„ {len(top_notes)}ê°œ ì„ íƒ")
    logger.info(f"ğŸ“Š ìƒìœ„ 5ê°œ ë…¸íŠ¸: {top_notes[:5]}")

    return top_notes


def get_perfume_indices(cluster_perfumes: pd.DataFrame, top_k: int = 10) -> List[int]:
    """
    ì¶”ì²œ í–¥ìˆ˜ë“¤ì˜ ì›ë³¸ DataFrame ì¸ë±ìŠ¤ ë°˜í™˜
    (í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œì—ì„œ ì‚¬ìš©)
    """
    # ì ìˆ˜ê°€ ìˆìœ¼ë©´ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬, ì—†ìœ¼ë©´ ì›ë³¸ ìˆœì„œ ìœ ì§€
    if 'score' in cluster_perfumes.columns:
        sorted_perfumes = cluster_perfumes.nlargest(top_k, 'score')
    else:
        sorted_perfumes = cluster_perfumes.head(top_k)

    indices = sorted_perfumes.index.tolist()

    logger.info(f"ğŸ“‹ ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤: {indices}")

    return indices


# â”€â”€â”€ 6. ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_model_availability():
    """ëª¨ë¸ íŒŒì¼ë“¤ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    global _model_available

    logger.info("ğŸ” ëª¨ë¸ íŒŒì¼ ê°€ìš©ì„± í™•ì¸ ì¤‘...")

    try:
        # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
        model_exists = os.path.exists(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH)

        model_valid = False
        encoder_valid = False

        if model_exists:
            model_size = os.path.getsize(MODEL_PATH)
            # âœ… ì‹¤ì œ ëª¨ë¸ íŒŒì¼ í¬ê¸°ì— ë§ê²Œ ìˆ˜ì •: 31KB ëª¨ë¸ì´ë¯€ë¡œ 10KB ì´ìƒìœ¼ë¡œ ì²´í¬
            model_valid = model_size > 10000  # 10KB ì´ìƒ
            logger.info(f"ğŸ“„ ëª¨ë¸ íŒŒì¼: {model_size:,}B ({model_size / 1024:.1f}KB) {'âœ…' if model_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")

        if encoder_exists:
            encoder_size = os.path.getsize(ENCODER_PATH)
            # âœ… ì¸ì½”ë”ëŠ” 1KBì´ë¯€ë¡œ 500B ì´ìƒìœ¼ë¡œ ì²´í¬
            encoder_valid = encoder_size > 500  # 500B ì´ìƒ
            logger.info(f"ğŸ“„ ì¸ì½”ë” íŒŒì¼: {encoder_size:,}B ({encoder_size}B) {'âœ…' if encoder_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")

        _model_available = model_valid and encoder_valid

        logger.info(f"ğŸ¤– ëª¨ë¸ ê°€ìš©ì„±: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if _model_available else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")

        if _model_available:
            logger.info(f"âœ¨ ëª¨ë¸ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ - í¬ê¸°: {model_size / 1024:.1f}KB")
        else:
            if not model_valid:
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ í¬ê¸° ë¶€ì¡±: {model_size}B (ìµœì†Œ 10KB í•„ìš”)")
            if not encoder_valid:
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ í¬ê¸° ë¶€ì¡±: {encoder_size}B (ìµœì†Œ 500B í•„ìš”)")

        return _model_available

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        _model_available = False
        return False


# â”€â”€â”€ 7. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_model():
    """Keras ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model

    if _model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
                return None

            # âœ… íŒŒì¼ í¬ê¸° í™•ì¸ - 31KB ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •
            model_size = os.path.getsize(MODEL_PATH)
            if model_size < 10000:  # 10KB ë¯¸ë§Œ
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {model_size} bytes ({model_size / 1024:.1f}KB)")
                return None

            logger.info(f"ğŸ“¦ ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸ ì™„ë£Œ: {model_size:,}B ({model_size / 1024:.1f}KB)")

            # TensorFlow ë™ì  ì„í¬íŠ¸ ë° Keras 3.x í˜¸í™˜ì„± ê³ ë ¤
            try:
                tf_start = datetime.now()

                # âœ… Keras 3.x ì§€ì›ì„ ìœ„í•œ ì„í¬íŠ¸ ë°©ì‹ ê°œì„ 
                try:
                    # Keras 3.x ë°©ì‹ ì‹œë„
                    import tensorflow as tf
                    from tensorflow import keras
                    load_model = keras.models.load_model
                    logger.info(f"ğŸ“¦ TensorFlow {tf.__version__} + Keras 3.x ìŠ¤íƒ€ì¼ ë¡œë”©")
                except:
                    # ê¸°ì¡´ ë°©ì‹ í´ë°±
                    from tensorflow.keras.models import load_model
                    logger.info(f"ğŸ“¦ TensorFlow ê¸°ì¡´ ìŠ¤íƒ€ì¼ ë¡œë”©")

                tf_load_time = (datetime.now() - tf_start).total_seconds()

                logger.info(f"ğŸ“¦ Keras ëª¨ë¸ ë¡œë”© ì‹œë„ (TF ë¡œë”©: {tf_load_time:.3f}ì´ˆ)")
                logger.info(f"ğŸ“Š ì˜ˆìƒ ëª¨ë¸ êµ¬ì¡°: ì…ë ¥(6) â†’ Dense(64,relu) â†’ Dense(6,softmax)")

                model_start = datetime.now()

                # âœ… compile=Falseë¡œ ë¹ ë¥¸ ë¡œë”©, Keras 3.x í˜¸í™˜
                _model = load_model(MODEL_PATH, compile=False)
                model_load_time = (datetime.now() - model_start).total_seconds()

                # âœ… ëª¨ë¸ êµ¬ì¡° ê²€ì¦
                logger.info(f"âœ… Keras ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ëª¨ë¸ ë¡œë”©: {model_load_time:.3f}ì´ˆ)")
                logger.info(f"ğŸ“Š ì‹¤ì œ ëª¨ë¸ ì…ë ¥ shape: {_model.input_shape}")
                logger.info(f"ğŸ“Š ì‹¤ì œ ëª¨ë¸ ì¶œë ¥ shape: {_model.output_shape}")

                # âœ… ë ˆì´ì–´ ì •ë³´ ì¶œë ¥
                logger.info(f"ğŸ“Š ëª¨ë¸ ë ˆì´ì–´ ìˆ˜: {len(_model.layers)}")
                for i, layer in enumerate(_model.layers):
                    layer_info = f"  Layer {i + 1}: {layer.__class__.__name__}"
                    if hasattr(layer, 'units'):
                        layer_info += f" (units: {layer.units})"
                    if hasattr(layer, 'activation'):
                        layer_info += f" (activation: {layer.activation.__name__})"
                    logger.info(layer_info)

                # âœ… ì¶œë ¥ í¬ê¸° ê²€ì¦ (6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„°)
                output_size = _model.output_shape[-1]
                if output_size == 6:
                    logger.info("ğŸ¯ 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ ëª¨ë¸ë¡œ í™•ì¸ë¨")
                else:
                    logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì¶œë ¥ í¬ê¸°: {output_size} (ì˜ˆìƒ: 6)")

                # âœ… ì…ë ¥ í¬ê¸° ê²€ì¦ (6ê°œ íŠ¹ì„±)
                input_size = _model.input_shape[-1]
                if input_size == 6:
                    logger.info("ğŸ¯ 6ê°œ ì…ë ¥ íŠ¹ì„± ëª¨ë¸ë¡œ í™•ì¸ë¨")
                else:
                    logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì…ë ¥ í¬ê¸°: {input_size} (ì˜ˆìƒ: 6)")

                # âœ… ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¶”ë¡  (ëª¨ë¸ ë™ì‘ í™•ì¸)
                try:
                    test_input = np.random.random((1, 6)).astype(np.float32)
                    test_output = _model.predict(test_input, verbose=0)
                    logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì„±ê³µ: ì…ë ¥{test_input.shape} â†’ ì¶œë ¥{test_output.shape}")
                    logger.info(f"ğŸ§ª ì¶œë ¥ í•©ê³„: {test_output.sum():.3f} (softmaxì´ë©´ ~1.0)")

                    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° í™•ì¸
                    predicted_cluster = int(np.argmax(test_output[0]))
                    confidence = float(test_output[0][predicted_cluster])
                    logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡: í´ëŸ¬ìŠ¤í„° {predicted_cluster} (ì‹ ë¢°ë„: {confidence:.3f})")
                except Exception as test_e:
                    logger.warning(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹¤íŒ¨: {test_e}")

            except ImportError as e:
                logger.error(f"âŒ TensorFlowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return None
            except Exception as e:
                logger.error(f"âŒ Keras ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                logger.error(f"  íŒŒì¼ ê²½ë¡œ: {MODEL_PATH}")
                logger.error(f"  íŒŒì¼ í¬ê¸°: {model_size}B")
                return None

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜ˆì™¸: {e}")
            return None

    return _model


def get_saved_encoder():
    """ì €ì¥ëœ encoder.pklì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _encoder

    if _encoder is None:
        try:
            if not os.path.exists(ENCODER_PATH):
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")
                return None

            encoder_size = os.path.getsize(ENCODER_PATH)
            logger.info(f"ğŸ“¦ ì¸ì½”ë” ë¡œë”© ì‹œë„: {ENCODER_PATH} ({encoder_size}B)")

            with open(ENCODER_PATH, "rb") as f:
                _encoder = pickle.load(f)
            logger.info("âœ… encoder.pkl ë¡œë“œ ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ encoder.pkl ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    return _encoder


def get_fallback_encoder():
    """âœ… encoder.pklê³¼ í˜¸í™˜ë˜ëŠ” Fallback OrdinalEncoderë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global _fallback_encoder

    if _fallback_encoder is None:
        try:
            logger.info("ğŸ”§ Fallback OrdinalEncoder ìƒì„± ì¤‘...")

            # âœ… encoder.pklê³¼ ë™ì¼í•œ ì¹´í…Œê³ ë¦¬ ì •ì˜
            from sklearn.preprocessing import OrdinalEncoder

            CATEGORIES = [
                ["men", "unisex", "women"],  # gender
                ["fall", "spring", "summer", "winter"],  # season_tags
                ["day", "night"],  # time_tags
                ["confident, fresh", "confident, mysterious", "elegant, friendly", "pure, friendly"],
                # desired_impression
                ["casual", "date", "work"],  # activity
                ["any", "cold", "hot", "rainy"]  # weather
            ]

            # âœ… OrdinalEncoder ìƒì„± (encoder.pklê³¼ ë™ì¼í•œ íƒ€ì…)
            _fallback_encoder = OrdinalEncoder(
                categories=CATEGORIES,
                handle_unknown="error"
            )

            # ë”ë¯¸ ë°ì´í„°ë¡œ fit (encoder.pklê³¼ ì™„ì „ ì¼ì¹˜)
            dummy_data = [
                ["men", "fall", "day", "confident, fresh", "casual", "any"],
                ["unisex", "spring", "night", "confident, mysterious", "date", "cold"],
                ["women", "summer", "day", "elegant, friendly", "work", "hot"],
                ["men", "winter", "night", "pure, friendly", "casual", "rainy"]
            ]

            _fallback_encoder.fit(dummy_data)
            logger.info("âœ… Fallback OrdinalEncoder ìƒì„± ë° í›ˆë ¨ ì™„ë£Œ")

            # âœ… ì¸ì½”ë” ê²€ì¦ í…ŒìŠ¤íŠ¸
            test_input = ["women", "spring", "day", "confident, fresh", "casual", "hot"]
            test_encoded = _fallback_encoder.transform([test_input])
            logger.info(f"ğŸ§ª Fallback ì¸ì½”ë” í…ŒìŠ¤íŠ¸ ì„±ê³µ: ì…ë ¥ 6ê°œ â†’ ì¶œë ¥ {test_encoded.shape[1]}ê°œ")

        except Exception as e:
            logger.error(f"âŒ Fallback encoder ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    return _fallback_encoder


def safe_transform_input(raw_features: list) -> np.ndarray:
    """âœ… ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ í•¨ìˆ˜"""
    try:
        # 1. ì €ì¥ëœ ì¸ì½”ë” ì‹œë„
        encoder = get_saved_encoder()
        if encoder:
            try:
                logger.info(f"ğŸ” ì €ì¥ëœ ì¸ì½”ë”ë¡œ ë³€í™˜ ì‹œë„: {raw_features}")
                transformed = encoder.transform([raw_features])
                logger.info(f"âœ… ì €ì¥ëœ ì¸ì½”ë” ë³€í™˜ ì„±ê³µ: {transformed.shape}")
                return transformed
            except Exception as e:
                logger.warning(f"âš ï¸ ì €ì¥ëœ ì¸ì½”ë” ì‹¤íŒ¨: {e}")

        # 2. Fallback ì¸ì½”ë” ì‹œë„
        fallback_encoder = get_fallback_encoder()
        if fallback_encoder:
            logger.info(f"ğŸ”„ Fallback ì¸ì½”ë”ë¡œ ë³€í™˜: {raw_features}")
            transformed = fallback_encoder.transform([raw_features])
            logger.info(f"âœ… Fallback ì¸ì½”ë” ë³€í™˜ ì„±ê³µ: {transformed.shape}")
            return transformed
        else:
            raise Exception("Fallback ì¸ì½”ë” ìƒì„± ì‹¤íŒ¨")

    except Exception as e:
        logger.error(f"âŒ ì…ë ¥ ë³€í™˜ ì™„ì „ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 8. ğŸ†• í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_cluster_recommendation(request_dict: dict) -> Dict[str, Any]:
    """
    âœ… í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ - ìƒˆë¡œìš´ ì‘ë‹µ í˜•íƒœ

    Returns:
        {
            "cluster": int,
            "description": str,
            "proba": List[float],
            "recommended_notes": List[str],
            "selected_idx": List[int]
        }
    """
    try:
        start_time = datetime.now()

        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # âœ… API ì…ë ¥ì„ ëª¨ë¸ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        raw_features = [
            request_dict["gender"],
            request_dict["season_tags"],
            request_dict["time_tags"],
            request_dict["desired_impression"],
            request_dict["activity"],
            request_dict["weather"]
        ]

        logger.info(f"ğŸ”® í´ëŸ¬ìŠ¤í„° ì¶”ì²œ ì…ë ¥ ë°ì´í„°: {raw_features}")

        # âœ… ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ ì‚¬ìš©
        x_input = safe_transform_input(raw_features)
        logger.info(f"ğŸ”® ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì‹œì‘ (ì…ë ¥ shape: {x_input.shape})")

        # ëª¨ë¸ ì˜ˆì¸¡ (ê°ì • í´ëŸ¬ìŠ¤í„°)
        preds = model.predict(x_input, verbose=0)  # (1, 6) ì¶œë ¥
        cluster_probabilities = preds[0]  # [0.1, 0.8, 0.05, 0.02, 0.02, 0.01]
        predicted_cluster = int(np.argmax(cluster_probabilities))  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„°
        confidence = float(cluster_probabilities[predicted_cluster])

        # í´ëŸ¬ìŠ¤í„° ì„¤ëª…
        cluster_description = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")

        logger.info(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°: {predicted_cluster} ({cluster_description}) - ì‹ ë¢°ë„: {confidence:.3f}")

        # ëª¨ë“  í´ëŸ¬ìŠ¤í„° í™•ë¥  ë¡œê·¸
        for i, prob in enumerate(cluster_probabilities):
            cluster_desc = EMOTION_CLUSTER_MAP.get(i, f"í´ëŸ¬ìŠ¤í„° {i}")
            logger.info(f"  í´ëŸ¬ìŠ¤í„° {i} ({cluster_desc}): {prob:.3f}")

        # ê°ì • í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
            logger.info(f"ğŸ“‹ í´ëŸ¬ìŠ¤í„° {predicted_cluster} í–¥ìˆ˜ ê°œìˆ˜: {len(cluster_perfumes)}ê°œ")
        else:
            logger.warning("âš ï¸ emotion_cluster ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ë°ì´í„° ì‚¬ìš©")
            cluster_perfumes = df.copy()

        # í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
        if cluster_perfumes.empty:
            logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {predicted_cluster}ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìŒ")
            # ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
            second_best = int(np.argsort(cluster_probabilities)[-2])
            cluster_perfumes = df[df['emotion_cluster'] == second_best].copy()
            predicted_cluster = second_best
            confidence = float(cluster_probabilities[second_best])
            cluster_description = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")
            logger.info(f"ğŸ“‹ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° {second_best} ì‚¬ìš©: {len(cluster_perfumes)}ê°œ")

        # âœ… ì¶”ê°€ í•„í„°ë§ (ì„±ë³„, ê³„ì ˆ ë“±)
        original_count = len(cluster_perfumes)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == request_dict["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered
                logger.info(f"  ì„±ë³„ '{request_dict['gender']}' í•„í„°ë§: {original_count} â†’ {len(cluster_perfumes)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    request_dict["season_tags"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered
                logger.info(f"  ê³„ì ˆ '{request_dict['season_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in cluster_perfumes.columns:
            time_filtered = cluster_perfumes[
                cluster_perfumes['time_tags'].str.contains(
                    request_dict["time_tags"], na=False, case=False
                )
            ]
            if not time_filtered.empty:
                cluster_perfumes = time_filtered
                logger.info(f"  ì‹œê°„ '{request_dict['time_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # âœ… ìƒìœ„ 15ê°œ ë…¸íŠ¸ ì¶”ì¶œ
        recommended_notes = get_top_notes_from_cluster(cluster_perfumes, top_k=15)

        # âœ… ìƒìœ„ 10ê°œ í–¥ìˆ˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
        selected_indices = get_perfume_indices(cluster_perfumes, top_k=10)

        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds()

        # âœ… ìƒˆë¡œìš´ í˜•íƒœì˜ ì‘ë‹µ êµ¬ì„±
        result = {
            "cluster": predicted_cluster,
            "description": cluster_description,
            "proba": [round(float(prob), 4) for prob in cluster_probabilities],  # ì†Œìˆ˜ì  4ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
            "recommended_notes": recommended_notes,
            "selected_idx": selected_indices,
            "metadata": {
                "processing_time_seconds": round(processing_time, 3),
                "total_cluster_perfumes": len(cluster_perfumes),
                "confidence": round(confidence, 3),
                "method": "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸",
                "filters_applied": {
                    "gender": request_dict["gender"],
                    "season": request_dict["season_tags"],
                    "time": request_dict["time_tags"]
                }
            }
        }

        logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ: í´ëŸ¬ìŠ¤í„° {predicted_cluster} (ì†Œìš”ì‹œê°„: {processing_time:.3f}ì´ˆ)")

        return result

    except Exception as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 9. AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ (ê¸°ì¡´ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_with_emotion_cluster_model(request_dict: dict) -> pd.DataFrame:
    """âœ… ìˆ˜ì •ëœ ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ì‚¬ìš©í•œ AI ì¶”ì²œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""

    try:
        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # âœ… API ì…ë ¥ì„ ëª¨ë¸ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        raw_features = [
            request_dict["gender"],
            request_dict["season_tags"],
            request_dict["time_tags"],
            request_dict["desired_impression"],
            request_dict["activity"],
            request_dict["weather"]
        ]

        logger.info(f"ğŸ”® AI ëª¨ë¸ ì…ë ¥ ë°ì´í„°: {raw_features}")

        # âœ… ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ ì‚¬ìš©
        x_input = safe_transform_input(raw_features)
        logger.info(f"ğŸ”® ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì‹œì‘ (ì…ë ¥ shape: {x_input.shape})")

        # ëª¨ë¸ ì˜ˆì¸¡ (ê°ì • í´ëŸ¬ìŠ¤í„°)
        preds = model.predict(x_input, verbose=0)  # (1, 6) ì¶œë ¥
        cluster_probabilities = preds[0]  # [0.1, 0.8, 0.05, 0.02, 0.02, 0.01]
        predicted_cluster = int(np.argmax(cluster_probabilities))  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„°
        confidence = float(cluster_probabilities[predicted_cluster])

        cluster_name = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")
        logger.info(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°: {predicted_cluster} ({cluster_name}) - ì‹ ë¢°ë„: {confidence:.3f}")

        # ëª¨ë“  í´ëŸ¬ìŠ¤í„° í™•ë¥  ë¡œê·¸
        for i, prob in enumerate(cluster_probabilities):
            cluster_desc = EMOTION_CLUSTER_MAP.get(i, f"í´ëŸ¬ìŠ¤í„° {i}")
            logger.info(f"  í´ëŸ¬ìŠ¤í„° {i} ({cluster_desc}): {prob:.3f}")

        # ê°ì • í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
            logger.info(f"ğŸ“‹ í´ëŸ¬ìŠ¤í„° {predicted_cluster} í–¥ìˆ˜ ê°œìˆ˜: {len(cluster_perfumes)}ê°œ")
        else:
            logger.warning("âš ï¸ emotion_cluster ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ë°ì´í„° ì‚¬ìš©")
            cluster_perfumes = df.copy()

        # í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
        if cluster_perfumes.empty:
            logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {predicted_cluster}ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìŒ")
            # ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
            second_best = int(np.argsort(cluster_probabilities)[-2])
            cluster_perfumes = df[df['emotion_cluster'] == second_best].copy()
            predicted_cluster = second_best
            confidence = float(cluster_probabilities[second_best])
            logger.info(f"ğŸ“‹ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° {second_best} ì‚¬ìš©: {len(cluster_perfumes)}ê°œ")

        # ì¶”ê°€ í•„í„°ë§ (ì„±ë³„, ê³„ì ˆ ë“±)
        original_count = len(cluster_perfumes)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == request_dict["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered
                logger.info(f"  ì„±ë³„ '{request_dict['gender']}' í•„í„°ë§: {original_count} â†’ {len(cluster_perfumes)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    request_dict["season_tags"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered
                logger.info(f"  ê³„ì ˆ '{request_dict['season_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in cluster_perfumes.columns:
            time_filtered = cluster_perfumes[
                cluster_perfumes['time_tags'].str.contains(
                    request_dict["time_tags"], na=False, case=False
                )
            ]
            if not time_filtered.empty:
                cluster_perfumes = time_filtered
                logger.info(f"  ì‹œê°„ '{request_dict['time_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # AI ì‹ ë¢°ë„ ê¸°ë°˜ ì ìˆ˜ í• ë‹¹
        cluster_perfumes = cluster_perfumes.copy()

        # í´ëŸ¬ìŠ¤í„° ì‹ ë¢°ë„ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ ì‚¬ìš©
        base_score = confidence * 0.8  # AI ì‹ ë¢°ë„ì˜ 80%ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ

        scores = []
        for idx, (_, row) in enumerate(cluster_perfumes.iterrows()):
            score = base_score

            # ì¶”ê°€ ì¡°ê±´ ì¼ì¹˜ ë³´ë„ˆìŠ¤
            if 'season_tags' in row and request_dict["season_tags"].lower() in str(row['season_tags']).lower():
                score += 0.08
            if 'time_tags' in row and request_dict["time_tags"].lower() in str(row['time_tags']).lower():
                score += 0.06
            if 'desired_impression' in row and request_dict["desired_impression"].lower() in str(
                    row['desired_impression']).lower():
                score += 0.05

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']
            if any(popular in str(row.get('brand', '')) for popular in popular_brands):
                score += 0.03

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜ (ì•ìª½ì¼ìˆ˜ë¡ ì•½ê°„ ë†’ì€ ì ìˆ˜)
            position_bonus = (len(cluster_perfumes) - idx) / len(cluster_perfumes) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.03, 0.05)

            # ì •ê·œí™” (0.4 ~ 0.95 ë²”ìœ„)
            score = max(0.4, min(0.95, score))
            scores.append(score)

        cluster_perfumes['score'] = scores

        # ìƒìœ„ 10ê°œ ì„ íƒ
        top_10 = cluster_perfumes.nlargest(10, 'score')

        logger.info(f"âœ… AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì™„ë£Œ: {len(top_10)}ê°œ")
        if not top_10.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_10['score'].min():.3f} ~ {top_10['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_10['score'].mean():.3f}")

        return top_10

    except Exception as e:
        logger.error(f"âŒ AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 10. ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ (ê¸°ì¡´ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def rule_based_recommendation(request_data: dict, top_k: int = 10) -> List[dict]:
    """ë£° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ (AI ëª¨ë¸ ëŒ€ì²´)"""
    logger.info("ğŸ¯ ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘")

    try:
        # í•„í„°ë§ ì¡°ê±´
        gender = request_data["gender"]
        season_tags = request_data["season_tags"]
        time_tags = request_data["time_tags"]
        desired_impression = request_data["desired_impression"]
        activity = request_data["activity"]
        weather = request_data["weather"]

        logger.info(f"ğŸ” í•„í„°ë§ ì¡°ê±´: gender={gender}, season_tags={season_tags}, time_tags={time_tags}, "
                    f"desired_impression={desired_impression}, activity={activity}, weather={weather}")

        # ì„±ë³„ ë§¤í•‘
        gender_map = {"women": "women", "men": "men", "unisex": "unisex"}
        mapped_gender = gender_map.get(gender, "unisex")

        # 1ë‹¨ê³„: ê¸°ë³¸ í•„í„°ë§
        candidates = df.copy()
        original_count = len(candidates)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in df.columns:
            gender_filtered = candidates[candidates['gender'] == mapped_gender]
            if not gender_filtered.empty:
                candidates = gender_filtered
                logger.info(f"  ì„±ë³„ '{mapped_gender}' í•„í„°ë§: {original_count} â†’ {len(candidates)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in df.columns:
            season_filtered = candidates[
                candidates['season_tags'].str.contains(season_tags, na=False, case=False)
            ]
            if not season_filtered.empty:
                candidates = season_filtered
                logger.info(f"  ê³„ì ˆ '{season_tags}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in df.columns:
            time_filtered = candidates[
                candidates['time_tags'].str.contains(time_tags, na=False, case=False)
            ]
            if not time_filtered.empty:
                candidates = time_filtered
                logger.info(f"  ì‹œê°„ '{time_tags}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì¸ìƒ í•„í„°ë§
        if 'desired_impression' in df.columns:
            impression_filtered = candidates[
                candidates['desired_impression'].str.contains(desired_impression, na=False, case=False)
            ]
            if not impression_filtered.empty:
                candidates = impression_filtered
                logger.info(f"  ì¸ìƒ '{desired_impression}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # í™œë™ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'activity' in df.columns:
            activity_filtered = candidates[
                candidates['activity'].str.contains(activity, na=False, case=False)
            ]
            if not activity_filtered.empty:
                candidates = activity_filtered
                logger.info(f"  í™œë™ '{activity}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ë‚ ì”¨ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'weather' in df.columns and weather != 'any':
            weather_filtered = candidates[
                candidates['weather'].str.contains(weather, na=False, case=False)
            ]
            if not weather_filtered.empty:
                candidates = weather_filtered
                logger.info(f"  ë‚ ì”¨ '{weather}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # 2ë‹¨ê³„: ìŠ¤ì½”ì–´ë§
        if candidates.empty:
            logger.warning("âš ï¸ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ì—ì„œ ë‹¤ì–‘ì„± ê¸°ë°˜ ì„ íƒ")
            # ë‹¤ì–‘í•œ ë¸Œëœë“œì—ì„œ ê³ ë¥´ê²Œ ì„ íƒ
            if 'brand' in df.columns:
                unique_brands = df['brand'].unique()
                candidates_list = []
                per_brand = max(1, top_k // len(unique_brands))

                for brand in unique_brands:
                    brand_perfumes = df[df['brand'] == brand].sample(
                        n=min(per_brand, len(df[df['brand'] == brand])),
                        random_state=42
                    )
                    candidates_list.append(brand_perfumes)

                candidates = pd.concat(candidates_list).head(top_k)
            else:
                candidates = df.sample(n=min(top_k, len(df)), random_state=42)

        # ì ìˆ˜ ê³„ì‚°
        candidates = candidates.copy()
        scores = []

        # ë¸Œëœë“œë³„ ê°€ì¤‘ì¹˜ (ì¸ê¸° ë¸Œëœë“œ ì˜ˆì‹œ)
        popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']

        for idx, (_, row) in enumerate(candidates.iterrows()):
            score = 0.3  # ê¸°ë³¸ ì ìˆ˜

            # 1. ì¡°ê±´ ì¼ì¹˜ë„ ì ìˆ˜
            brand_name = str(row.get('brand', ''))
            notes_text = str(row.get('notes', ''))

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            if any(popular in brand_name for popular in popular_brands):
                score += 0.15

            # ë…¸íŠ¸ ë³µì¡ì„± (ë” ë§ì€ ë…¸íŠ¸ = ë” ë³µì¡í•œ í–¥ìˆ˜)
            note_count = len([n.strip() for n in notes_text.split(',') if n.strip()])
            if note_count >= 8:
                score += 0.10
            elif note_count >= 5:
                score += 0.05

            # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì •í™•ë„
            impression_match_count = 0
            if 'desired_impression' in row:
                impressions = str(row['desired_impression']).lower().split(',')
                impression_match_count = sum(1 for imp in impressions if desired_impression.lower() in imp.strip())
                score += impression_match_count * 0.08

            # ê³„ì ˆ/ì‹œê°„ ë§¤ì¹­ ì •í™•ë„
            if 'season_tags' in row:
                season_tags_data = str(row['season_tags']).lower()
                if season_tags.lower() in season_tags_data:
                    score += 0.12 if f' {season_tags.lower()} ' in f' {season_tags_data} ' else 0.08

            if 'time_tags' in row:
                time_tags_data = str(row['time_tags']).lower()
                if time_tags.lower() in time_tags_data:
                    score += 0.12 if f' {time_tags.lower()} ' in f' {time_tags_data} ' else 0.08

            # í™œë™ ë§¤ì¹­
            if 'activity' in row and activity.lower() in str(row['activity']).lower():
                score += 0.08

            # ë‚ ì”¨ ë§¤ì¹­
            if 'weather' in row and weather != 'any':
                if weather.lower() in str(row['weather']).lower():
                    score += 0.06
            elif weather == 'any':
                score += 0.03

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜
            position_bonus = (len(candidates) - idx) / len(candidates) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.15, 0.15)

            # ì ìˆ˜ ì •ê·œí™” (0.2 ~ 0.95 ë²”ìœ„)
            score = max(0.2, min(0.95, score))
            scores.append(score)

        candidates['score'] = scores

        # ìƒìœ„ Kê°œ ì„ íƒ
        top_candidates = candidates.nlargest(top_k, 'score')

        logger.info(f"âœ… ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ: ìµœì¢… {len(top_candidates)}ê°œ ì„ íƒ")
        if not top_candidates.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_candidates['score'].min():.3f} ~ {top_candidates['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_candidates['score'].mean():.3f}")

        return top_candidates.to_dict('records')

    except Exception as e:
        logger.error(f"âŒ ë£° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {e}")
        # ìµœì¢… ì•ˆì „ì¥ì¹˜: ì™„ì „ ëœë¤ ì¶”ì²œ
        logger.info("ğŸ² ì™„ì „ ëœë¤ ì¶”ì²œìœ¼ë¡œ ëŒ€ì²´")
        random_sample = df.sample(n=min(top_k, len(df)), random_state=42)
        random_sample = random_sample.copy()
        random_sample['score'] = [random.uniform(0.4, 0.7) for _ in range(len(random_sample))]
        return random_sample.to_dict('records')


# â”€â”€â”€ 11. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_emotion_text(row):
    """ê°ì • ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # 1ìˆœìœ„: desired_impression
    if 'desired_impression' in df.columns and pd.notna(row.get('desired_impression')):
        return str(row['desired_impression'])

    # 2ìˆœìœ„: emotion_clusterë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if 'emotion_cluster' in df.columns and pd.notna(row.get('emotion_cluster')):
        cluster_id = int(row['emotion_cluster']) if str(row['emotion_cluster']).isdigit() else 0
        return EMOTION_CLUSTER_MAP.get(cluster_id, "ê· í˜•ì¡íŒ")

    return "ë‹¤ì–‘í•œ ê°ì •"


def get_recommendation_reason(score: float, method: str) -> str:
    """ì ìˆ˜ì™€ ë°©ë²•ì— ë”°ë¥¸ ì¶”ì²œ ì´ìœ  ìƒì„±"""

    if method.startswith("AI"):
        if score >= 0.9:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì˜ ì™„ë²½í•œ í–¥ìˆ˜ë¼ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤!"
        elif score >= 0.8:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì—ê²Œ ì˜ ë§ì„ ê²ƒì´ë¼ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤."
        elif score >= 0.6:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒˆë¡œìš´ ì‹œë„í•´ë³¼ ë§Œí•œ í–¥ìˆ˜ë¡œ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤."
        else:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒ‰ë‹¤ë¥¸ ë§¤ë ¥ì„ ì œì•ˆí•©ë‹ˆë‹¤."
    else:
        # ë£° ê¸°ë°˜ - ë” ë‹¤ì–‘í•œ ë©”ì‹œì§€
        if score >= 0.9:
            return f"ğŸ¯ ì¡°ê±´ ì™„ë²½ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ì´ë³´ë‹¤ ì™„ë²½í•  ìˆœ ì—†ì–´ìš”!"
        elif score >= 0.8:
            return f"â­ ì¡°ê±´ ë†’ì€ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ê°•ë ¥ ì¶”ì²œ!"
        elif score >= 0.6:
            return f"âœ¨ ì¡°ê±´ ì í•© (ì¼ì¹˜ë„ {score:.1%}) - ê³ ë ¤í•´ë³´ì„¸ìš”!"
        elif score >= 0.4:
            return f"ğŸ” ë¶€ë¶„ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ìƒˆë¡œìš´ ë°œê²¬ì´ ë  ìˆ˜ë„!"
        else:
            return f"ğŸ² ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ì œì•ˆ (ì¼ì¹˜ë„ {score:.1%}) - ë„ì „í•´ë³´ì„¸ìš”!"


# â”€â”€â”€ 12. ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ ì •ì˜ (í•˜ìœ„ í˜¸í™˜ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class PerfumeRecommendItem(BaseModel):
    name: str
    brand: str
    image_url: str
    notes: str
    emotions: str
    reason: str
    score: Optional[float] = None
    method: Optional[str] = None


# â”€â”€â”€ 13. ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/perfumes", tags=["Perfume"])

# ì‹œì‘ ì‹œ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
logger.info("ğŸš€ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
check_model_availability()
if _model_available:
    logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
else:
    logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œ ë™ì‘")
logger.info("âœ… ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")


# â”€â”€â”€ 14. ğŸ†• ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post(
    "/recommend-cluster",
    response_model=ClusterRecommendResponse,
    summary="í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ (ìƒˆë¡œìš´ ì‘ë‹µ í˜•íƒœ)",
    description=(
            "ğŸ†• **ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ API**\n\n"
            "ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ëª¨ë¸ì´ ê°ì • í´ëŸ¬ìŠ¤í„°ë¥¼ ì˜ˆì¸¡í•˜ê³ ,\n"
            "í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ì •ë³´ì™€ ì¶”ì²œ í–¥ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n\n"
            "**ğŸ¤– ì‘ë‹µ í˜•íƒœ:**\n"
            "- `cluster`: ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤ (0-5)\n"
            "- `description`: í´ëŸ¬ìŠ¤í„° ì„¤ëª… (ê°ì • íŠ¹ì„±)\n"
            "- `proba`: 6ê°œ í´ëŸ¬ìŠ¤í„°ë³„ softmax í™•ë¥  ë°°ì—´\n"
            "- `recommended_notes`: í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ìƒìœ„ 15ê°œ ì¸ê¸° ë…¸íŠ¸\n"
            "- `selected_idx`: ì¶”ì²œ í–¥ìˆ˜ë“¤ì˜ ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ 10ê°œ\n\n"
            "**ğŸ“‹ ì…ë ¥ íŒŒë¼ë¯¸í„°:**\n"
            "- encoder.pklê³¼ ì™„ì „ í˜¸í™˜ë˜ëŠ” 6ê°œ íŠ¹ì„± ì…ë ¥\n"
            "- AI ëª¨ë¸ ìš°ì„ , ì‹¤íŒ¨ ì‹œ ë£° ê¸°ë°˜ í´ë°±\n\n"
            "**âœ¨ í™œìš© ë°©ë²•:**\n"
            "- í´ë¼ì´ì–¸íŠ¸ì—ì„œ `selected_idx`ë¡œ í•´ë‹¹ í–¥ìˆ˜ë“¤ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ\n"
            "- `proba` ì •ë³´ë¡œ ì‚¬ìš©ì ì„ í˜¸ë„ ë¶„ì„ ê°€ëŠ¥\n"
            "- `recommended_notes`ë¡œ í–¥ìˆ˜ ë…¸íŠ¸ ê¸°ë°˜ UI êµ¬ì„± ê°€ëŠ¥"
    )
)
def recommend_cluster_based(request: RecommendRequest):
    request_start_time = datetime.now()
    logger.info(f"ğŸ†• í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­: {request}")

    # âœ… ì…ë ¥ ê²€ì¦
    if not validate_request_categories(request):
        logger.error("âŒ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ê°’ ì…ë ¥")
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ ê°’ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ê°’: {SUPPORTED_CATEGORIES}"
        )

    # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    request_dict = request.dict()

    try:
        # AI ëª¨ë¸ ì‹œë„
        if _model_available:
            try:
                logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ë¡œ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì‹œë„")
                result = predict_cluster_recommendation(request_dict)

                # ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                total_processing_time = (datetime.now() - request_start_time).total_seconds()
                result["metadata"]["total_processing_time_seconds"] = round(total_processing_time, 3)

                logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì„±ê³µ (í´ëŸ¬ìŠ¤í„°: {result['cluster']}, ì†Œìš”ì‹œê°„: {total_processing_time:.3f}ì´ˆ)")

                return ClusterRecommendResponse(**result)

            except Exception as e:
                logger.warning(f"âš ï¸ AI ëª¨ë¸ í´ëŸ¬ìŠ¤í„° ì¶”ì²œ ì‹¤íŒ¨: {e}")
                # ë£° ê¸°ë°˜ìœ¼ë¡œ í´ë°±í•˜ë˜, í´ëŸ¬ìŠ¤í„° í˜•íƒœë¡œ ë³€í™˜
                logger.info("ğŸ“‹ ë£° ê¸°ë°˜ìœ¼ë¡œ í´ë°±í•˜ì—¬ í´ëŸ¬ìŠ¤í„° í˜•íƒœ ì‘ë‹µ ìƒì„±")

        else:
            logger.info("ğŸ“‹ AI ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€, ë£° ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° í˜•íƒœ ì‘ë‹µ ìƒì„±")

        # ë£° ê¸°ë°˜ í´ë°± - í´ëŸ¬ìŠ¤í„° í˜•íƒœë¡œ ë³€í™˜
        rule_results = rule_based_recommendation(request_dict, 10)
        rule_df = pd.DataFrame(rule_results)

        # ê°€ìƒì˜ í´ëŸ¬ìŠ¤í„° ì •ë³´ ìƒì„± (ë£° ê¸°ë°˜ì´ë¯€ë¡œ)
        fallback_cluster = 2  # ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° (ìš°ì•„í•¨, ì¹œê·¼í•¨)
        fallback_proba = [0.1, 0.15, 0.4, 0.15, 0.1, 0.1]  # ê°€ìƒ í™•ë¥ 

        # ë£° ê¸°ë°˜ ê²°ê³¼ì—ì„œ ë…¸íŠ¸ ì¶”ì¶œ
        fallback_notes = get_top_notes_from_cluster(rule_df, top_k=15)

        # ë£° ê¸°ë°˜ ê²°ê³¼ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        fallback_indices = get_perfume_indices(rule_df, top_k=10)

        total_processing_time = (datetime.now() - request_start_time).total_seconds()

        fallback_result = {
            "cluster": fallback_cluster,
            "description": EMOTION_CLUSTER_MAP[fallback_cluster] + " (ë£° ê¸°ë°˜ ì¶”ì •)",
            "proba": fallback_proba,
            "recommended_notes": fallback_notes,
            "selected_idx": fallback_indices,
            "metadata": {
                "processing_time_seconds": round(total_processing_time, 3),
                "total_cluster_perfumes": len(rule_df),
                "confidence": 0.4,  # ë£° ê¸°ë°˜ì´ë¯€ë¡œ ë‚®ì€ ì‹ ë¢°ë„
                "method": "ë£° ê¸°ë°˜ (AI ëª¨ë¸ ëŒ€ì²´)",
                "fallback_used": True,
                "filters_applied": {
                    "gender": request_dict["gender"],
                    "season": request_dict["season_tags"],
                    "time": request_dict["time_tags"]
                }
            }
        }

        logger.info(f"âœ… ë£° ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° í˜•íƒœ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {total_processing_time:.3f}ì´ˆ)")

        return ClusterRecommendResponse(**fallback_result)

    except Exception as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# â”€â”€â”€ 15. ê¸°ì¡´ APIë“¤ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post(
    "/recommend",
    response_model=List[PerfumeRecommendItem],
    summary="í–¥ìˆ˜ ì¶”ì²œ (ê¸°ì¡´ ë°©ì‹, í•˜ìœ„ í˜¸í™˜ì„±)",
    description=(
            "**ğŸ”„ ê¸°ì¡´ í–¥ìˆ˜ ì¶”ì²œ API (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)**\n\n"
            "ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n\n"
            "**ğŸ¤– ì¶”ì²œ ë°©ì‹:**\n"
            "1. **AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸**: 6ê°œ ì…ë ¥ â†’ 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ â†’ í•´ë‹¹ í´ëŸ¬ìŠ¤í„° í–¥ìˆ˜ ì¶”ì²œ\n"
            "2. **ë£° ê¸°ë°˜ Fallback**: ì¡°ê±´ë¶€ í•„í„°ë§ + ìŠ¤ì½”ì–´ë§ (ëª¨ë¸ì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°)\n"
            "3. **ë‹¤ì–‘ì„± ë³´ì¥**: ë¸Œëœë“œë³„ ê· í˜• ì¡íŒ ì¶”ì²œ\n\n"
            "**âš ï¸ ê¶Œì¥ì‚¬í•­:**\n"
            "- ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ëŠ” `/recommend-cluster` API ì‚¬ìš© ê¶Œì¥\n"
            "- ë” êµ¬ì¡°í™”ëœ ì‘ë‹µê³¼ í´ëŸ¬ìŠ¤í„° ì •ë³´ ì œê³µ\n"
            "- ì´ APIëŠ” ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€"
    )
)
def recommend_perfumes(request: RecommendRequest):
    request_start_time = datetime.now()
    logger.info(f"ğŸ¯ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­ ì‹œì‘ (ê¸°ì¡´ ë°©ì‹): {request}")

    # âœ… ì…ë ¥ ê²€ì¦
    if not validate_request_categories(request):
        logger.error("âŒ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ê°’ ì…ë ¥")
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ ê°’ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ê°’: {SUPPORTED_CATEGORIES}"
        )

    # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    request_dict = request.dict()

    method_used = "ì•Œ ìˆ˜ ì—†ìŒ"

    # 1) AI ëª¨ë¸ ì‹œë„
    if _model_available:
        model_start_time = datetime.now()
        try:
            logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹œë„")

            # ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ë¡œ ì¶”ì²œ
            top_10 = predict_with_emotion_cluster_model(request_dict)
            method_used = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"

            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.info(f"âœ… AI ëª¨ë¸ ì¶”ì²œ ì„±ê³µ (ë°©ë²•: {method_used}, ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ)")

        except Exception as e:
            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.warning(f"âš ï¸ AI ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ): {e}")
            logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ ì „í™˜")

            rule_start_time = datetime.now()
            rule_results = rule_based_recommendation(request_dict, 10)
            top_10 = pd.DataFrame(rule_results)
            rule_time = (datetime.now() - rule_start_time).total_seconds()
            method_used = "ë£° ê¸°ë°˜ (AI ëª¨ë¸ ì‹¤íŒ¨)"
            logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")
    else:
        logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì‚¬ìš© (ëª¨ë¸ íŒŒì¼ í¬ê¸° ë¶€ì¡±)")
        rule_start_time = datetime.now()
        rule_results = rule_based_recommendation(request_dict, 10)
        top_10 = pd.DataFrame(rule_results)
        rule_time = (datetime.now() - rule_start_time).total_seconds()
        method_used = "ë£° ê¸°ë°˜ (ëª¨ë¸ í¬ê¸° ë¶€ì¡±)"
        logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")

    # 2) ê²°ê³¼ ê°€ê³µ
    response_list: List[PerfumeRecommendItem] = []
    for idx, (_, row) in enumerate(top_10.iterrows(), 1):
        emotions_text = get_emotion_text(row)
        score = float(row.get('score', 0.0))

        # ì¶”ì²œ ì´ìœ  ìƒì„±
        reason = get_recommendation_reason(score, method_used)

        response_list.append(
            PerfumeRecommendItem(
                name=str(row["name"]),
                brand=str(row["brand"]),
                image_url=str(row["image_url"]),
                notes=str(row["notes"]),
                emotions=emotions_text,
                reason=reason,
                score=score,
                method=method_used
            )
        )

    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    total_processing_time = (datetime.now() - request_start_time).total_seconds()

    logger.info(f"âœ… í–¥ìˆ˜ ì¶”ì²œ ì™„ë£Œ: {len(response_list)}ê°œ ({method_used})")
    logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.3f}ì´ˆ")
    if response_list:
        logger.info(
            f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {min(item.score for item in response_list):.3f} ~ {max(item.score for item in response_list):.3f}")
        logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {sum(item.score for item in response_list) / len(response_list):.3f}")

    return response_list