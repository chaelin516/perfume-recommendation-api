import os
import pickle
import logging
import random
import sys
import numpy as np
from datetime import datetime
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Literal, Optional, Dict, Any
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from collections import Counter

# âœ… schemas/recommend.pyì—ì„œ ìŠ¤í‚¤ë§ˆ ì„í¬íŠ¸
from schemas.recommend import (
    RecommendRequest,
    RecommendedPerfume,
    RecommendResponse,
    ClusterRecommendResponse,  # ğŸ†• ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ
    SUPPORTED_CATEGORIES,
    EMOTION_CLUSTER_DESCRIPTIONS,
    validate_request_categories,
    map_single_to_combined_impression
)

# â”€â”€â”€ ë¡œê±° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("recommend_router")

# â”€â”€â”€ 1. perfume_final_dataset.csv ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_PATH = os.path.join(os.path.dirname(__file__), "../data/perfume_final_dataset.csv")
try:
    df = pd.read_csv(DATA_PATH)
    df.fillna("", inplace=True)
    logger.info(f"âœ… Perfume dataset loaded: {df.shape[0]} rows")
    logger.info(f"ğŸ“‹ Available columns: {list(df.columns)}")

    # âœ… ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    required_columns = ['name', 'brand', 'image_url', 'notes']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        logger.error(f"âŒ Missing required columns: {missing_columns}")
        raise RuntimeError(f"Missing required columns: {missing_columns}")

    # âœ… emotion ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
    if 'desired_impression' in df.columns:
        logger.info("âœ… Using 'desired_impression' column for emotion data")
    if 'emotion_cluster' in df.columns:
        logger.info("âœ… Using 'emotion_cluster' column for cluster data")
        # emotion_cluster ì»¬ëŸ¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
        df['emotion_cluster'] = pd.to_numeric(df['emotion_cluster'], errors='coerce').fillna(0).astype(int)
        logger.info(f"ğŸ“Š Emotion clusters: {sorted(df['emotion_cluster'].unique())}")
    else:
        logger.warning("âš ï¸ No emotion_cluster column found")

    # ğŸ“Š ë°ì´í„° ìƒ˜í”Œ ë¡œê·¸
    if len(df) > 0:
        sample_row = df.iloc[0]
        logger.info(f"ğŸ“ Sample data: {sample_row['name']} by {sample_row['brand']}")

except Exception as e:
    logger.error(f"âŒ perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    raise RuntimeError(f"perfume_final_dataset.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# â”€â”€â”€ 2. ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "../models/final_model.keras")
ENCODER_PATH = os.path.join(BASE_DIR, "../models/encoder.pkl")

# â”€â”€â”€ 3. ì „ì—­ ë³€ìˆ˜ ë° ìƒíƒœ ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_model = None
_encoder = None
_model_available = False
_fallback_encoder = None

# â”€â”€â”€ 4. ê°ì • í´ëŸ¬ìŠ¤í„° ë§¤í•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMOTION_CLUSTER_MAP = {
    0: "ì°¨ë¶„í•œ, í¸ì•ˆí•œ",
    1: "ìì‹ ê°, ì‹ ì„ í•¨",
    2: "ìš°ì•„í•¨, ì¹œê·¼í•¨",
    3: "ìˆœìˆ˜í•¨, ì¹œê·¼í•¨",
    4: "ì‹ ë¹„ë¡œìš´, ë§¤ë ¥ì ",
    5: "í™œê¸°ì°¬, ì—ë„ˆì§€"
}

# âœ… encoder.pklê³¼ í˜¸í™˜ë˜ëŠ” ì¹´í…Œê³ ë¦¬ ë§¤í•‘
API_TO_MODEL_MAPPING = {
    "gender": {
        "men": "men",
        "unisex": "unisex",
        "women": "women"
    },
    "season_tags": {
        "fall": "fall",
        "spring": "spring",
        "summer": "summer",
        "winter": "winter"
    },
    "time_tags": {
        "day": "day",
        "night": "night"
    },
    "desired_impression": {
        "confident, fresh": "confident, fresh",
        "confident, mysterious": "confident, mysterious",
        "elegant, friendly": "elegant, friendly",
        "pure, friendly": "pure, friendly"
    },
    "activity": {
        "casual": "casual",
        "date": "date",
        "work": "work"
    },
    "weather": {
        "any": "any",
        "cold": "cold",
        "hot": "hot",
        "rainy": "rainy"
    }
}


# â”€â”€â”€ 5. ğŸ†• ë…¸íŠ¸ ë¶„ì„ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_notes_from_string(notes_str: str) -> List[str]:
    """
    ë…¸íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ê°œë³„ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

    Args:
        notes_str: "bergamot, jasmine, white musk, amber" í˜•íƒœì˜ ë¬¸ìì—´

    Returns:
        ê°œë³„ ë…¸íŠ¸ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
    """
    if not notes_str or pd.isna(notes_str):
        return []

    # ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°
    notes = [note.strip().lower() for note in str(notes_str).split(',')]

    # ë¹ˆ ë¬¸ìì—´ ì œê±°
    notes = [note for note in notes if note and note != '']

    return notes


def get_top_notes_from_cluster(cluster_perfumes: pd.DataFrame, top_k: int = 15) -> List[str]:
    """
    í´ëŸ¬ìŠ¤í„°ì— ì†í•œ í–¥ìˆ˜ë“¤ì˜ ë…¸íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìƒìœ„ Kê°œ ë…¸íŠ¸ ë°˜í™˜

    Args:
        cluster_perfumes: í´ëŸ¬ìŠ¤í„°ì— ì†í•œ í–¥ìˆ˜ë“¤ì˜ DataFrame
        top_k: ë°˜í™˜í•  ìƒìœ„ ë…¸íŠ¸ ê°œìˆ˜

    Returns:
        ë¹ˆë„ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìƒìœ„ Kê°œ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    all_notes = []

    for _, row in cluster_perfumes.iterrows():
        notes = parse_notes_from_string(row.get('notes', ''))
        all_notes.extend(notes)

    if not all_notes:
        # ë…¸íŠ¸ê°€ ì—†ìœ¼ë©´ ì¼ë°˜ì ì¸ í–¥ìˆ˜ ë…¸íŠ¸ ë°˜í™˜
        return [
                   "bergamot", "jasmine", "rose", "vanilla", "sandalwood",
                   "cedar", "musk", "amber", "lavender", "citrus",
                   "woody", "floral", "fresh", "sweet", "spicy"
               ][:top_k]

    # ë¹ˆë„ ê³„ì‚° ë° ìƒìœ„ Kê°œ ì„ íƒ
    note_counter = Counter(all_notes)
    top_notes = [note for note, count in note_counter.most_common(top_k)]

    logger.info(f"ğŸ“Š í´ëŸ¬ìŠ¤í„° ë…¸íŠ¸ ë¶„ì„: ì´ {len(all_notes)}ê°œ ë…¸íŠ¸ â†’ ìƒìœ„ {len(top_notes)}ê°œ ì„ íƒ")
    logger.info(f"ğŸ“Š ìƒìœ„ 5ê°œ ë…¸íŠ¸: {top_notes[:5]}")

    return top_notes


def get_perfume_indices(cluster_perfumes: pd.DataFrame, top_k: int = 10) -> List[int]:
    """
    ì¶”ì²œ í–¥ìˆ˜ë“¤ì˜ ì›ë³¸ DataFrame ì¸ë±ìŠ¤ ë°˜í™˜

    Args:
        cluster_perfumes: í´ëŸ¬ìŠ¤í„°ì— ì†í•œ í–¥ìˆ˜ë“¤ì˜ DataFrame
        top_k: ë°˜í™˜í•  ì¸ë±ìŠ¤ ê°œìˆ˜

    Returns:
        ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œì˜ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    # ì ìˆ˜ê°€ ìˆìœ¼ë©´ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬, ì—†ìœ¼ë©´ ì›ë³¸ ìˆœì„œ ìœ ì§€
    if 'score' in cluster_perfumes.columns:
        sorted_perfumes = cluster_perfumes.nlargest(top_k, 'score')
    else:
        sorted_perfumes = cluster_perfumes.head(top_k)

    indices = sorted_perfumes.index.tolist()

    logger.info(f"ğŸ“‹ ì„ íƒëœ í–¥ìˆ˜ ì¸ë±ìŠ¤: {indices}")

    return indices


# â”€â”€â”€ 6. ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ (31KB ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_model_availability():
    """ëª¨ë¸ íŒŒì¼ë“¤ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤."""
    global _model_available

    logger.info("ğŸ” ëª¨ë¸ íŒŒì¼ ê°€ìš©ì„± í™•ì¸ ì¤‘...")

    try:
        # íŒŒì¼ ì¡´ì¬ ë° í¬ê¸° í™•ì¸
        model_exists = os.path.exists(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH)

        model_valid = False
        encoder_valid = False

        if model_exists:
            model_size = os.path.getsize(MODEL_PATH)
            # âœ… ì‹¤ì œ ëª¨ë¸ íŒŒì¼ í¬ê¸°ì— ë§ê²Œ ìˆ˜ì •: 31KB ëª¨ë¸ì´ë¯€ë¡œ 10KB ì´ìƒìœ¼ë¡œ ì²´í¬
            model_valid = model_size > 10000  # 10KB ì´ìƒ (ê¸°ì¡´: 100KB)
            logger.info(f"ğŸ“„ ëª¨ë¸ íŒŒì¼: {model_size:,}B ({model_size / 1024:.1f}KB) {'âœ…' if model_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")

        if encoder_exists:
            encoder_size = os.path.getsize(ENCODER_PATH)
            # âœ… ì¸ì½”ë”ëŠ” 1KBì´ë¯€ë¡œ 500B ì´ìƒìœ¼ë¡œ ì²´í¬ (ê¸°ì¡´: 100B)
            encoder_valid = encoder_size > 500  # 500B ì´ìƒ
            logger.info(f"ğŸ“„ ì¸ì½”ë” íŒŒì¼: {encoder_size:,}B ({encoder_size}B) {'âœ…' if encoder_valid else 'âŒ'}")
        else:
            logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")

        _model_available = model_valid and encoder_valid

        logger.info(f"ğŸ¤– ëª¨ë¸ ê°€ìš©ì„±: {'âœ… ì‚¬ìš© ê°€ëŠ¥' if _model_available else 'âŒ ì‚¬ìš© ë¶ˆê°€'}")

        if _model_available:
            logger.info(f"âœ¨ ëª¨ë¸ ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ - í¬ê¸°: {model_size / 1024:.1f}KB")
        else:
            if not model_valid:
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ í¬ê¸° ë¶€ì¡±: {model_size}B (ìµœì†Œ 10KB í•„ìš”)")
            if not encoder_valid:
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ í¬ê¸° ë¶€ì¡±: {encoder_size}B (ìµœì†Œ 500B í•„ìš”)")

        return _model_available

    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        _model_available = False
        return False


# â”€â”€â”€ 7. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ë“¤ (Keras 3.8.0 í˜¸í™˜ ë° í¬ê¸° ì²´í¬ ìˆ˜ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_model():
    """Keras ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _model

    if _model is None:
        try:
            if not os.path.exists(MODEL_PATH):
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
                return None

            # âœ… íŒŒì¼ í¬ê¸° í™•ì¸ - 31KB ëª¨ë¸ì— ë§ê²Œ ìˆ˜ì •
            model_size = os.path.getsize(MODEL_PATH)
            if model_size < 10000:  # 10KB ë¯¸ë§Œ (ê¸°ì¡´: 100KB)
                logger.warning(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {model_size} bytes ({model_size / 1024:.1f}KB)")
                return None

            logger.info(f"ğŸ“¦ ëª¨ë¸ íŒŒì¼ í¬ê¸° í™•ì¸ ì™„ë£Œ: {model_size:,}B ({model_size / 1024:.1f}KB)")

            # TensorFlow ë™ì  ì„í¬íŠ¸ ë° Keras 3.x í˜¸í™˜ì„± ê³ ë ¤
            try:
                tf_start = datetime.now()

                # âœ… Keras 3.x ì§€ì›ì„ ìœ„í•œ ì„í¬íŠ¸ ë°©ì‹ ê°œì„ 
                try:
                    # Keras 3.x ë°©ì‹ ì‹œë„
                    import tensorflow as tf
                    from tensorflow import keras
                    load_model = keras.models.load_model
                    logger.info(f"ğŸ“¦ TensorFlow {tf.__version__} + Keras 3.x ìŠ¤íƒ€ì¼ ë¡œë”©")
                except:
                    # ê¸°ì¡´ ë°©ì‹ í´ë°±
                    from tensorflow.keras.models import load_model
                    logger.info(f"ğŸ“¦ TensorFlow ê¸°ì¡´ ìŠ¤íƒ€ì¼ ë¡œë”©")

                tf_load_time = (datetime.now() - tf_start).total_seconds()

                logger.info(f"ğŸ“¦ Keras ëª¨ë¸ ë¡œë”© ì‹œë„ (TF ë¡œë”©: {tf_load_time:.3f}ì´ˆ)")
                logger.info(f"ğŸ“Š ì˜ˆìƒ ëª¨ë¸ êµ¬ì¡°: ì…ë ¥(6) â†’ Dense(64,relu) â†’ Dense(6,softmax)")

                model_start = datetime.now()

                # âœ… compile=Falseë¡œ ë¹ ë¥¸ ë¡œë”©, Keras 3.x í˜¸í™˜
                _model = load_model(MODEL_PATH, compile=False)
                model_load_time = (datetime.now() - model_start).total_seconds()

                # âœ… ëª¨ë¸ êµ¬ì¡° ê²€ì¦
                logger.info(f"âœ… Keras ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ëª¨ë¸ ë¡œë”©: {model_load_time:.3f}ì´ˆ)")
                logger.info(f"ğŸ“Š ì‹¤ì œ ëª¨ë¸ ì…ë ¥ shape: {_model.input_shape}")
                logger.info(f"ğŸ“Š ì‹¤ì œ ëª¨ë¸ ì¶œë ¥ shape: {_model.output_shape}")

                # âœ… ë ˆì´ì–´ ì •ë³´ ì¶œë ¥
                logger.info(f"ğŸ“Š ëª¨ë¸ ë ˆì´ì–´ ìˆ˜: {len(_model.layers)}")
                for i, layer in enumerate(_model.layers):
                    layer_info = f"  Layer {i + 1}: {layer.__class__.__name__}"
                    if hasattr(layer, 'units'):
                        layer_info += f" (units: {layer.units})"
                    if hasattr(layer, 'activation'):
                        layer_info += f" (activation: {layer.activation.__name__})"
                    logger.info(layer_info)

                # âœ… ì¶œë ¥ í¬ê¸° ê²€ì¦ (6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„°)
                output_size = _model.output_shape[-1]
                if output_size == 6:
                    logger.info("ğŸ¯ 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ ëª¨ë¸ë¡œ í™•ì¸ë¨")
                else:
                    logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì¶œë ¥ í¬ê¸°: {output_size} (ì˜ˆìƒ: 6)")

                # âœ… ì…ë ¥ í¬ê¸° ê²€ì¦ (6ê°œ íŠ¹ì„±)
                input_size = _model.input_shape[-1]
                if input_size == 6:
                    logger.info("ğŸ¯ 6ê°œ ì…ë ¥ íŠ¹ì„± ëª¨ë¸ë¡œ í™•ì¸ë¨")
                else:
                    logger.warning(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì…ë ¥ í¬ê¸°: {input_size} (ì˜ˆìƒ: 6)")

                # âœ… ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¶”ë¡  (ëª¨ë¸ ë™ì‘ í™•ì¸)
                try:
                    test_input = np.random.random((1, 6)).astype(np.float32)
                    test_output = _model.predict(test_input, verbose=0)
                    logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì„±ê³µ: ì…ë ¥{test_input.shape} â†’ ì¶œë ¥{test_output.shape}")
                    logger.info(f"ğŸ§ª ì¶œë ¥ í•©ê³„: {test_output.sum():.3f} (softmaxì´ë©´ ~1.0)")

                    # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° í™•ì¸
                    predicted_cluster = int(np.argmax(test_output[0]))
                    confidence = float(test_output[0][predicted_cluster])
                    logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡: í´ëŸ¬ìŠ¤í„° {predicted_cluster} (ì‹ ë¢°ë„: {confidence:.3f})")
                except Exception as test_e:
                    logger.warning(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì¶”ë¡  ì‹¤íŒ¨: {test_e}")

            except ImportError as e:
                logger.error(f"âŒ TensorFlowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
                return None
            except Exception as e:
                logger.error(f"âŒ Keras ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                logger.error(f"  íŒŒì¼ ê²½ë¡œ: {MODEL_PATH}")
                logger.error(f"  íŒŒì¼ í¬ê¸°: {model_size}B")
                return None

        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì¤‘ ì˜ˆì™¸: {e}")
            return None

    return _model


def get_saved_encoder():
    """ì €ì¥ëœ encoder.pklì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    global _encoder

    if _encoder is None:
        try:
            if not os.path.exists(ENCODER_PATH):
                logger.warning(f"âš ï¸ ì¸ì½”ë” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {ENCODER_PATH}")
                return None

            encoder_size = os.path.getsize(ENCODER_PATH)
            logger.info(f"ğŸ“¦ ì¸ì½”ë” ë¡œë”© ì‹œë„: {ENCODER_PATH} ({encoder_size}B)")

            with open(ENCODER_PATH, "rb") as f:
                _encoder = pickle.load(f)
            logger.info("âœ… encoder.pkl ë¡œë“œ ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ encoder.pkl ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    return _encoder


def get_fallback_encoder():
    """âœ… encoder.pklê³¼ í˜¸í™˜ë˜ëŠ” Fallback OrdinalEncoderë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    global _fallback_encoder

    if _fallback_encoder is None:
        try:
            logger.info("ğŸ”§ Fallback OrdinalEncoder ìƒì„± ì¤‘...")

            # âœ… encoder.pklê³¼ ë™ì¼í•œ ì¹´í…Œê³ ë¦¬ ì •ì˜
            from sklearn.preprocessing import OrdinalEncoder

            CATEGORIES = [
                ["men", "unisex", "women"],  # gender
                ["fall", "spring", "summer", "winter"],  # season_tags
                ["day", "night"],  # time_tags
                ["confident, fresh", "confident, mysterious", "elegant, friendly", "pure, friendly"],
                # desired_impression
                ["casual", "date", "work"],  # activity
                ["any", "cold", "hot", "rainy"]  # weather
            ]

            # âœ… OrdinalEncoder ìƒì„± (encoder.pklê³¼ ë™ì¼í•œ íƒ€ì…)
            _fallback_encoder = OrdinalEncoder(
                categories=CATEGORIES,
                handle_unknown="error"
            )

            # ë”ë¯¸ ë°ì´í„°ë¡œ fit (encoder.pklê³¼ ì™„ì „ ì¼ì¹˜)
            dummy_data = [
                ["men", "fall", "day", "confident, fresh", "casual", "any"],
                ["unisex", "spring", "night", "confident, mysterious", "date", "cold"],
                ["women", "summer", "day", "elegant, friendly", "work", "hot"],
                ["men", "winter", "night", "pure, friendly", "casual", "rainy"]
            ]

            _fallback_encoder.fit(dummy_data)
            logger.info("âœ… Fallback OrdinalEncoder ìƒì„± ë° í›ˆë ¨ ì™„ë£Œ")

            # âœ… ì¸ì½”ë” ê²€ì¦ í…ŒìŠ¤íŠ¸
            test_input = ["women", "spring", "day", "confident, fresh", "casual", "hot"]
            test_encoded = _fallback_encoder.transform([test_input])
            logger.info(f"ğŸ§ª Fallback ì¸ì½”ë” í…ŒìŠ¤íŠ¸ ì„±ê³µ: ì…ë ¥ 6ê°œ â†’ ì¶œë ¥ {test_encoded.shape[1]}ê°œ")

        except Exception as e:
            logger.error(f"âŒ Fallback encoder ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    return _fallback_encoder


def safe_transform_input(raw_features: list) -> np.ndarray:
    """âœ… ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ í•¨ìˆ˜"""
    try:
        # 1. ì €ì¥ëœ ì¸ì½”ë” ì‹œë„
        encoder = get_saved_encoder()
        if encoder:
            try:
                logger.info(f"ğŸ” ì €ì¥ëœ ì¸ì½”ë”ë¡œ ë³€í™˜ ì‹œë„: {raw_features}")
                transformed = encoder.transform([raw_features])
                logger.info(f"âœ… ì €ì¥ëœ ì¸ì½”ë” ë³€í™˜ ì„±ê³µ: {transformed.shape}")
                return transformed
            except Exception as e:
                logger.warning(f"âš ï¸ ì €ì¥ëœ ì¸ì½”ë” ì‹¤íŒ¨: {e}")

        # 2. Fallback ì¸ì½”ë” ì‹œë„
        fallback_encoder = get_fallback_encoder()
        if fallback_encoder:
            logger.info(f"ğŸ”„ Fallback ì¸ì½”ë”ë¡œ ë³€í™˜: {raw_features}")
            transformed = fallback_encoder.transform([raw_features])
            logger.info(f"âœ… Fallback ì¸ì½”ë” ë³€í™˜ ì„±ê³µ: {transformed.shape}")
            return transformed
        else:
            raise Exception("Fallback ì¸ì½”ë” ìƒì„± ì‹¤íŒ¨")

    except Exception as e:
        logger.error(f"âŒ ì…ë ¥ ë³€í™˜ ì™„ì „ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 8. ğŸ†• í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_cluster_recommendation(request_dict: dict) -> Dict[str, Any]:
    """
    âœ… í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ - ìƒˆë¡œìš´ ì‘ë‹µ í˜•íƒœ

    Returns:
        {
            "cluster": int,
            "description": str,
            "proba": List[float],
            "recommended_notes": List[str],
            "selected_idx": List[int]
        }
    """
    try:
        start_time = datetime.now()

        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # âœ… API ì…ë ¥ì„ ëª¨ë¸ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        raw_features = [
            request_dict["gender"],
            request_dict["season_tags"],
            request_dict["time_tags"],
            request_dict["desired_impression"],
            request_dict["activity"],
            request_dict["weather"]
        ]

        logger.info(f"ğŸ”® í´ëŸ¬ìŠ¤í„° ì¶”ì²œ ì…ë ¥ ë°ì´í„°: {raw_features}")

        # âœ… ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ ì‚¬ìš©
        x_input = safe_transform_input(raw_features)
        logger.info(f"ğŸ”® ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì‹œì‘ (ì…ë ¥ shape: {x_input.shape})")

        # ëª¨ë¸ ì˜ˆì¸¡ (ê°ì • í´ëŸ¬ìŠ¤í„°)
        preds = model.predict(x_input, verbose=0)  # (1, 6) ì¶œë ¥
        cluster_probabilities = preds[0]  # [0.1, 0.8, 0.05, 0.02, 0.02, 0.01]
        predicted_cluster = int(np.argmax(cluster_probabilities))  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„°
        confidence = float(cluster_probabilities[predicted_cluster])

        # í´ëŸ¬ìŠ¤í„° ì„¤ëª…
        cluster_description = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")

        logger.info(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°: {predicted_cluster} ({cluster_description}) - ì‹ ë¢°ë„: {confidence:.3f}")

        # ëª¨ë“  í´ëŸ¬ìŠ¤í„° í™•ë¥  ë¡œê·¸
        for i, prob in enumerate(cluster_probabilities):
            cluster_desc = EMOTION_CLUSTER_MAP.get(i, f"í´ëŸ¬ìŠ¤í„° {i}")
            logger.info(f"  í´ëŸ¬ìŠ¤í„° {i} ({cluster_desc}): {prob:.3f}")

        # ê°ì • í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
            logger.info(f"ğŸ“‹ í´ëŸ¬ìŠ¤í„° {predicted_cluster} í–¥ìˆ˜ ê°œìˆ˜: {len(cluster_perfumes)}ê°œ")
        else:
            logger.warning("âš ï¸ emotion_cluster ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ë°ì´í„° ì‚¬ìš©")
            cluster_perfumes = df.copy()

        # í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
        if cluster_perfumes.empty:
            logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {predicted_cluster}ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìŒ")
            # ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
            second_best = int(np.argsort(cluster_probabilities)[-2])
            cluster_perfumes = df[df['emotion_cluster'] == second_best].copy()
            predicted_cluster = second_best
            confidence = float(cluster_probabilities[second_best])
            cluster_description = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")
            logger.info(f"ğŸ“‹ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° {second_best} ì‚¬ìš©: {len(cluster_perfumes)}ê°œ")

        # âœ… ì¶”ê°€ í•„í„°ë§ (ì„±ë³„, ê³„ì ˆ ë“±)
        original_count = len(cluster_perfumes)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == request_dict["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered
                logger.info(f"  ì„±ë³„ '{request_dict['gender']}' í•„í„°ë§: {original_count} â†’ {len(cluster_perfumes)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    request_dict["season_tags"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered
                logger.info(f"  ê³„ì ˆ '{request_dict['season_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in cluster_perfumes.columns:
            time_filtered = cluster_perfumes[
                cluster_perfumes['time_tags'].str.contains(
                    request_dict["time_tags"], na=False, case=False
                )
            ]
            if not time_filtered.empty:
                cluster_perfumes = time_filtered
                logger.info(f"  ì‹œê°„ '{request_dict['time_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # âœ… ìƒìœ„ 15ê°œ ë…¸íŠ¸ ì¶”ì¶œ
        recommended_notes = get_top_notes_from_cluster(cluster_perfumes, top_k=15)

        # âœ… ìƒìœ„ 10ê°œ í–¥ìˆ˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
        selected_indices = get_perfume_indices(cluster_perfumes, top_k=10)

        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.now() - start_time).total_seconds()

        # âœ… ìƒˆë¡œìš´ í˜•íƒœì˜ ì‘ë‹µ êµ¬ì„±
        result = {
            "cluster": predicted_cluster,
            "description": cluster_description,
            "proba": [round(float(prob), 4) for prob in cluster_probabilities],  # ì†Œìˆ˜ì  4ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
            "recommended_notes": recommended_notes,
            "selected_idx": selected_indices,
            "metadata": {
                "processing_time_seconds": round(processing_time, 3),
                "total_cluster_perfumes": len(cluster_perfumes),
                "confidence": round(confidence, 3),
                "method": "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸",
                "filters_applied": {
                    "gender": request_dict["gender"],
                    "season": request_dict["season_tags"],
                    "time": request_dict["time_tags"]
                }
            }
        }

        logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ: í´ëŸ¬ìŠ¤í„° {predicted_cluster} (ì†Œìš”ì‹œê°„: {processing_time:.3f}ì´ˆ)")

        return result

    except Exception as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 9. AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ (ê¸°ì¡´ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def predict_with_emotion_cluster_model(request_dict: dict) -> pd.DataFrame:
    """âœ… ìˆ˜ì •ëœ ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ì„ ì‚¬ìš©í•œ AI ì¶”ì²œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""

    try:
        # ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        model = get_model()
        if model is None:
            raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

        # âœ… API ì…ë ¥ì„ ëª¨ë¸ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        raw_features = [
            request_dict["gender"],
            request_dict["season_tags"],
            request_dict["time_tags"],
            request_dict["desired_impression"],
            request_dict["activity"],
            request_dict["weather"]
        ]

        logger.info(f"ğŸ”® AI ëª¨ë¸ ì…ë ¥ ë°ì´í„°: {raw_features}")

        # âœ… ì•ˆì „í•œ ì…ë ¥ ë³€í™˜ ì‚¬ìš©
        x_input = safe_transform_input(raw_features)
        logger.info(f"ğŸ”® ê°ì • í´ëŸ¬ìŠ¤í„° ì˜ˆì¸¡ ì‹œì‘ (ì…ë ¥ shape: {x_input.shape})")

        # ëª¨ë¸ ì˜ˆì¸¡ (ê°ì • í´ëŸ¬ìŠ¤í„°)
        preds = model.predict(x_input, verbose=0)  # (1, 6) ì¶œë ¥
        cluster_probabilities = preds[0]  # [0.1, 0.8, 0.05, 0.02, 0.02, 0.01]
        predicted_cluster = int(np.argmax(cluster_probabilities))  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„°
        confidence = float(cluster_probabilities[predicted_cluster])

        cluster_name = EMOTION_CLUSTER_MAP.get(predicted_cluster, f"í´ëŸ¬ìŠ¤í„° {predicted_cluster}")
        logger.info(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„°: {predicted_cluster} ({cluster_name}) - ì‹ ë¢°ë„: {confidence:.3f}")

        # ëª¨ë“  í´ëŸ¬ìŠ¤í„° í™•ë¥  ë¡œê·¸
        for i, prob in enumerate(cluster_probabilities):
            cluster_desc = EMOTION_CLUSTER_MAP.get(i, f"í´ëŸ¬ìŠ¤í„° {i}")
            logger.info(f"  í´ëŸ¬ìŠ¤í„° {i} ({cluster_desc}): {prob:.3f}")

        # ê°ì • í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ í•„í„°ë§
        if 'emotion_cluster' in df.columns:
            cluster_perfumes = df[df['emotion_cluster'] == predicted_cluster].copy()
            logger.info(f"ğŸ“‹ í´ëŸ¬ìŠ¤í„° {predicted_cluster} í–¥ìˆ˜ ê°œìˆ˜: {len(cluster_perfumes)}ê°œ")
        else:
            logger.warning("âš ï¸ emotion_cluster ì»¬ëŸ¼ì´ ì—†ì–´ ì „ì²´ ë°ì´í„° ì‚¬ìš©")
            cluster_perfumes = df.copy()

        # í´ëŸ¬ìŠ¤í„°ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìœ¼ë©´ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° ì‚¬ìš©
        if cluster_perfumes.empty:
            logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {predicted_cluster}ì— í•´ë‹¹í•˜ëŠ” í–¥ìˆ˜ê°€ ì—†ìŒ")
            # ë‘ ë²ˆì§¸ë¡œ ë†’ì€ í™•ë¥ ì˜ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
            second_best = int(np.argsort(cluster_probabilities)[-2])
            cluster_perfumes = df[df['emotion_cluster'] == second_best].copy()
            predicted_cluster = second_best
            confidence = float(cluster_probabilities[second_best])
            logger.info(f"ğŸ“‹ ëŒ€ì²´ í´ëŸ¬ìŠ¤í„° {second_best} ì‚¬ìš©: {len(cluster_perfumes)}ê°œ")

        # ì¶”ê°€ í•„í„°ë§ (ì„±ë³„, ê³„ì ˆ ë“±)
        original_count = len(cluster_perfumes)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in cluster_perfumes.columns:
            gender_filtered = cluster_perfumes[
                cluster_perfumes['gender'] == request_dict["gender"]
                ]
            if not gender_filtered.empty:
                cluster_perfumes = gender_filtered
                logger.info(f"  ì„±ë³„ '{request_dict['gender']}' í•„í„°ë§: {original_count} â†’ {len(cluster_perfumes)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in cluster_perfumes.columns:
            season_filtered = cluster_perfumes[
                cluster_perfumes['season_tags'].str.contains(
                    request_dict["season_tags"], na=False, case=False
                )
            ]
            if not season_filtered.empty:
                cluster_perfumes = season_filtered
                logger.info(f"  ê³„ì ˆ '{request_dict['season_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in cluster_perfumes.columns:
            time_filtered = cluster_perfumes[
                cluster_perfumes['time_tags'].str.contains(
                    request_dict["time_tags"], na=False, case=False
                )
            ]
            if not time_filtered.empty:
                cluster_perfumes = time_filtered
                logger.info(f"  ì‹œê°„ '{request_dict['time_tags']}' í•„í„°ë§: â†’ {len(cluster_perfumes)}ê°œ")

        # AI ì‹ ë¢°ë„ ê¸°ë°˜ ì ìˆ˜ í• ë‹¹
        cluster_perfumes = cluster_perfumes.copy()

        # í´ëŸ¬ìŠ¤í„° ì‹ ë¢°ë„ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ ì‚¬ìš©
        base_score = confidence * 0.8  # AI ì‹ ë¢°ë„ì˜ 80%ë¥¼ ê¸°ë³¸ ì ìˆ˜ë¡œ

        scores = []
        for idx, (_, row) in enumerate(cluster_perfumes.iterrows()):
            score = base_score

            # ì¶”ê°€ ì¡°ê±´ ì¼ì¹˜ ë³´ë„ˆìŠ¤
            if 'season_tags' in row and request_dict["season_tags"].lower() in str(row['season_tags']).lower():
                score += 0.08
            if 'time_tags' in row and request_dict["time_tags"].lower() in str(row['time_tags']).lower():
                score += 0.06
            if 'desired_impression' in row and request_dict["desired_impression"].lower() in str(
                    row['desired_impression']).lower():
                score += 0.05

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']
            if any(popular in str(row.get('brand', '')) for popular in popular_brands):
                score += 0.03

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜ (ì•ìª½ì¼ìˆ˜ë¡ ì•½ê°„ ë†’ì€ ì ìˆ˜)
            position_bonus = (len(cluster_perfumes) - idx) / len(cluster_perfumes) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.03, 0.05)

            # ì •ê·œí™” (0.4 ~ 0.95 ë²”ìœ„)
            score = max(0.4, min(0.95, score))
            scores.append(score)

        cluster_perfumes['score'] = scores

        # ìƒìœ„ 10ê°œ ì„ íƒ
        top_10 = cluster_perfumes.nlargest(10, 'score')

        logger.info(f"âœ… AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì™„ë£Œ: {len(top_10)}ê°œ")
        if not top_10.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_10['score'].min():.3f} ~ {top_10['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_10['score'].mean():.3f}")

        return top_10

    except Exception as e:
        logger.error(f"âŒ AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨: {e}")
        raise e


# â”€â”€â”€ 10. ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ (ê¸°ì¡´ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def rule_based_recommendation(request_data: dict, top_k: int = 10) -> List[dict]:
    """ë£° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ ì‹œìŠ¤í…œ (AI ëª¨ë¸ ëŒ€ì²´)"""
    logger.info("ğŸ¯ ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ ì‹œì‘")

    try:
        # í•„í„°ë§ ì¡°ê±´
        gender = request_data["gender"]
        season_tags = request_data["season_tags"]
        time_tags = request_data["time_tags"]
        desired_impression = request_data["desired_impression"]
        activity = request_data["activity"]
        weather = request_data["weather"]

        logger.info(f"ğŸ” í•„í„°ë§ ì¡°ê±´: gender={gender}, season_tags={season_tags}, time_tags={time_tags}, "
                    f"desired_impression={desired_impression}, activity={activity}, weather={weather}")

        # ì„±ë³„ ë§¤í•‘
        gender_map = {"women": "women", "men": "men", "unisex": "unisex"}
        mapped_gender = gender_map.get(gender, "unisex")

        # 1ë‹¨ê³„: ê¸°ë³¸ í•„í„°ë§
        candidates = df.copy()
        original_count = len(candidates)

        # ì„±ë³„ í•„í„°ë§
        if 'gender' in df.columns:
            gender_filtered = candidates[candidates['gender'] == mapped_gender]
            if not gender_filtered.empty:
                candidates = gender_filtered
                logger.info(f"  ì„±ë³„ '{mapped_gender}' í•„í„°ë§: {original_count} â†’ {len(candidates)}ê°œ")

        # ê³„ì ˆ í•„í„°ë§
        if 'season_tags' in df.columns:
            season_filtered = candidates[
                candidates['season_tags'].str.contains(season_tags, na=False, case=False)
            ]
            if not season_filtered.empty:
                candidates = season_filtered
                logger.info(f"  ê³„ì ˆ '{season_tags}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì‹œê°„ í•„í„°ë§
        if 'time_tags' in df.columns:
            time_filtered = candidates[
                candidates['time_tags'].str.contains(time_tags, na=False, case=False)
            ]
            if not time_filtered.empty:
                candidates = time_filtered
                logger.info(f"  ì‹œê°„ '{time_tags}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ì¸ìƒ í•„í„°ë§
        if 'desired_impression' in df.columns:
            impression_filtered = candidates[
                candidates['desired_impression'].str.contains(desired_impression, na=False, case=False)
            ]
            if not impression_filtered.empty:
                candidates = impression_filtered
                logger.info(f"  ì¸ìƒ '{desired_impression}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # í™œë™ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'activity' in df.columns:
            activity_filtered = candidates[
                candidates['activity'].str.contains(activity, na=False, case=False)
            ]
            if not activity_filtered.empty:
                candidates = activity_filtered
                logger.info(f"  í™œë™ '{activity}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # ë‚ ì”¨ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if 'weather' in df.columns and weather != 'any':
            weather_filtered = candidates[
                candidates['weather'].str.contains(weather, na=False, case=False)
            ]
            if not weather_filtered.empty:
                candidates = weather_filtered
                logger.info(f"  ë‚ ì”¨ '{weather}' í•„í„°ë§: â†’ {len(candidates)}ê°œ")

        # 2ë‹¨ê³„: ìŠ¤ì½”ì–´ë§
        if candidates.empty:
            logger.warning("âš ï¸ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ì—ì„œ ë‹¤ì–‘ì„± ê¸°ë°˜ ì„ íƒ")
            # ë‹¤ì–‘í•œ ë¸Œëœë“œì—ì„œ ê³ ë¥´ê²Œ ì„ íƒ
            if 'brand' in df.columns:
                unique_brands = df['brand'].unique()
                candidates_list = []
                per_brand = max(1, top_k // len(unique_brands))

                for brand in unique_brands:
                    brand_perfumes = df[df['brand'] == brand].sample(
                        n=min(per_brand, len(df[df['brand'] == brand])),
                        random_state=42
                    )
                    candidates_list.append(brand_perfumes)

                candidates = pd.concat(candidates_list).head(top_k)
            else:
                candidates = df.sample(n=min(top_k, len(df)), random_state=42)

        # ì ìˆ˜ ê³„ì‚°
        candidates = candidates.copy()
        scores = []

        # ë¸Œëœë“œë³„ ê°€ì¤‘ì¹˜ (ì¸ê¸° ë¸Œëœë“œ ì˜ˆì‹œ)
        popular_brands = ['Creed', 'Tom Ford', 'Chanel', 'Dior', 'Jo Malone', 'Diptyque']

        for idx, (_, row) in enumerate(candidates.iterrows()):
            score = 0.3  # ê¸°ë³¸ ì ìˆ˜

            # 1. ì¡°ê±´ ì¼ì¹˜ë„ ì ìˆ˜
            brand_name = str(row.get('brand', ''))
            notes_text = str(row.get('notes', ''))

            # ë¸Œëœë“œ ì¸ê¸°ë„ ë³´ë„ˆìŠ¤
            if any(popular in brand_name for popular in popular_brands):
                score += 0.15

            # ë…¸íŠ¸ ë³µì¡ì„± (ë” ë§ì€ ë…¸íŠ¸ = ë” ë³µì¡í•œ í–¥ìˆ˜)
            note_count = len([n.strip() for n in notes_text.split(',') if n.strip()])
            if note_count >= 8:
                score += 0.10
            elif note_count >= 5:
                score += 0.05

            # í…ìŠ¤íŠ¸ ë§¤ì¹­ ì •í™•ë„
            impression_match_count = 0
            if 'desired_impression' in row:
                impressions = str(row['desired_impression']).lower().split(',')
                impression_match_count = sum(1 for imp in impressions if desired_impression.lower() in imp.strip())
                score += impression_match_count * 0.08

            # ê³„ì ˆ/ì‹œê°„ ë§¤ì¹­ ì •í™•ë„
            if 'season_tags' in row:
                season_tags_data = str(row['season_tags']).lower()
                if season_tags.lower() in season_tags_data:
                    score += 0.12 if f' {season_tags.lower()} ' in f' {season_tags_data} ' else 0.08

            if 'time_tags' in row:
                time_tags_data = str(row['time_tags']).lower()
                if time_tags.lower() in time_tags_data:
                    score += 0.12 if f' {time_tags.lower()} ' in f' {time_tags_data} ' else 0.08

            # í™œë™ ë§¤ì¹­
            if 'activity' in row and activity.lower() in str(row['activity']).lower():
                score += 0.08

            # ë‚ ì”¨ ë§¤ì¹­
            if 'weather' in row and weather != 'any':
                if weather.lower() in str(row['weather']).lower():
                    score += 0.06
            elif weather == 'any':
                score += 0.03

            # ë‹¤ì–‘ì„±ì„ ìœ„í•œ ìœ„ì¹˜ ê¸°ë°˜ ì ìˆ˜
            position_bonus = (len(candidates) - idx) / len(candidates) * 0.05
            score += position_bonus

            # ëœë¤ ìš”ì†Œ (ë‹¤ì–‘ì„± í™•ë³´)
            score += random.uniform(-0.15, 0.15)

            # ì ìˆ˜ ì •ê·œí™” (0.2 ~ 0.95 ë²”ìœ„)
            score = max(0.2, min(0.95, score))
            scores.append(score)

        candidates['score'] = scores

        # ìƒìœ„ Kê°œ ì„ íƒ
        top_candidates = candidates.nlargest(top_k, 'score')

        logger.info(f"âœ… ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ: ìµœì¢… {len(top_candidates)}ê°œ ì„ íƒ")
        if not top_candidates.empty:
            logger.info(f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {top_candidates['score'].min():.3f} ~ {top_candidates['score'].max():.3f}")
            logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {top_candidates['score'].mean():.3f}")

        return top_candidates.to_dict('records')

    except Exception as e:
        logger.error(f"âŒ ë£° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {e}")
        # ìµœì¢… ì•ˆì „ì¥ì¹˜: ì™„ì „ ëœë¤ ì¶”ì²œ
        logger.info("ğŸ² ì™„ì „ ëœë¤ ì¶”ì²œìœ¼ë¡œ ëŒ€ì²´")
        random_sample = df.sample(n=min(top_k, len(df)), random_state=42)
        random_sample = random_sample.copy()
        random_sample['score'] = [random.uniform(0.4, 0.7) for _ in range(len(random_sample))]
        return random_sample.to_dict('records')


# â”€â”€â”€ 11. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_emotion_text(row):
    """ê°ì • ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # 1ìˆœìœ„: desired_impression
    if 'desired_impression' in df.columns and pd.notna(row.get('desired_impression')):
        return str(row['desired_impression'])

    # 2ìˆœìœ„: emotion_clusterë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if 'emotion_cluster' in df.columns and pd.notna(row.get('emotion_cluster')):
        cluster_id = int(row['emotion_cluster']) if str(row['emotion_cluster']).isdigit() else 0
        return EMOTION_CLUSTER_MAP.get(cluster_id, "ê· í˜•ì¡íŒ")

    return "ë‹¤ì–‘í•œ ê°ì •"


def get_recommendation_reason(score: float, method: str) -> str:
    """ì ìˆ˜ì™€ ë°©ë²•ì— ë”°ë¥¸ ì¶”ì²œ ì´ìœ  ìƒì„±"""

    if method.startswith("AI"):
        if score >= 0.9:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì˜ ì™„ë²½í•œ í–¥ìˆ˜ë¼ê³  ë¶„ì„í–ˆìŠµë‹ˆë‹¤!"
        elif score >= 0.8:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ë‹¹ì‹ ì—ê²Œ ì˜ ë§ì„ ê²ƒì´ë¼ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤."
        elif score >= 0.6:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒˆë¡œìš´ ì‹œë„í•´ë³¼ ë§Œí•œ í–¥ìˆ˜ë¡œ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤."
        else:
            return f"ğŸ¤– AIê°€ {score:.1%} í™•ë¥ ë¡œ ìƒ‰ë‹¤ë¥¸ ë§¤ë ¥ì„ ì œì•ˆí•©ë‹ˆë‹¤."
    else:
        # ë£° ê¸°ë°˜ - ë” ë‹¤ì–‘í•œ ë©”ì‹œì§€
        if score >= 0.9:
            return f"ğŸ¯ ì¡°ê±´ ì™„ë²½ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ì´ë³´ë‹¤ ì™„ë²½í•  ìˆœ ì—†ì–´ìš”!"
        elif score >= 0.8:
            return f"â­ ì¡°ê±´ ë†’ì€ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ê°•ë ¥ ì¶”ì²œ!"
        elif score >= 0.6:
            return f"âœ¨ ì¡°ê±´ ì í•© (ì¼ì¹˜ë„ {score:.1%}) - ê³ ë ¤í•´ë³´ì„¸ìš”!"
        elif score >= 0.4:
            return f"ğŸ” ë¶€ë¶„ ì¼ì¹˜ (ì¼ì¹˜ë„ {score:.1%}) - ìƒˆë¡œìš´ ë°œê²¬ì´ ë  ìˆ˜ë„!"
        else:
            return f"ğŸ² ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼ ì œì•ˆ (ì¼ì¹˜ë„ {score:.1%}) - ë„ì „í•´ë³´ì„¸ìš”!"


# â”€â”€â”€ 12. ë ˆê±°ì‹œ ìŠ¤í‚¤ë§ˆ ì •ì˜ (í•˜ìœ„ í˜¸í™˜ì„±) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class PerfumeRecommendItem(BaseModel):
    name: str
    brand: str
    image_url: str
    notes: str
    emotions: str
    reason: str
    score: Optional[float] = None
    method: Optional[str] = None


# â”€â”€â”€ 13. ë¼ìš°í„° ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
router = APIRouter(prefix="/perfumes", tags=["Perfume"])

# ì‹œì‘ ì‹œ ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
logger.info("ğŸš€ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹œì‘...")
check_model_availability()
if _model_available:
    logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
else:
    logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œ ë™ì‘")
logger.info("âœ… ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")


# â”€â”€â”€ 14. ğŸ†• ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post(
    "/recommend-cluster",
    response_model=ClusterRecommendResponse,
    summary="í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ (ìƒˆë¡œìš´ ì‘ë‹µ í˜•íƒœ)",
    description=(
            "ğŸ†• **ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ API**\n\n"
            "ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ AI ëª¨ë¸ì´ ê°ì • í´ëŸ¬ìŠ¤í„°ë¥¼ ì˜ˆì¸¡í•˜ê³ ,\n"
            "í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ì •ë³´ì™€ ì¶”ì²œ í–¥ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n\n"
            "**ğŸ¤– ì‘ë‹µ í˜•íƒœ:**\n"
            "- `cluster`: ì˜ˆì¸¡ëœ ê°ì • í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤ (0-5)\n"
            "- `description`: í´ëŸ¬ìŠ¤í„° ì„¤ëª… (ê°ì • íŠ¹ì„±)\n"
            "- `proba`: 6ê°œ í´ëŸ¬ìŠ¤í„°ë³„ softmax í™•ë¥  ë°°ì—´\n"
            "- `recommended_notes`: í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ìƒìœ„ 15ê°œ ì¸ê¸° ë…¸íŠ¸\n"
            "- `selected_idx`: ì¶”ì²œ í–¥ìˆ˜ë“¤ì˜ ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ 10ê°œ\n\n"
            "**ğŸ“‹ ì…ë ¥ íŒŒë¼ë¯¸í„°:**\n"
            "- encoder.pklê³¼ ì™„ì „ í˜¸í™˜ë˜ëŠ” 6ê°œ íŠ¹ì„± ì…ë ¥\n"
            "- AI ëª¨ë¸ ìš°ì„ , ì‹¤íŒ¨ ì‹œ ë£° ê¸°ë°˜ í´ë°±\n\n"
            "**âœ¨ í™œìš© ë°©ë²•:**\n"
            "- í´ë¼ì´ì–¸íŠ¸ì—ì„œ `selected_idx`ë¡œ í•´ë‹¹ í–¥ìˆ˜ë“¤ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ\n"
            "- `proba` ì •ë³´ë¡œ ì‚¬ìš©ì ì„ í˜¸ë„ ë¶„ì„ ê°€ëŠ¥\n"
            "- `recommended_notes`ë¡œ í–¥ìˆ˜ ë…¸íŠ¸ ê¸°ë°˜ UI êµ¬ì„± ê°€ëŠ¥"
    )
)
def recommend_cluster_based(request: RecommendRequest):
    request_start_time = datetime.now()
    logger.info(f"ğŸ†• í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­: {request}")

    # âœ… ì…ë ¥ ê²€ì¦
    if not validate_request_categories(request):
        logger.error("âŒ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ê°’ ì…ë ¥")
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ ê°’ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ê°’: {SUPPORTED_CATEGORIES}"
        )

    # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    request_dict = request.dict()

    try:
        # AI ëª¨ë¸ ì‹œë„
        if _model_available:
            try:
                logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ë¡œ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì‹œë„")
                result = predict_cluster_recommendation(request_dict)

                # ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                total_processing_time = (datetime.now() - request_start_time).total_seconds()
                result["metadata"]["total_processing_time_seconds"] = round(total_processing_time, 3)

                logger.info(f"âœ… í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì„±ê³µ (í´ëŸ¬ìŠ¤í„°: {result['cluster']}, ì†Œìš”ì‹œê°„: {total_processing_time:.3f}ì´ˆ)")

                return ClusterRecommendResponse(**result)

            except Exception as e:
                logger.warning(f"âš ï¸ AI ëª¨ë¸ í´ëŸ¬ìŠ¤í„° ì¶”ì²œ ì‹¤íŒ¨: {e}")
                # ë£° ê¸°ë°˜ìœ¼ë¡œ í´ë°±í•˜ë˜, í´ëŸ¬ìŠ¤í„° í˜•íƒœë¡œ ë³€í™˜
                logger.info("ğŸ“‹ ë£° ê¸°ë°˜ìœ¼ë¡œ í´ë°±í•˜ì—¬ í´ëŸ¬ìŠ¤í„° í˜•íƒœ ì‘ë‹µ ìƒì„±")

        else:
            logger.info("ğŸ“‹ AI ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€, ë£° ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° í˜•íƒœ ì‘ë‹µ ìƒì„±")

        # ë£° ê¸°ë°˜ í´ë°± - í´ëŸ¬ìŠ¤í„° í˜•íƒœë¡œ ë³€í™˜
        rule_results = rule_based_recommendation(request_dict, 10)
        rule_df = pd.DataFrame(rule_results)

        # ê°€ìƒì˜ í´ëŸ¬ìŠ¤í„° ì •ë³´ ìƒì„± (ë£° ê¸°ë°˜ì´ë¯€ë¡œ)
        fallback_cluster = 2  # ê¸°ë³¸ í´ëŸ¬ìŠ¤í„° (ìš°ì•„í•¨, ì¹œê·¼í•¨)
        fallback_proba = [0.1, 0.15, 0.4, 0.15, 0.1, 0.1]  # ê°€ìƒ í™•ë¥ 

        # ë£° ê¸°ë°˜ ê²°ê³¼ì—ì„œ ë…¸íŠ¸ ì¶”ì¶œ
        fallback_notes = get_top_notes_from_cluster(rule_df, top_k=15)

        # ë£° ê¸°ë°˜ ê²°ê³¼ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        fallback_indices = get_perfume_indices(rule_df, top_k=10)

        total_processing_time = (datetime.now() - request_start_time).total_seconds()

        fallback_result = {
            "cluster": fallback_cluster,
            "description": EMOTION_CLUSTER_MAP[fallback_cluster] + " (ë£° ê¸°ë°˜ ì¶”ì •)",
            "proba": fallback_proba,
            "recommended_notes": fallback_notes,
            "selected_idx": fallback_indices,
            "metadata": {
                "processing_time_seconds": round(total_processing_time, 3),
                "total_cluster_perfumes": len(rule_df),
                "confidence": 0.4,  # ë£° ê¸°ë°˜ì´ë¯€ë¡œ ë‚®ì€ ì‹ ë¢°ë„
                "method": "ë£° ê¸°ë°˜ (AI ëª¨ë¸ ëŒ€ì²´)",
                "fallback_used": True,
                "filters_applied": {
                    "gender": request_dict["gender"],
                    "season": request_dict["season_tags"],
                    "time": request_dict["time_tags"]
                }
            }
        }

        logger.info(f"âœ… ë£° ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° í˜•íƒœ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {total_processing_time:.3f}ì´ˆ)")

        return ClusterRecommendResponse(**fallback_result)

    except Exception as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# â”€â”€â”€ 15. ê¸°ì¡´ APIë“¤ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.post(
    "/recommend",
    response_model=List[PerfumeRecommendItem],
    summary="í–¥ìˆ˜ ì¶”ì²œ (ê¸°ì¡´ ë°©ì‹, í•˜ìœ„ í˜¸í™˜ì„±)",
    description=(
            "**ğŸ”„ ê¸°ì¡´ í–¥ìˆ˜ ì¶”ì²œ API (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)**\n\n"
            "ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n\n"
            "**ğŸ¤– ì¶”ì²œ ë°©ì‹:**\n"
            "1. **AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸**: 6ê°œ ì…ë ¥ â†’ 6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜ â†’ í•´ë‹¹ í´ëŸ¬ìŠ¤í„° í–¥ìˆ˜ ì¶”ì²œ\n"
            "2. **ë£° ê¸°ë°˜ Fallback**: ì¡°ê±´ë¶€ í•„í„°ë§ + ìŠ¤ì½”ì–´ë§ (ëª¨ë¸ì´ ì—†ê±°ë‚˜ ì‹¤íŒ¨í•œ ê²½ìš°)\n"
            "3. **ë‹¤ì–‘ì„± ë³´ì¥**: ë¸Œëœë“œë³„ ê· í˜• ì¡íŒ ì¶”ì²œ\n\n"
            "**âš ï¸ ê¶Œì¥ì‚¬í•­:**\n"
            "- ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ëŠ” `/recommend-cluster` API ì‚¬ìš© ê¶Œì¥\n"
            "- ë” êµ¬ì¡°í™”ëœ ì‘ë‹µê³¼ í´ëŸ¬ìŠ¤í„° ì •ë³´ ì œê³µ\n"
            "- ì´ APIëŠ” ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€"
    )
)
def recommend_perfumes(request: RecommendRequest):
    request_start_time = datetime.now()
    logger.info(f"ğŸ¯ í–¥ìˆ˜ ì¶”ì²œ ìš”ì²­ ì‹œì‘ (ê¸°ì¡´ ë°©ì‹): {request}")

    # âœ… ì…ë ¥ ê²€ì¦
    if not validate_request_categories(request):
        logger.error("âŒ ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ê°’ ì…ë ¥")
        raise HTTPException(
            status_code=400,
            detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì¹´í…Œê³ ë¦¬ ê°’ì…ë‹ˆë‹¤. ì§€ì›ë˜ëŠ” ê°’: {SUPPORTED_CATEGORIES}"
        )

    # ìš”ì²­ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    request_dict = request.dict()

    method_used = "ì•Œ ìˆ˜ ì—†ìŒ"

    # 1) AI ëª¨ë¸ ì‹œë„
    if _model_available:
        model_start_time = datetime.now()
        try:
            logger.info("ğŸ¤– AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ ì¶”ì²œ ì‹œë„")

            # ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸ë¡œ ì¶”ì²œ
            top_10 = predict_with_emotion_cluster_model(request_dict)
            method_used = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"

            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.info(f"âœ… AI ëª¨ë¸ ì¶”ì²œ ì„±ê³µ (ë°©ë²•: {method_used}, ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ)")

        except Exception as e:
            model_time = (datetime.now() - model_start_time).total_seconds()
            logger.warning(f"âš ï¸ AI ëª¨ë¸ ì¶”ì²œ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {model_time:.3f}ì´ˆ): {e}")
            logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œìœ¼ë¡œ ì „í™˜")

            rule_start_time = datetime.now()
            rule_results = rule_based_recommendation(request_dict, 10)
            top_10 = pd.DataFrame(rule_results)
            rule_time = (datetime.now() - rule_start_time).total_seconds()
            method_used = "ë£° ê¸°ë°˜ (AI ëª¨ë¸ ì‹¤íŒ¨)"
            logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")
    else:
        logger.info("ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì‚¬ìš© (ëª¨ë¸ íŒŒì¼ í¬ê¸° ë¶€ì¡±)")
        rule_start_time = datetime.now()
        rule_results = rule_based_recommendation(request_dict, 10)
        top_10 = pd.DataFrame(rule_results)
        rule_time = (datetime.now() - rule_start_time).total_seconds()
        method_used = "ë£° ê¸°ë°˜ (ëª¨ë¸ í¬ê¸° ë¶€ì¡±)"
        logger.info(f"ğŸ“‹ ë£° ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {rule_time:.3f}ì´ˆ)")

    # 2) ê²°ê³¼ ê°€ê³µ
    response_list: List[PerfumeRecommendItem] = []
    for idx, (_, row) in enumerate(top_10.iterrows(), 1):
        emotions_text = get_emotion_text(row)
        score = float(row.get('score', 0.0))

        # ì¶”ì²œ ì´ìœ  ìƒì„±
        reason = get_recommendation_reason(score, method_used)

        response_list.append(
            PerfumeRecommendItem(
                name=str(row["name"]),
                brand=str(row["brand"]),
                image_url=str(row["image_url"]),
                notes=str(row["notes"]),
                emotions=emotions_text,
                reason=reason,
                score=score,
                method=method_used
            )
        )

    # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
    total_processing_time = (datetime.now() - request_start_time).total_seconds()

    logger.info(f"âœ… í–¥ìˆ˜ ì¶”ì²œ ì™„ë£Œ: {len(response_list)}ê°œ ({method_used})")
    logger.info(f"â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_processing_time:.3f}ì´ˆ")
    if response_list:
        logger.info(
            f"ğŸ“Š ì ìˆ˜ ë²”ìœ„: {min(item.score for item in response_list):.3f} ~ {max(item.score for item in response_list):.3f}")
        logger.info(f"ğŸ“Š í‰ê·  ì ìˆ˜: {sum(item.score for item in response_list) / len(response_list):.3f}")

    return response_list


@router.get(
    "/model-status",
    summary="ëª¨ë¸ ìƒíƒœ í™•ì¸",
    description="AI ëª¨ë¸ê³¼ ê´€ë ¨ íŒŒì¼ë“¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def get_model_status():
    """ëª¨ë¸ ë° ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    # íŒŒì¼ ìƒíƒœ í™•ì¸
    model_exists = os.path.exists(MODEL_PATH)
    encoder_exists = os.path.exists(ENCODER_PATH)

    model_size = os.path.getsize(MODEL_PATH) if model_exists else 0
    encoder_size = os.path.getsize(ENCODER_PATH) if encoder_exists else 0

    # âœ… ìˆ˜ì •ëœ ìœ íš¨ì„± ê¸°ì¤€
    model_size_valid = model_size > 10000  # 10KB ì´ìƒ (ê¸°ì¡´: 100KB)
    encoder_size_valid = encoder_size > 500  # 500B ì´ìƒ (ê¸°ì¡´: 100B)

    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ (ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš°)
    model_structure = None
    if _model is not None:
        try:
            model_structure = {
                "input_shape": str(_model.input_shape),
                "output_shape": str(_model.output_shape),
                "total_params": _model.count_params(),
                "layers": len(_model.layers),
                "layer_details": [
                    {
                        "name": layer.name,
                        "type": layer.__class__.__name__,
                        "units": getattr(layer, 'units', None),
                        "activation": getattr(layer.activation, '__name__', None) if hasattr(layer,
                                                                                             'activation') else None
                    } for layer in _model.layers
                ]
            }
        except:
            model_structure = "ëª¨ë¸ ì •ë³´ ì½ê¸° ì‹¤íŒ¨"

    # âœ… scikit-learn ë²„ì „ ì •ë³´ ì¶”ê°€
    try:
        import sklearn
        sklearn_version = sklearn.__version__
    except:
        sklearn_version = "ë¶ˆëª…"

    return {
        "timestamp": datetime.now().isoformat(),
        "model_available": _model_available,
        "files": {
            "keras_model": {
                "path": MODEL_PATH,
                "exists": model_exists,
                "size_bytes": model_size,
                "size_kb": round(model_size / 1024, 2),  # KB ë‹¨ìœ„ ì¶”ê°€
                "size_mb": round(model_size / (1024 * 1024), 2),
                "valid": model_size_valid,
                "min_required_kb": 10,  # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ëª…ì‹œ
                "status": "âœ… ìœ íš¨" if model_size_valid else "âŒ í¬ê¸° ë¶€ì¡±"
            },
            "encoder": {
                "path": ENCODER_PATH,
                "exists": encoder_exists,
                "size_bytes": encoder_size,
                "size_kb": round(encoder_size / 1024, 2),
                "valid": encoder_size_valid,
                "min_required_bytes": 500,  # ìµœì†Œ ìš”êµ¬ì‚¬í•­ ëª…ì‹œ
                "status": "âœ… ìœ íš¨" if encoder_size_valid else "âŒ í¬ê¸° ë¶€ì¡±"
            }
        },
        "model_info": {
            "expected_structure": {
                "input_shape": "(None, 6)",
                "layers": [
                    "Dense(64, activation='relu')",
                    "Dense(6, activation='softmax')"
                ],
                "output_shape": "(None, 6)",
                "purpose": "6ê°œ ê°ì • í´ëŸ¬ìŠ¤í„° ë¶„ë¥˜"
            },
            "keras_version": "3.8.0 (detected from file)",
            "saved_date": "2025-06-05@05:09:56"
        },
        "model_structure": model_structure,
        "emotion_clusters": EMOTION_CLUSTER_MAP,
        "recommendation_method": "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸" if _model_available else "ë£° ê¸°ë°˜",
        "fallback_encoder_ready": _fallback_encoder is not None,
        "supported_categories": SUPPORTED_CATEGORIES,  # âœ… encoder.pkl í˜¸í™˜ ì¹´í…Œê³ ë¦¬
        "system": {
            "python_version": sys.version.split()[0],
            "sklearn_version": sklearn_version,  # âœ… ì¶”ê°€
            "current_directory": os.getcwd(),
            "router_location": BASE_DIR,
            "dataset_loaded": len(df) > 0,
            "dataset_size": len(df)
        },
        "dataset_info": {
            "total_perfumes": len(df),
            "columns": list(df.columns),
            "sample_brands": df['brand'].unique()[:5].tolist() if 'brand' in df.columns else [],
            "emotion_cluster_distribution": dict(
                df['emotion_cluster'].value_counts()) if 'emotion_cluster' in df.columns else None
        },
        "compatibility": {
            "encoder_type": "OrdinalEncoder (6 output features)",
            "api_schema_categories": SUPPORTED_CATEGORIES,
            "encoder_fallback_available": _fallback_encoder is not None,
            "sklearn_compatibility": "OrdinalEncoder ì‚¬ìš© (encoder.pkl í˜¸í™˜)"
        },
        "ğŸ†•_new_features": {
            "cluster_based_api": "/perfumes/recommend-cluster",
            "cluster_response_format": {
                "cluster": "int (0-5)",
                "description": "str",
                "proba": "List[float] (length 6)",
                "recommended_notes": "List[str] (max 15)",
                "selected_idx": "List[int] (max 10)"
            }
        }
    }


@router.get(
    "/health",
    summary="ì¶”ì²œ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬",
    description="ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì „ë°˜ì ì¸ ê±´ê°• ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
)
def health_check():
    """ì¶”ì²œ ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬"""

    health_status = {
        "timestamp": datetime.now().isoformat(),
        "status": "healthy",
        "checks": {}
    }

    # ë°ì´í„°ì…‹ í™•ì¸
    try:
        health_status["checks"]["dataset"] = {
            "status": "ok" if len(df) > 0 else "error",
            "perfume_count": len(df),
            "columns_available": len(df.columns)
        }
    except Exception as e:
        health_status["checks"]["dataset"] = {
            "status": "error",
            "error": str(e)
        }

    # ëª¨ë¸ íŒŒì¼ í™•ì¸ (ìˆ˜ì •ëœ ê¸°ì¤€)
    try:
        model_exists = os.path.exists(MODEL_PATH)
        encoder_exists = os.path.exists(ENCODER_PATH)
        model_size = os.path.getsize(MODEL_PATH) if model_exists else 0
        encoder_size = os.path.getsize(ENCODER_PATH) if encoder_exists else 0

        # âœ… ìˆ˜ì •ëœ í¬ê¸° ê¸°ì¤€
        model_valid = model_exists and model_size > 10000  # 10KB ì´ìƒ
        encoder_valid = encoder_exists and encoder_size > 500  # 500B ì´ìƒ

        health_status["checks"]["model_files"] = {
            "status": "ok" if model_valid and encoder_valid else "warning",
            "model_available": model_valid,
            "encoder_available": encoder_valid,
            "model_size_kb": round(model_size / 1024, 2),
            "encoder_size_bytes": encoder_size,
            "fallback_ready": _fallback_encoder is not None
        }
    except Exception as e:
        health_status["checks"]["model_files"] = {
            "status": "error",
            "error": str(e)
        }

    # âœ… ì¸ì½”ë” í˜¸í™˜ì„± ì²´í¬ ì¶”ê°€
    try:
        fallback_encoder = get_fallback_encoder()
        health_status["checks"]["encoder_compatibility"] = {
            "status": "ok" if fallback_encoder is not None else "error",
            "fallback_encoder_available": fallback_encoder is not None,
            "encoder_type": "OrdinalEncoder",
            "output_features": 6,
            "sklearn_compatible": True  # fallback ìƒì„± ì„±ê³µí•˜ë©´ í˜¸í™˜ë¨
        }
    except Exception as e:
        health_status["checks"]["encoder_compatibility"] = {
            "status": "error",
            "error": str(e),
            "sklearn_compatible": False
        }

    # ğŸ†• í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
    try:
        test_request = {
            "gender": "women",
            "season_tags": "spring",
            "time_tags": "day",
            "desired_impression": "confident, fresh",
            "activity": "casual",
            "weather": "any"
        }

        start_time = datetime.now()
        if _model_available:
            try:
                cluster_result = predict_cluster_recommendation(test_request)
                method = "AI í´ëŸ¬ìŠ¤í„° ëª¨ë¸"
                test_success = True
                result_count = len(cluster_result.get("selected_idx", []))
            except:
                rule_results = rule_based_recommendation(test_request, 3)
                test_results = pd.DataFrame(rule_results)
                method = "ë£° ê¸°ë°˜ (AI ì‹¤íŒ¨)"
                test_success = True
                result_count = len(test_results)
        else:
            rule_results = rule_based_recommendation(test_request, 3)
            test_results = pd.DataFrame(rule_results)
            method = "ë£° ê¸°ë°˜ (ëª¨ë¸ í¬ê¸° ë¶€ì¡±)"
            test_success = True
            result_count = len(test_results)

        processing_time = (datetime.now() - start_time).total_seconds()

        health_status["checks"]["recommendation_system"] = {
            "status": "ok" if test_success and result_count > 0 else "error",
            "test_result_count": result_count,
            "processing_time_seconds": round(processing_time, 3),
            "method": method
        }

        # ğŸ†• í´ëŸ¬ìŠ¤í„° API í…ŒìŠ¤íŠ¸ ì¶”ê°€
        health_status["checks"]["cluster_api"] = {
            "status": "ok" if _model_available else "warning",
            "cluster_api_available": _model_available,
            "fallback_available": True
        }

    except Exception as e:
        health_status["checks"]["recommendation_system"] = {
            "status": "error",
            "error": str(e)
        }

    # ì „ì²´ ìƒíƒœ ê²°ì •
    all_checks = health_status["checks"].values()
    if any(check.get("status") == "error" for check in all_checks):
        health_status["status"] = "unhealthy"
    elif any(check.get("status") == "warning" for check in all_checks):
        health_status["status"] = "degraded"

    return health_status


@router.post(
    "/test-recommendation",
    summary="ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ (ê°œë°œìš©)",
    description="ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ ì¶”ì²œ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
)
def test_recommendation_system():
    """ì¶”ì²œ ì‹œìŠ¤í…œì„ ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""

    test_cases = [
        {
            "name": "ì—¬ì„±ìš© ë´„ ë°ì´ í–¥ìˆ˜",
            "request": {
                "gender": "women",
                "season_tags": "spring",
                "time_tags": "day",
                "desired_impression": "confident, fresh",
                "activity": "casual",
                "weather": "any"
            }
        },
        {
            "name": "ë‚¨ì„±ìš© ê²¨ìš¸ ë‚˜ì´íŠ¸ í–¥ìˆ˜",
            "request": {
                "gender": "men",
                "season_tags": "winter",
                "time_tags": "night",
                "desired_impression": "confident, mysterious",
                "activity": "date",
                "weather": "cold"
            }
        },
        {
            "name": "ìœ ë‹ˆì„¹ìŠ¤ ì—¬ë¦„ í–¥ìˆ˜",
            "request": {
                "gender": "unisex",
                "season_tags": "summer",
                "time_tags": "day",
                "desired_impression": "elegant, friendly",
                "activity": "work",
                "weather": "hot"
            }
        }
    ]

    results = []

    for test_case in test_cases:
        try:
            start_time = datetime.now()

            # ğŸ†• í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ ì¶”ì²œ í…ŒìŠ¤íŠ¸
            cluster_result = None
            cluster_success = False

            if _model_available:
                try:
                    cluster_result = predict_cluster_recommendation(test_case["request"])
                    cluster_success = True
                    cluster_method = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"
                except Exception as e:
                    cluster_success = False
                    cluster_error = str(e)
                    cluster_method = "ì‹¤íŒ¨"

            # ê¸°ì¡´ ë°©ì‹ ì¶”ì²œ í…ŒìŠ¤íŠ¸
            if _model_available:
                try:
                    ai_results = predict_with_emotion_cluster_model(test_case["request"])
                    result_data = ai_results.to_dict('records')[:3]
                    method = "AI ê°ì • í´ëŸ¬ìŠ¤í„° ëª¨ë¸"
                except:
                    rule_results = rule_based_recommendation(test_case["request"], 5)
                    result_data = rule_results[:3]
                    method = "ë£° ê¸°ë°˜ (AI ì‹¤íŒ¨)"
            else:
                rule_results = rule_based_recommendation(test_case["request"], 5)
                result_data = rule_results[:3]
                method = "ë£° ê¸°ë°˜ (ëª¨ë¸ í¬ê¸° ë¶€ì¡±)"

            processing_time = (datetime.now() - start_time).total_seconds()

            # ê²°ê³¼ êµ¬ì„±
            test_result = {
                "test_name": test_case["name"],
                "request": test_case["request"],
                "success": True,
                "legacy_api": {
                    "method": method,
                    "result_count": len(result_data),
                    "sample_results": [
                        {
                            "name": r.get("name", ""),
                            "brand": r.get("brand", ""),
                            "score": round(r.get("score", 0), 3)
                        } for r in result_data
                    ]
                },
                "ğŸ†•_cluster_api": {
                    "success": cluster_success,
                    "method": cluster_method if cluster_success else "ì‹¤íŒ¨",
                    "cluster": cluster_result.get("cluster") if cluster_result else None,
                    "description": cluster_result.get("description") if cluster_result else None,
                    "confidence": cluster_result["proba"][cluster_result["cluster"]] if cluster_result else None,
                    "notes_count": len(cluster_result.get("recommended_notes", [])) if cluster_result else 0,
                    "selected_perfumes_count": len(cluster_result.get("selected_idx", [])) if cluster_result else 0,
                    "error": cluster_error if not cluster_success else None
                },
                "processing_time_seconds": round(processing_time, 3)
            }

            results.append(test_result)

        except Exception as e:
            results.append({
                "test_name": test_case["name"],
                "request": test_case["request"],
                "success": False,
                "error": str(e),
                "processing_time_seconds": 0
            })

    # âœ… scikit-learn ë²„ì „ ì •ë³´ ì¶”ê°€
    try:
        import sklearn
        sklearn_version = sklearn.__version__
    except:
        sklearn_version = "ë¶ˆëª…"

    return {
        "timestamp": datetime.now().isoformat(),
        "model_available": _model_available,
        "model_size_kb": round(os.path.getsize(MODEL_PATH) / 1024, 2) if os.path.exists(MODEL_PATH) else 0,
        "encoder_size_bytes": os.path.getsize(ENCODER_PATH) if os.path.exists(ENCODER_PATH) else 0,
        "fallback_encoder_available": _fallback_encoder is not None,
        "dataset_size": len(df),
        "emotion_clusters": EMOTION_CLUSTER_MAP,
        "supported_categories": SUPPORTED_CATEGORIES,  # âœ… encoder.pkl í˜¸í™˜ ì¹´í…Œê³ ë¦¬
        "sklearn_version": sklearn_version,  # âœ… ì¶”ê°€
        "ğŸ†•_new_features": {
            "cluster_api_endpoint": "/perfumes/recommend-cluster",
            "cluster_response_includes": [
                "cluster (int)", "description (str)", "proba (List[float])",
                "recommended_notes (List[str])", "selected_idx (List[int])"
            ]
        },
        "test_results": results,
        "summary": {
            "total_tests": len(test_cases),
            "successful_tests": sum(1 for r in results if r["success"]),
            "cluster_api_successful_tests": sum(1 for r in results if r.get("ğŸ†•_cluster_api", {}).get("success", False)),
            "average_processing_time": round(
                sum(r.get("processing_time_seconds", 0) for r in results) / len(results), 3
            )
        }
    }


# â”€â”€â”€ 16. ğŸ†• ë…¸íŠ¸ ë¶„ì„ ì „ìš© API (ì¶”ê°€ ê¸°ëŠ¥) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.get(
    "/notes/analysis",
    summary="í–¥ìˆ˜ ë…¸íŠ¸ ë¶„ì„ (í´ëŸ¬ìŠ¤í„°ë³„)",
    description="ê° ê°ì • í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ì¸ê¸° ìˆëŠ” í–¥ìˆ˜ ë…¸íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."
)
def analyze_notes_by_cluster():
    """í´ëŸ¬ìŠ¤í„°ë³„ ë…¸íŠ¸ ë¶„ì„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    cluster_notes_analysis = {}

    try:
        for cluster_id in range(6):  # 0-5 í´ëŸ¬ìŠ¤í„°
            if 'emotion_cluster' in df.columns:
                cluster_perfumes = df[df['emotion_cluster'] == cluster_id]

                if len(cluster_perfumes) > 0:
                    # ìƒìœ„ 15ê°œ ë…¸íŠ¸ ì¶”ì¶œ
                    top_notes = get_top_notes_from_cluster(cluster_perfumes, top_k=15)

                    # ë…¸íŠ¸ ë¹ˆë„ ê³„ì‚°
                    all_notes = []
                    for _, row in cluster_perfumes.iterrows():
                        notes = parse_notes_from_string(row.get('notes', ''))
                        all_notes.extend(notes)

                    note_counter = Counter(all_notes)

                    cluster_notes_analysis[cluster_id] = {
                        "cluster_name": EMOTION_CLUSTER_MAP.get(cluster_id, f"í´ëŸ¬ìŠ¤í„° {cluster_id}"),
                        "perfume_count": len(cluster_perfumes),
                        "total_notes_found": len(all_notes),
                        "unique_notes_count": len(set(all_notes)),
                        "top_15_notes": top_notes,
                        "top_5_with_frequency": [
                            {"note": note, "frequency": count}
                            for note, count in note_counter.most_common(5)
                        ]
                    }
                else:
                    cluster_notes_analysis[cluster_id] = {
                        "cluster_name": EMOTION_CLUSTER_MAP.get(cluster_id, f"í´ëŸ¬ìŠ¤í„° {cluster_id}"),
                        "perfume_count": 0,
                        "error": "í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤."
                    }

        return {
            "timestamp": datetime.now().isoformat(),
            "total_perfumes": len(df),
            "cluster_analysis": cluster_notes_analysis,
            "summary": {
                "clusters_with_data": sum(1 for analysis in cluster_notes_analysis.values() if "error" not in analysis),
                "total_unique_notes": len(set(
                    note for analysis in cluster_notes_analysis.values()
                    if "top_15_notes" in analysis
                    for note in analysis["top_15_notes"]
                ))
            }
        }

    except Exception as e:
        logger.error(f"âŒ ë…¸íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "error": f"ë…¸íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }


@router.get(
    "/notes/search/{note_name}",
    summary="íŠ¹ì • ë…¸íŠ¸ê°€ í¬í•¨ëœ í–¥ìˆ˜ ê²€ìƒ‰",
    description="ì§€ì •ëœ ë…¸íŠ¸ê°€ í¬í•¨ëœ í–¥ìˆ˜ë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."
)
def search_perfumes_by_note(note_name: str, limit: int = 20):
    """íŠ¹ì • ë…¸íŠ¸ê°€ í¬í•¨ëœ í–¥ìˆ˜ë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""

    try:
        note_name = note_name.lower().strip()
        matching_perfumes = []

        for idx, row in df.iterrows():
            notes = parse_notes_from_string(row.get('notes', ''))

            if note_name in notes:
                perfume_info = {
                    "index": int(idx),
                    "name": str(row.get('name', '')),
                    "brand": str(row.get('brand', '')),
                    "notes": str(row.get('notes', '')),
                    "emotion_cluster": int(row.get('emotion_cluster', 0)),
                    "cluster_description": EMOTION_CLUSTER_MAP.get(int(row.get('emotion_cluster', 0)), "ì•Œ ìˆ˜ ì—†ìŒ"),
                    "gender": str(row.get('gender', '')),
                    "season_tags": str(row.get('season_tags', '')),
                    "time_tags": str(row.get('time_tags', ''))
                }
                matching_perfumes.append(perfume_info)

        # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ì •ë ¬
        matching_perfumes.sort(key=lambda x: x['emotion_cluster'])

        # ì œí•œëœ ê°œìˆ˜ë§Œ ë°˜í™˜
        limited_results = matching_perfumes[:limit]

        # í´ëŸ¬ìŠ¤í„°ë³„ ë¶„í¬ ê³„ì‚°
        cluster_distribution = {}
        for perfume in matching_perfumes:
            cluster = perfume['emotion_cluster']
            cluster_distribution[cluster] = cluster_distribution.get(cluster, 0) + 1

        return {
            "timestamp": datetime.now().isoformat(),
            "search_note": note_name,
            "total_matches": len(matching_perfumes),
            "returned_count": len(limited_results),
            "cluster_distribution": cluster_distribution,
            "matching_perfumes": limited_results
        }

    except Exception as e:
        logger.error(f"âŒ ë…¸íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ë…¸íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


# â”€â”€â”€ 17. ğŸ†• í´ëŸ¬ìŠ¤í„° ì •ë³´ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@router.get(
    "/clusters/info",
    summary="ê°ì • í´ëŸ¬ìŠ¤í„° ì •ë³´",
    description="ëª¨ë“  ê°ì • í´ëŸ¬ìŠ¤í„°ì˜ ì •ë³´ì™€ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
)
def get_cluster_info():
    """ê°ì • í´ëŸ¬ìŠ¤í„° ì •ë³´ì™€ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""

    try:
        cluster_info = {}

        for cluster_id in range(6):
            cluster_perfumes = df[
                df['emotion_cluster'] == cluster_id] if 'emotion_cluster' in df.columns else pd.DataFrame()

            cluster_info[cluster_id] = {
                "cluster_id": cluster_id,
                "description": EMOTION_CLUSTER_MAP.get(cluster_id, f"í´ëŸ¬ìŠ¤í„° {cluster_id}"),
                "perfume_count": len(cluster_perfumes),
                "percentage": round(len(cluster_perfumes) / len(df) * 100, 2) if len(df) > 0 else 0
            }

            if len(cluster_perfumes) > 0:
                # ì„±ë³„ ë¶„í¬
                gender_dist = cluster_perfumes[
                    'gender'].value_counts().to_dict() if 'gender' in cluster_perfumes.columns else {}

                # ë¸Œëœë“œ ë¶„í¬ (ìƒìœ„ 5ê°œ)
                brand_dist = cluster_perfumes['brand'].value_counts().head(
                    5).to_dict() if 'brand' in cluster_perfumes.columns else {}

                cluster_info[cluster_id].update({
                    "gender_distribution": gender_dist,
                    "top_5_brands": brand_dist,
                    "sample_perfumes": [
                        {
                            "name": row['name'],
                            "brand": row['brand']
                        } for _, row in cluster_perfumes.head(3).iterrows()
                    ]
                })

        return {
            "timestamp": datetime.now().isoformat(),
            "total_perfumes": len(df),
            "total_clusters": 6,
            "cluster_details": cluster_info,
            "emotion_cluster_map": EMOTION_CLUSTER_MAP
        }

    except Exception as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get(
    "/clusters/{cluster_id}/perfumes",
    summary="íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì˜ í–¥ìˆ˜ ëª©ë¡",
    description="ì§€ì •ëœ ê°ì • í´ëŸ¬ìŠ¤í„°ì— ì†í•œ í–¥ìˆ˜ë“¤ì˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
)
def get_cluster_perfumes(cluster_id: int, limit: int = 50, offset: int = 0):
    """íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì˜ í–¥ìˆ˜ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""

    if cluster_id < 0 or cluster_id > 5:
        raise HTTPException(
            status_code=400,
            detail="í´ëŸ¬ìŠ¤í„° IDëŠ” 0-5 ë²”ìœ„ì—¬ì•¼ í•©ë‹ˆë‹¤."
        )

    try:
        if 'emotion_cluster' not in df.columns:
            raise HTTPException(
                status_code=500,
                detail="ë°ì´í„°ì…‹ì— emotion_cluster ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."
            )

        cluster_perfumes = df[df['emotion_cluster'] == cluster_id]

        if len(cluster_perfumes) == 0:
            return {
                "cluster_id": cluster_id,
                "description": EMOTION_CLUSTER_MAP.get(cluster_id, f"í´ëŸ¬ìŠ¤í„° {cluster_id}"),
                "total_count": 0,
                "perfumes": [],
                "message": "í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì— í–¥ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤."
            }

        # í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
        paginated_perfumes = cluster_perfumes.iloc[offset:offset + limit]

        perfume_list = []
        for idx, row in paginated_perfumes.iterrows():
            perfume_list.append({
                "index": int(idx),
                "name": str(row.get('name', '')),
                "brand": str(row.get('brand', '')),
                "image_url": str(row.get('image_url', '')),
                "notes": str(row.get('notes', '')),
                "gender": str(row.get('gender', '')),
                "season_tags": str(row.get('season_tags', '')),
                "time_tags": str(row.get('time_tags', '')),
                "desired_impression": str(row.get('desired_impression', ''))
            })

        return {
            "cluster_id": cluster_id,
            "description": EMOTION_CLUSTER_MAP.get(cluster_id, f"í´ëŸ¬ìŠ¤í„° {cluster_id}"),
            "total_count": len(cluster_perfumes),
            "returned_count": len(perfume_list),
            "offset": offset,
            "limit": limit,
            "has_more": offset + limit < len(cluster_perfumes),
            "perfumes": perfume_list
        }

    except Exception as e:
        logger.error(f"âŒ í´ëŸ¬ìŠ¤í„° í–¥ìˆ˜ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"í´ëŸ¬ìŠ¤í„° í–¥ìˆ˜ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )